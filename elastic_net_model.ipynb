{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, we train an elastic net model for each fold of the cross-validation set and compute the corresponding metrics. The elastic net model minimises the loss function\n",
    "\n",
    "$$L(w_1,\\dots,w_n) = \\sum_{i=1}^{n}\\left(\\left(y_i-w_ix_i\\right)^2 + \\alpha\\left|w_i\\right| + \\beta w_i^2\\right),$$\n",
    "\n",
    "where $y_i$ are the ground truth labels, $x_i$ are the input features (or \"predictor variables\"), $w_i$ are the weights for the individual features (or \"coefficients\"), $n$ is the number of training samples, and $\\alpha,\\beta$ are regularisation parameters.\n",
    "\n",
    "Note that the shapes of the feature arrays in the following block are:\n",
    "- `X_train`: (20160, 132)\n",
    "- `Y_train`: (20160,)\n",
    "- `X_val`: (5040, 132)\n",
    "- `Y_val`: (5040,)\n",
    "- `X_test`: (48, 132)\n",
    "- `Y_test`: (48,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "- Libraries\n",
    "- Data files with responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "clip = lambda x, x_min = -1, x_max = 1: np.where(np.where(x < x_min,x_min,x) > x_max, x_max, np.where(x < x_min,x_min,x)) # Clip an array to values between x_min and x_max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.read_csv(os.path.join('..','data','responses.csv'), dtype = {'participant':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate ground truth labels for pleasantness and eventfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['pleasant', 'eventful', 'chaotic', 'vibrant', 'uneventful', 'calm', 'annoying', 'monotonous'] # Define attributes to extract from dataframes\n",
    "ISOPl_weights = [1,0,-np.sqrt(2)/2,np.sqrt(2)/2, 0, np.sqrt(2)/2,-1,-np.sqrt(2)/2] # Define weights for each attribute in attributes in computation of ISO Pleasantness\n",
    "\n",
    "responses_copy = responses.copy() \n",
    "responses_copy['ground_truth_label'] = ((responses[attributes] * ISOPl_weights).sum(axis=1)/(4+np.sqrt(32))).values # These are normalised ISO Pleasantness values (in [-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['pleasant', 'eventful', 'chaotic', 'vibrant', 'uneventful', 'calm', 'annoying', 'monotonous'] # Define attributes to extract from dataframes\n",
    "ISOEv_weights = [0,1,np.sqrt(2)/2,np.sqrt(2)/2, -1, -np.sqrt(2)/2,0,-np.sqrt(2)/2] # Define weights for each attribute in attributes in computation of ISO Pleasantness\n",
    "\n",
    "responses_copy2 = responses.copy() \n",
    "responses_copy2['ground_truth_label'] = ((responses[attributes] * ISOEv_weights).sum(axis=1)/(4+np.sqrt(32))).values # These are normalised ISO Pleasantness values (in [-1,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the predictor variables that we will be using in `relevant_columns_enet`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns_enet = ['Savg_r','Smax_r','S05_r','S10_r','S20_r','S30_r','S40_r','S50_r','S60_r','S70_r','S80_r','S90_r','S95_r',\n",
    "                         'Navg_r','Nrmc_r','Nmax_r','N05_r','N10_r','N20_r','N30_r','N40_r','N50_r','N60_r','N70_r','N80_r','N90_r','N95_r',\n",
    "                         'Favg_r','Fmax_r','F05_r','F10_r','F20_r','F30_r','F40_r','F50_r','F60_r','F70_r','F80_r','F90_r','F95_r',\n",
    "                         'LAavg_r','LAmin_r','LAmax_r','LA05_r','LA10_r','LA20_r','LA30_r','LA40_r','LA50_r','LA60_r','LA70_r','LA80_r','LA90_r','LA95_r',\n",
    "                         'LCavg_r','LCmin_r','LCmax_r','LC05_r','LC10_r','LC20_r','LC30_r','LC40_r','LC50_r','LC60_r','LC70_r','LC80_r','LC90_r','LC95_r',\n",
    "                         'Ravg_r','Rmax_r','R05_r','R10_r','R20_r','R30_r','R40_r','R50_r','R60_r','R70_r','R80_r','R90_r','R95_r',\n",
    "                         'Tgavg_r','Tavg_r','Tmax_r','T05_r','T10_r','T20_r','T30_r','T40_r','T50_r','T60_r','T70_r','T80_r','T90_r','T95_r',\n",
    "                         'M00005_0_r','M00006_3_r','M00008_0_r','M00010_0_r','M00012_5_r','M00016_0_r','M00020_0_r','M00025_0_r','M00031_5_r','M00040_0_r',\n",
    "                         'M00050_0_r','M00063_0_r','M00080_0_r','M00100_0_r','M00125_0_r','M00160_0_r','M00200_0_r','M00250_0_r','M00315_0_r','M00400_0_r',\n",
    "                         'M00500_0_r','M00630_0_r','M00800_0_r','M01000_0_r','M01250_0_r','M01600_0_r','M02000_0_r','M02500_0_r','M03150_0_r','M04000_0_r',\n",
    "                         'M05000_0_r','M06300_0_r','M08000_0_r','M10000_0_r','M12500_0_r','M16000_0_r','M20000_0_r']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we generate the elastic net models and evaluate their performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLEASANTNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating performance of ElasticNet() model...\n",
      "     |    Mean squared error    |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "   1 | 0.1360 | 0.1321 | 0.0912 |  0.3074 | 20160 |  5040 |  48  |  132  |   3  \n",
      "   2 | 0.1368 | 0.1284 | 0.0954 |  0.3105 | 20160 |  5040 |  48  |  132  |   2  \n",
      "   3 | 0.1351 | 0.1384 | 0.0941 |  0.2898 | 20160 |  5040 |  48  |  132  |   2  \n",
      "   4 | 0.1329 | 0.1439 | 0.0941 |  0.3070 | 20160 |  5040 |  48  |  132  |   2  \n",
      "   5 | 0.1349 | 0.1355 | 0.0900 |  0.3029 | 20160 |  5040 |  48  |  132  |   3  \n",
      "Mean | 0.1351 | 0.1357 | 0.0930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = sklearn.linear_model.ElasticNet\n",
    "print(f'Investigating performance of {model()} model...')\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses_copy[(responses_copy['fold_r'] != val_fold) & (responses_copy['fold_r'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses_copy[responses_copy['fold_r'] == val_fold]\n",
    "    df_test  = responses_copy[responses_copy['fold_r'] == 0].groupby(['soundscape','masker','smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['ground_truth_label'].values\n",
    "    Y_val = df_val['ground_truth_label'].values\n",
    "    Y_test = df_test['ground_truth_label'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[relevant_columns_enet].values \n",
    "    X_val = df_val[relevant_columns_enet].values\n",
    "    X_test = df_test[relevant_columns_enet].values        \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model().fit(X_train, Y_train)\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((X_LR.predict(X_train) - Y_train)**2)\n",
    "    MSE_val = np.mean((X_LR.predict(X_val) - Y_val)**2)\n",
    "    MSE_test = np.mean((X_LR.predict(X_test) - Y_test)**2)\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d}')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nmax_r: -0.008460668968782803\n",
      "M12500_0_r: -0.00134853022124568\n",
      "M10000_0_r: -0.0004837700048420805\n",
      "Savg_r: 0.0\n",
      "Smax_r: 0.0\n",
      "S05_r: 0.0\n",
      "S10_r: 0.0\n",
      "S20_r: -0.0\n",
      "S30_r: -0.0\n",
      "S40_r: -0.0\n",
      "S50_r: -0.0\n",
      "S60_r: -0.0\n",
      "S70_r: -0.0\n",
      "S80_r: 0.0\n",
      "S90_r: 0.0\n",
      "S95_r: 0.0\n",
      "Navg_r: -0.0\n",
      "Nrmc_r: -0.0\n",
      "N05_r: -0.0\n",
      "N10_r: -0.0\n",
      "N20_r: -0.0\n",
      "N30_r: -0.0\n",
      "N40_r: -0.0\n",
      "N50_r: -0.0\n",
      "N60_r: -0.0\n",
      "N70_r: -0.0\n",
      "N80_r: -0.0\n",
      "N90_r: -0.0\n",
      "N95_r: -0.0\n",
      "Favg_r: 0.0\n",
      "Fmax_r: -0.0\n",
      "F05_r: 0.0\n",
      "F10_r: 0.0\n",
      "F20_r: 0.0\n",
      "F30_r: 0.0\n",
      "F40_r: 0.0\n",
      "F50_r: 0.0\n",
      "F60_r: 0.0\n",
      "F70_r: 0.0\n",
      "F80_r: 0.0\n",
      "F90_r: 0.0\n",
      "F95_r: 0.0\n",
      "LAavg_r: -0.0\n",
      "LAmin_r: -0.0\n",
      "LAmax_r: -0.0\n",
      "LA05_r: -0.0\n",
      "LA10_r: -0.0\n",
      "LA20_r: -0.0\n",
      "LA30_r: -0.0\n",
      "LA40_r: -0.0\n",
      "LA50_r: -0.0\n",
      "LA60_r: -0.0\n",
      "LA70_r: -0.0\n",
      "LA80_r: -0.0\n",
      "LA90_r: -0.0\n",
      "LA95_r: -0.0\n",
      "LCavg_r: -0.0\n",
      "LCmin_r: -0.0\n",
      "LCmax_r: -0.0\n",
      "LC05_r: -0.0\n",
      "LC10_r: -0.0\n",
      "LC20_r: -0.0\n",
      "LC30_r: -0.0\n",
      "LC40_r: -0.0\n",
      "LC50_r: -0.0\n",
      "LC60_r: -0.0\n",
      "LC70_r: -0.0\n",
      "LC80_r: -0.0\n",
      "LC90_r: -0.0\n",
      "LC95_r: -0.0\n",
      "Ravg_r: -0.0\n",
      "Rmax_r: -0.0\n",
      "R05_r: -0.0\n",
      "R10_r: -0.0\n",
      "R20_r: -0.0\n",
      "R30_r: -0.0\n",
      "R40_r: -0.0\n",
      "R50_r: -0.0\n",
      "R60_r: -0.0\n",
      "R70_r: -0.0\n",
      "R80_r: -0.0\n",
      "R90_r: -0.0\n",
      "R95_r: -0.0\n",
      "Tgavg_r: -0.0\n",
      "Tavg_r: 0.0\n",
      "Tmax_r: -0.0\n",
      "T05_r: -0.0\n",
      "T10_r: -0.0\n",
      "T20_r: -0.0\n",
      "T30_r: 0.0\n",
      "T40_r: 0.0\n",
      "T50_r: 0.0\n",
      "T60_r: 0.0\n",
      "T70_r: 0.0\n",
      "T80_r: 0.0\n",
      "T90_r: 0.0\n",
      "T95_r: 0.0\n",
      "M00005_0_r: -0.0\n",
      "M00006_3_r: -0.0\n",
      "M00008_0_r: -0.0\n",
      "M00010_0_r: -0.0\n",
      "M00012_5_r: -0.0\n",
      "M00016_0_r: -0.0\n",
      "M00020_0_r: -0.0\n",
      "M00025_0_r: -0.0\n",
      "M00031_5_r: -0.0\n",
      "M00040_0_r: -0.0\n",
      "M00050_0_r: -0.0\n",
      "M00063_0_r: -0.0\n",
      "M00080_0_r: -0.0\n",
      "M00100_0_r: -0.0\n",
      "M00125_0_r: -0.0\n",
      "M00160_0_r: -0.0\n",
      "M00200_0_r: -0.0\n",
      "M00250_0_r: -0.0\n",
      "M00315_0_r: -0.0\n",
      "M00400_0_r: -0.0\n",
      "M00500_0_r: -0.0\n",
      "M00630_0_r: -0.0\n",
      "M00800_0_r: -0.0\n",
      "M01000_0_r: -0.0\n",
      "M01250_0_r: -0.0\n",
      "M01600_0_r: -0.0\n",
      "M02000_0_r: -0.0\n",
      "M02500_0_r: -0.0\n",
      "M03150_0_r: -0.0\n",
      "M04000_0_r: -0.0\n",
      "M05000_0_r: -0.0\n",
      "M06300_0_r: -0.0\n",
      "M08000_0_r: -0.0\n",
      "M16000_0_r: -0.0\n",
      "M20000_0_r: -0.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_LR is your linear regression model\n",
    "coefficients = X_LR.coef_\n",
    "\n",
    "# Pairing coefficients with feature names\n",
    "feature_importances = list(zip(relevant_columns_enet, coefficients))\n",
    "\n",
    "# Sorting feature importances by absolute value of coefficient\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Displaying feature importances\n",
    "for feature, importance in feature_importances:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVENTFULNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating performance of ElasticNet() model...\n",
      "     |    Mean squared error    |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "   1 | 0.1376 | 0.1297 | 0.0425 | -0.2748 | 20160 |  5040 |  48  |  132  |   4  \n",
      "   2 | 0.1373 | 0.1365 | 0.0463 | -0.2423 | 20160 |  5040 |  48  |  132  |   4  \n",
      "   3 | 0.1390 | 0.1247 | 0.0434 | -0.3780 | 20160 |  5040 |  48  |  132  |   6  \n",
      "   4 | 0.1352 | 0.1401 | 0.0439 | -0.3372 | 20160 |  5040 |  48  |  132  |   4  \n",
      "   5 | 0.1322 | 0.1546 | 0.0450 | -0.3418 | 20160 |  5040 |  48  |  132  |   4  \n",
      "Mean | 0.1363 | 0.1371 | 0.0442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = sklearn.linear_model.ElasticNet\n",
    "print(f'Investigating performance of {model()} model...')\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses_copy2[(responses_copy2['fold_r'] != val_fold) & (responses_copy2['fold_r'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses_copy2[responses_copy2['fold_r'] == val_fold]\n",
    "    df_test  = responses_copy2[responses_copy2['fold_r'] == 0].groupby(['soundscape','masker','smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['ground_truth_label'].values\n",
    "    Y_val = df_val['ground_truth_label'].values\n",
    "    Y_test = df_test['ground_truth_label'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[relevant_columns_enet].values \n",
    "    X_val = df_val[relevant_columns_enet].values\n",
    "    X_test = df_test[relevant_columns_enet].values        \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model().fit(X_train, Y_train)\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((X_LR.predict(X_train) - Y_train)**2)\n",
    "    MSE_val = np.mean((X_LR.predict(X_val) - Y_val)**2)\n",
    "    MSE_test = np.mean((X_LR.predict(X_test) - Y_test)**2)\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d}')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nmax_r: 0.009261245154877232\n",
      "M00630_0_r: 0.001858724441504498\n",
      "M00005_0_r: -0.0007956206191416494\n",
      "M00006_3_r: -0.00020145418858936152\n",
      "Savg_r: 0.0\n",
      "Smax_r: 0.0\n",
      "S05_r: 0.0\n",
      "S10_r: 0.0\n",
      "S20_r: 0.0\n",
      "S30_r: 0.0\n",
      "S40_r: 0.0\n",
      "S50_r: 0.0\n",
      "S60_r: 0.0\n",
      "S70_r: 0.0\n",
      "S80_r: 0.0\n",
      "S90_r: 0.0\n",
      "S95_r: 0.0\n",
      "Navg_r: 0.0\n",
      "Nrmc_r: 0.0\n",
      "N05_r: 0.0\n",
      "N10_r: 0.0\n",
      "N20_r: 0.0\n",
      "N30_r: 0.0\n",
      "N40_r: 0.0\n",
      "N50_r: 0.0\n",
      "N60_r: 0.0\n",
      "N70_r: 0.0\n",
      "N80_r: 0.0\n",
      "N90_r: 0.0\n",
      "N95_r: 0.0\n",
      "Favg_r: 0.0\n",
      "Fmax_r: 0.0\n",
      "F05_r: 0.0\n",
      "F10_r: 0.0\n",
      "F20_r: 0.0\n",
      "F30_r: 0.0\n",
      "F40_r: 0.0\n",
      "F50_r: 0.0\n",
      "F60_r: 0.0\n",
      "F70_r: 0.0\n",
      "F80_r: 0.0\n",
      "F90_r: 0.0\n",
      "F95_r: 0.0\n",
      "LAavg_r: 0.0\n",
      "LAmin_r: 0.0\n",
      "LAmax_r: 0.0\n",
      "LA05_r: 0.0\n",
      "LA10_r: 0.0\n",
      "LA20_r: 0.0\n",
      "LA30_r: 0.0\n",
      "LA40_r: 0.0\n",
      "LA50_r: 0.0\n",
      "LA60_r: 0.0\n",
      "LA70_r: 0.0\n",
      "LA80_r: 0.0\n",
      "LA90_r: 0.0\n",
      "LA95_r: 0.0\n",
      "LCavg_r: 0.0\n",
      "LCmin_r: 0.0\n",
      "LCmax_r: 0.0\n",
      "LC05_r: 0.0\n",
      "LC10_r: 0.0\n",
      "LC20_r: 0.0\n",
      "LC30_r: 0.0\n",
      "LC40_r: 0.0\n",
      "LC50_r: 0.0\n",
      "LC60_r: 0.0\n",
      "LC70_r: 0.0\n",
      "LC80_r: 0.0\n",
      "LC90_r: 0.0\n",
      "LC95_r: 0.0\n",
      "Ravg_r: 0.0\n",
      "Rmax_r: 0.0\n",
      "R05_r: 0.0\n",
      "R10_r: 0.0\n",
      "R20_r: 0.0\n",
      "R30_r: 0.0\n",
      "R40_r: 0.0\n",
      "R50_r: 0.0\n",
      "R60_r: 0.0\n",
      "R70_r: 0.0\n",
      "R80_r: 0.0\n",
      "R90_r: 0.0\n",
      "R95_r: 0.0\n",
      "Tgavg_r: 0.0\n",
      "Tavg_r: 0.0\n",
      "Tmax_r: 0.0\n",
      "T05_r: 0.0\n",
      "T10_r: 0.0\n",
      "T20_r: 0.0\n",
      "T30_r: 0.0\n",
      "T40_r: 0.0\n",
      "T50_r: 0.0\n",
      "T60_r: 0.0\n",
      "T70_r: 0.0\n",
      "T80_r: 0.0\n",
      "T90_r: 0.0\n",
      "T95_r: 0.0\n",
      "M00008_0_r: -0.0\n",
      "M00010_0_r: -0.0\n",
      "M00012_5_r: -0.0\n",
      "M00016_0_r: -0.0\n",
      "M00020_0_r: -0.0\n",
      "M00025_0_r: 0.0\n",
      "M00031_5_r: 0.0\n",
      "M00040_0_r: 0.0\n",
      "M00050_0_r: 0.0\n",
      "M00063_0_r: -0.0\n",
      "M00080_0_r: -0.0\n",
      "M00100_0_r: 0.0\n",
      "M00125_0_r: 0.0\n",
      "M00160_0_r: 0.0\n",
      "M00200_0_r: 0.0\n",
      "M00250_0_r: 0.0\n",
      "M00315_0_r: 0.0\n",
      "M00400_0_r: 0.0\n",
      "M00500_0_r: 0.0\n",
      "M00800_0_r: 0.0\n",
      "M01000_0_r: 0.0\n",
      "M01250_0_r: 0.0\n",
      "M01600_0_r: 0.0\n",
      "M02000_0_r: 0.0\n",
      "M02500_0_r: 0.0\n",
      "M03150_0_r: 0.0\n",
      "M04000_0_r: 0.0\n",
      "M05000_0_r: 0.0\n",
      "M06300_0_r: 0.0\n",
      "M08000_0_r: 0.0\n",
      "M10000_0_r: 0.0\n",
      "M12500_0_r: 0.0\n",
      "M16000_0_r: 0.0\n",
      "M20000_0_r: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_LR is your linear regression model\n",
    "coefficients = X_LR.coef_\n",
    "\n",
    "# Pairing coefficients with feature names\n",
    "feature_importances = list(zip(relevant_columns_enet, coefficients))\n",
    "\n",
    "# Sorting feature importances by absolute value of coefficient\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Displaying feature importances\n",
    "for feature, importance in feature_importances:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which sound source is present in a soundscape can provide very usefull and direct information about the pleasantness and eventfulness of a sound scene. Therefore, we are introducing the masker column as an additional input feature to test any improvements in the predictions of the elastic models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat process with responses_maskers_onehot.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.read_csv(os.path.join('..','data','responses_maskers_onehot.csv'), dtype = {'participant':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pleasantness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['pleasant', 'eventful', 'chaotic', 'vibrant', 'uneventful', 'calm', 'annoying', 'monotonous'] # Define attributes to extract from dataframes\n",
    "ISOPl_weights = [1,0,-np.sqrt(2)/2,np.sqrt(2)/2, 0, np.sqrt(2)/2,-1,-np.sqrt(2)/2] # Define weights for each attribute in attributes in computation of ISO Pleasantness\n",
    "\n",
    "responses_copy = responses.copy() \n",
    "responses_copy['ground_truth_label'] = ((responses[attributes] * ISOPl_weights).sum(axis=1)/(4+np.sqrt(32))).values # These are normalised ISO Pleasantness values (in [-1,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eventfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['pleasant', 'eventful', 'chaotic', 'vibrant', 'uneventful', 'calm', 'annoying', 'monotonous'] # Define attributes to extract from dataframes\n",
    "ISOEv_weights = [0,1,np.sqrt(2)/2,np.sqrt(2)/2, -1, -np.sqrt(2)/2,0,-np.sqrt(2)/2] # Define weights for each attribute in attributes in computation of ISO Pleasantness\n",
    "\n",
    "responses_copy2 = responses.copy() \n",
    "responses_copy2['ground_truth_label'] = ((responses[attributes] * ISOEv_weights).sum(axis=1)/(4+np.sqrt(32))).values # These are normalised ISO Pleasantness values (in [-1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns_enet = ['Savg_r','Smax_r','S05_r','S10_r','S20_r','S30_r','S40_r','S50_r','S60_r','S70_r','S80_r','S90_r','S95_r',\n",
    "                         'Navg_r','Nrmc_r','Nmax_r','N05_r','N10_r','N20_r','N30_r','N40_r','N50_r','N60_r','N70_r','N80_r','N90_r','N95_r',\n",
    "                         'Favg_r','Fmax_r','F05_r','F10_r','F20_r','F30_r','F40_r','F50_r','F60_r','F70_r','F80_r','F90_r','F95_r',\n",
    "                         'LAavg_r','LAmin_r','LAmax_r','LA05_r','LA10_r','LA20_r','LA30_r','LA40_r','LA50_r','LA60_r','LA70_r','LA80_r','LA90_r','LA95_r',\n",
    "                         'LCavg_r','LCmin_r','LCmax_r','LC05_r','LC10_r','LC20_r','LC30_r','LC40_r','LC50_r','LC60_r','LC70_r','LC80_r','LC90_r','LC95_r',\n",
    "                         'Ravg_r','Rmax_r','R05_r','R10_r','R20_r','R30_r','R40_r','R50_r','R60_r','R70_r','R80_r','R90_r','R95_r',\n",
    "                         'Tgavg_r','Tavg_r','Tmax_r','T05_r','T10_r','T20_r','T30_r','T40_r','T50_r','T60_r','T70_r','T80_r','T90_r','T95_r',\n",
    "                         'M00005_0_r','M00006_3_r','M00008_0_r','M00010_0_r','M00012_5_r','M00016_0_r','M00020_0_r','M00025_0_r','M00031_5_r','M00040_0_r',\n",
    "                         'M00050_0_r','M00063_0_r','M00080_0_r','M00100_0_r','M00125_0_r','M00160_0_r','M00200_0_r','M00250_0_r','M00315_0_r','M00400_0_r',\n",
    "                         'M00500_0_r','M00630_0_r','M00800_0_r','M01000_0_r','M01250_0_r','M01600_0_r','M02000_0_r','M02500_0_r','M03150_0_r','M04000_0_r',\n",
    "                         'M05000_0_r','M06300_0_r','M08000_0_r','M10000_0_r','M12500_0_r','M16000_0_r','M20000_0_r', 'masker_bird' , 'masker_construction',  \n",
    "                         'masker_silence',  'masker_traffic','masker_water',  'masker_wind']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pleasantness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating performance of ElasticNet() model...\n",
      "     |    Mean squared error    |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "   1 | 0.1360 | 0.1321 | 0.0912 |  0.3074 | 20160 |  5040 |  48  |  138  |   3  \n",
      "   2 | 0.1368 | 0.1284 | 0.0954 |  0.3105 | 20160 |  5040 |  48  |  138  |   2  \n",
      "   3 | 0.1351 | 0.1384 | 0.0941 |  0.2898 | 20160 |  5040 |  48  |  138  |   2  \n",
      "   4 | 0.1329 | 0.1439 | 0.0941 |  0.3070 | 20160 |  5040 |  48  |  138  |   2  \n",
      "   5 | 0.1349 | 0.1355 | 0.0900 |  0.3029 | 20160 |  5040 |  48  |  138  |   3  \n",
      "Mean | 0.1351 | 0.1357 | 0.0930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = sklearn.linear_model.ElasticNet\n",
    "print(f'Investigating performance of {model()} model...')\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses_copy[(responses_copy['fold_r'] != val_fold) & (responses_copy['fold_r'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses_copy[responses_copy['fold_r'] == val_fold]\n",
    "    df_test  = responses_copy[responses_copy['fold_r'] == 0].groupby(['soundscape','masker','smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['ground_truth_label'].values\n",
    "    Y_val = df_val['ground_truth_label'].values\n",
    "    Y_test = df_test['ground_truth_label'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[relevant_columns_enet].values \n",
    "    X_val = df_val[relevant_columns_enet].values\n",
    "    X_test = df_test[relevant_columns_enet].values        \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model().fit(X_train, Y_train)\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((X_LR.predict(X_train) - Y_train)**2)\n",
    "    MSE_val = np.mean((X_LR.predict(X_val) - Y_val)**2)\n",
    "    MSE_test = np.mean((X_LR.predict(X_test) - Y_test)**2)\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d}')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nmax_r: -0.008460668968782803\n",
      "M12500_0_r: -0.00134853022124568\n",
      "M10000_0_r: -0.0004837700048420805\n",
      "Savg_r: 0.0\n",
      "Smax_r: 0.0\n",
      "S05_r: 0.0\n",
      "S10_r: 0.0\n",
      "S20_r: -0.0\n",
      "S30_r: -0.0\n",
      "S40_r: -0.0\n",
      "S50_r: -0.0\n",
      "S60_r: -0.0\n",
      "S70_r: -0.0\n",
      "S80_r: 0.0\n",
      "S90_r: 0.0\n",
      "S95_r: 0.0\n",
      "Navg_r: -0.0\n",
      "Nrmc_r: -0.0\n",
      "N05_r: -0.0\n",
      "N10_r: -0.0\n",
      "N20_r: -0.0\n",
      "N30_r: -0.0\n",
      "N40_r: -0.0\n",
      "N50_r: -0.0\n",
      "N60_r: -0.0\n",
      "N70_r: -0.0\n",
      "N80_r: -0.0\n",
      "N90_r: -0.0\n",
      "N95_r: -0.0\n",
      "Favg_r: 0.0\n",
      "Fmax_r: -0.0\n",
      "F05_r: 0.0\n",
      "F10_r: 0.0\n",
      "F20_r: 0.0\n",
      "F30_r: 0.0\n",
      "F40_r: 0.0\n",
      "F50_r: 0.0\n",
      "F60_r: 0.0\n",
      "F70_r: 0.0\n",
      "F80_r: 0.0\n",
      "F90_r: 0.0\n",
      "F95_r: 0.0\n",
      "LAavg_r: -0.0\n",
      "LAmin_r: -0.0\n",
      "LAmax_r: -0.0\n",
      "LA05_r: -0.0\n",
      "LA10_r: -0.0\n",
      "LA20_r: -0.0\n",
      "LA30_r: -0.0\n",
      "LA40_r: -0.0\n",
      "LA50_r: -0.0\n",
      "LA60_r: -0.0\n",
      "LA70_r: -0.0\n",
      "LA80_r: -0.0\n",
      "LA90_r: -0.0\n",
      "LA95_r: -0.0\n",
      "LCavg_r: -0.0\n",
      "LCmin_r: -0.0\n",
      "LCmax_r: -0.0\n",
      "LC05_r: -0.0\n",
      "LC10_r: -0.0\n",
      "LC20_r: -0.0\n",
      "LC30_r: -0.0\n",
      "LC40_r: -0.0\n",
      "LC50_r: -0.0\n",
      "LC60_r: -0.0\n",
      "LC70_r: -0.0\n",
      "LC80_r: -0.0\n",
      "LC90_r: -0.0\n",
      "LC95_r: -0.0\n",
      "Ravg_r: -0.0\n",
      "Rmax_r: -0.0\n",
      "R05_r: -0.0\n",
      "R10_r: -0.0\n",
      "R20_r: -0.0\n",
      "R30_r: -0.0\n",
      "R40_r: -0.0\n",
      "R50_r: -0.0\n",
      "R60_r: -0.0\n",
      "R70_r: -0.0\n",
      "R80_r: -0.0\n",
      "R90_r: -0.0\n",
      "R95_r: -0.0\n",
      "Tgavg_r: -0.0\n",
      "Tavg_r: 0.0\n",
      "Tmax_r: -0.0\n",
      "T05_r: -0.0\n",
      "T10_r: -0.0\n",
      "T20_r: -0.0\n",
      "T30_r: 0.0\n",
      "T40_r: 0.0\n",
      "T50_r: 0.0\n",
      "T60_r: 0.0\n",
      "T70_r: 0.0\n",
      "T80_r: 0.0\n",
      "T90_r: 0.0\n",
      "T95_r: 0.0\n",
      "M00005_0_r: -0.0\n",
      "M00006_3_r: -0.0\n",
      "M00008_0_r: -0.0\n",
      "M00010_0_r: -0.0\n",
      "M00012_5_r: -0.0\n",
      "M00016_0_r: -0.0\n",
      "M00020_0_r: -0.0\n",
      "M00025_0_r: -0.0\n",
      "M00031_5_r: -0.0\n",
      "M00040_0_r: -0.0\n",
      "M00050_0_r: -0.0\n",
      "M00063_0_r: -0.0\n",
      "M00080_0_r: -0.0\n",
      "M00100_0_r: -0.0\n",
      "M00125_0_r: -0.0\n",
      "M00160_0_r: -0.0\n",
      "M00200_0_r: -0.0\n",
      "M00250_0_r: -0.0\n",
      "M00315_0_r: -0.0\n",
      "M00400_0_r: -0.0\n",
      "M00500_0_r: -0.0\n",
      "M00630_0_r: -0.0\n",
      "M00800_0_r: -0.0\n",
      "M01000_0_r: -0.0\n",
      "M01250_0_r: -0.0\n",
      "M01600_0_r: -0.0\n",
      "M02000_0_r: -0.0\n",
      "M02500_0_r: -0.0\n",
      "M03150_0_r: -0.0\n",
      "M04000_0_r: -0.0\n",
      "M05000_0_r: -0.0\n",
      "M06300_0_r: -0.0\n",
      "M08000_0_r: -0.0\n",
      "M16000_0_r: -0.0\n",
      "M20000_0_r: -0.0\n",
      "masker_bird: 0.0\n",
      "masker_construction: -0.0\n",
      "masker_silence: 0.0\n",
      "masker_traffic: -0.0\n",
      "masker_water: 0.0\n",
      "masker_wind: -0.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_LR is your linear regression model\n",
    "coefficients = X_LR.coef_\n",
    "\n",
    "# Pairing coefficients with feature names\n",
    "feature_importances = list(zip(relevant_columns_enet, coefficients))\n",
    "\n",
    "# Sorting feature importances by absolute value of coefficient\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Displaying feature importances\n",
    "for feature, importance in feature_importances:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eventfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating performance of ElasticNet() model...\n",
      "     |    Mean squared error    |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "   1 | 0.1376 | 0.1297 | 0.0425 | -0.2748 | 20160 |  5040 |  48  |  138  |   4  \n",
      "   2 | 0.1373 | 0.1365 | 0.0463 | -0.2423 | 20160 |  5040 |  48  |  138  |   4  \n",
      "   3 | 0.1390 | 0.1247 | 0.0434 | -0.3780 | 20160 |  5040 |  48  |  138  |   6  \n",
      "   4 | 0.1352 | 0.1401 | 0.0439 | -0.3372 | 20160 |  5040 |  48  |  138  |   4  \n",
      "   5 | 0.1322 | 0.1546 | 0.0450 | -0.3418 | 20160 |  5040 |  48  |  138  |   4  \n",
      "Mean | 0.1363 | 0.1371 | 0.0442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = sklearn.linear_model.ElasticNet\n",
    "print(f'Investigating performance of {model()} model...')\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses_copy2[(responses_copy2['fold_r'] != val_fold) & (responses_copy2['fold_r'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses_copy2[responses_copy2['fold_r'] == val_fold]\n",
    "    df_test  = responses_copy2[responses_copy2['fold_r'] == 0].groupby(['soundscape','masker','smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['ground_truth_label'].values\n",
    "    Y_val = df_val['ground_truth_label'].values\n",
    "    Y_test = df_test['ground_truth_label'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[relevant_columns_enet].values \n",
    "    X_val = df_val[relevant_columns_enet].values\n",
    "    X_test = df_test[relevant_columns_enet].values        \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model().fit(X_train, Y_train)\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((X_LR.predict(X_train) - Y_train)**2)\n",
    "    MSE_val = np.mean((X_LR.predict(X_val) - Y_val)**2)\n",
    "    MSE_test = np.mean((X_LR.predict(X_test) - Y_test)**2)\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d}')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nmax_r: 0.009261245154877232\n",
      "M00630_0_r: 0.001858724441504498\n",
      "M00005_0_r: -0.0007956206191416494\n",
      "M00006_3_r: -0.00020145418858936152\n",
      "Savg_r: 0.0\n",
      "Smax_r: 0.0\n",
      "S05_r: 0.0\n",
      "S10_r: 0.0\n",
      "S20_r: 0.0\n",
      "S30_r: 0.0\n",
      "S40_r: 0.0\n",
      "S50_r: 0.0\n",
      "S60_r: 0.0\n",
      "S70_r: 0.0\n",
      "S80_r: 0.0\n",
      "S90_r: 0.0\n",
      "S95_r: 0.0\n",
      "Navg_r: 0.0\n",
      "Nrmc_r: 0.0\n",
      "N05_r: 0.0\n",
      "N10_r: 0.0\n",
      "N20_r: 0.0\n",
      "N30_r: 0.0\n",
      "N40_r: 0.0\n",
      "N50_r: 0.0\n",
      "N60_r: 0.0\n",
      "N70_r: 0.0\n",
      "N80_r: 0.0\n",
      "N90_r: 0.0\n",
      "N95_r: 0.0\n",
      "Favg_r: 0.0\n",
      "Fmax_r: 0.0\n",
      "F05_r: 0.0\n",
      "F10_r: 0.0\n",
      "F20_r: 0.0\n",
      "F30_r: 0.0\n",
      "F40_r: 0.0\n",
      "F50_r: 0.0\n",
      "F60_r: 0.0\n",
      "F70_r: 0.0\n",
      "F80_r: 0.0\n",
      "F90_r: 0.0\n",
      "F95_r: 0.0\n",
      "LAavg_r: 0.0\n",
      "LAmin_r: 0.0\n",
      "LAmax_r: 0.0\n",
      "LA05_r: 0.0\n",
      "LA10_r: 0.0\n",
      "LA20_r: 0.0\n",
      "LA30_r: 0.0\n",
      "LA40_r: 0.0\n",
      "LA50_r: 0.0\n",
      "LA60_r: 0.0\n",
      "LA70_r: 0.0\n",
      "LA80_r: 0.0\n",
      "LA90_r: 0.0\n",
      "LA95_r: 0.0\n",
      "LCavg_r: 0.0\n",
      "LCmin_r: 0.0\n",
      "LCmax_r: 0.0\n",
      "LC05_r: 0.0\n",
      "LC10_r: 0.0\n",
      "LC20_r: 0.0\n",
      "LC30_r: 0.0\n",
      "LC40_r: 0.0\n",
      "LC50_r: 0.0\n",
      "LC60_r: 0.0\n",
      "LC70_r: 0.0\n",
      "LC80_r: 0.0\n",
      "LC90_r: 0.0\n",
      "LC95_r: 0.0\n",
      "Ravg_r: 0.0\n",
      "Rmax_r: 0.0\n",
      "R05_r: 0.0\n",
      "R10_r: 0.0\n",
      "R20_r: 0.0\n",
      "R30_r: 0.0\n",
      "R40_r: 0.0\n",
      "R50_r: 0.0\n",
      "R60_r: 0.0\n",
      "R70_r: 0.0\n",
      "R80_r: 0.0\n",
      "R90_r: 0.0\n",
      "R95_r: 0.0\n",
      "Tgavg_r: 0.0\n",
      "Tavg_r: 0.0\n",
      "Tmax_r: 0.0\n",
      "T05_r: 0.0\n",
      "T10_r: 0.0\n",
      "T20_r: 0.0\n",
      "T30_r: 0.0\n",
      "T40_r: 0.0\n",
      "T50_r: 0.0\n",
      "T60_r: 0.0\n",
      "T70_r: 0.0\n",
      "T80_r: 0.0\n",
      "T90_r: 0.0\n",
      "T95_r: 0.0\n",
      "M00008_0_r: -0.0\n",
      "M00010_0_r: -0.0\n",
      "M00012_5_r: -0.0\n",
      "M00016_0_r: -0.0\n",
      "M00020_0_r: -0.0\n",
      "M00025_0_r: 0.0\n",
      "M00031_5_r: 0.0\n",
      "M00040_0_r: 0.0\n",
      "M00050_0_r: 0.0\n",
      "M00063_0_r: -0.0\n",
      "M00080_0_r: -0.0\n",
      "M00100_0_r: 0.0\n",
      "M00125_0_r: 0.0\n",
      "M00160_0_r: 0.0\n",
      "M00200_0_r: 0.0\n",
      "M00250_0_r: 0.0\n",
      "M00315_0_r: 0.0\n",
      "M00400_0_r: 0.0\n",
      "M00500_0_r: 0.0\n",
      "M00800_0_r: 0.0\n",
      "M01000_0_r: 0.0\n",
      "M01250_0_r: 0.0\n",
      "M01600_0_r: 0.0\n",
      "M02000_0_r: 0.0\n",
      "M02500_0_r: 0.0\n",
      "M03150_0_r: 0.0\n",
      "M04000_0_r: 0.0\n",
      "M05000_0_r: 0.0\n",
      "M06300_0_r: 0.0\n",
      "M08000_0_r: 0.0\n",
      "M10000_0_r: 0.0\n",
      "M12500_0_r: 0.0\n",
      "M16000_0_r: 0.0\n",
      "M20000_0_r: 0.0\n",
      "masker_bird: 0.0\n",
      "masker_construction: 0.0\n",
      "masker_silence: -0.0\n",
      "masker_traffic: 0.0\n",
      "masker_water: -0.0\n",
      "masker_wind: -0.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_LR is your linear regression model\n",
    "coefficients = X_LR.coef_\n",
    "\n",
    "# Pairing coefficients with feature names\n",
    "feature_importances = list(zip(relevant_columns_enet, coefficients))\n",
    "\n",
    "# Sorting feature importances by absolute value of coefficient\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Displaying feature importances\n",
    "for feature, importance in feature_importances:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the maskers as features didn't provide any improvements to the elastic net linear regression model. In fact, we can see which features are employed or perform a more important role are only :\n",
    "For pleasantness\n",
    "- Nmax_r: -0.008460668968782803\n",
    "- M12500_0_r: -0.00134853022124568\n",
    "- M10000_0_r: -0.0004837700048420805\n",
    "For eventfulness\n",
    "- Nmax_r: 0.009261245154877232\n",
    "- M00630_0_r: 0.001858724441504498\n",
    "- M00005_0_r: -0.0007956206191416494\n",
    "- M00006_3_r: -0.00020145418858936152\n",
    "Meaning that only features related to loudness (Nmax_r) and to frequency energy distribution (M...) play a role in the model. The coefficients indicate the contribution of each feature to the model's predictions. Here's how to interpret the results:\n",
    "- Positive Coefficient: A positive coefficient (e.g., Savg_r: 0.123) means that as the value of the feature increases, the predicted target variable is expected to increase by the coefficient value.\n",
    "- Negative Coefficient: A negative coefficient (e.g., Nmax_r: -0.008) means that as the value of the feature increases, the predicted target variable is expected to decrease by the absolute value of the coefficient.\n",
    "- Coefficient Magnitude: The magnitude (absolute value) of the coefficient indicates the strength of the effect. Larger magnitudes imply a stronger impact on the predictions.\n",
    "\n",
    "Then, it makes sense that as loudness increases, pleasantness decreases but eventfulness increases. It also makes sense that pleasantness is more influenced by high frequency bands content (they can be more annoying) and eventfulness with low frequency content (?why)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "araus-mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
