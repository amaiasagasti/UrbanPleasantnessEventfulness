{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from SoundLights.dataset.features_groups import  general_info, ARAUS_features, Freesound_features, mix_features, masker_features\n",
    "from SoundLights.models.models_functions import clip, normalize_columns, normalize_columns_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_models(dataframe, features_evaluated, masker_transform:str=\"None\", maskers_gain: float = 1):\n",
    "\n",
    "    # Drop string columns\n",
    "    \"\"\"dataframe = dataframe.drop(\"info.file\", axis=1)\n",
    "    dataframe = dataframe.drop(\"info.participant\", axis=1)\"\"\"\n",
    "\n",
    "    # Maskers colum, increase values\n",
    "    if(masker_transform==\"-1,1\"):\n",
    "        dataframe[\"info.masker_bird\"] = (dataframe[\"info.masker_bird\"]*2-1) * maskers_gain\n",
    "        dataframe[\"info.masker_construction\"] = (\n",
    "            (dataframe[\"info.masker_construction\"]*2-1) * maskers_gain\n",
    "        )\n",
    "        dataframe[\"info.masker_traffic\"] = (dataframe[\"info.masker_traffic\"]*2-1) * maskers_gain\n",
    "        dataframe[\"info.masker_silence\"] = (dataframe[\"info.masker_silence\"]*2-1) * maskers_gain\n",
    "        dataframe[\"info.masker_water\"] = (dataframe[\"info.masker_water\"]*2-1) * maskers_gain\n",
    "        dataframe[\"info.masker_wind\"] = (dataframe[\"info.masker_wind\"]*2-1) * maskers_gain\n",
    "    else:\n",
    "        dataframe[\"info.masker_bird\"] = (dataframe[\"info.masker_bird\"]) * maskers_gain\n",
    "        dataframe[\"info.masker_construction\"] = (\n",
    "            dataframe[\"info.masker_construction\"] * maskers_gain\n",
    "        )\n",
    "        dataframe[\"info.masker_traffic\"] = dataframe[\"info.masker_traffic\"] * maskers_gain\n",
    "        dataframe[\"info.masker_silence\"] = dataframe[\"info.masker_silence\"] * maskers_gain\n",
    "        dataframe[\"info.masker_water\"] = dataframe[\"info.masker_water\"] * maskers_gain\n",
    "        dataframe[\"info.masker_wind\"] = dataframe[\"info.masker_wind\"] * maskers_gain\n",
    "\n",
    "    # For fold 0, group data\n",
    "    dataframe_fold0 = dataframe[dataframe[\"info.fold\"] == 0]\n",
    "    # Drop string columns\n",
    "    dataframe_fold0 = dataframe_fold0.drop(\"info.file\", axis=1)\n",
    "    dataframe_fold0 = dataframe_fold0.drop(\"info.participant\", axis=1)\n",
    "    dataframe_fold0 = dataframe_fold0.groupby(\n",
    "        [\"info.soundscape\", \"info.masker\", \"info.smr\"]\n",
    "    ).mean()  # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "    dataframe_filtered = dataframe[\n",
    "        dataframe[\"info.fold\"] != 0\n",
    "    ]  # Filter rows where 'fold' column is not equal to 0\n",
    "    dataframe = pd.concat(\n",
    "        [dataframe_fold0, dataframe_filtered], ignore_index=True\n",
    "    )  # Join together\n",
    "\n",
    "    # Drop columns with all equal values or std=0\n",
    "    std = np.std(dataframe[features_evaluated], axis=0)\n",
    "    columns_to_mantain_arg = np.where(std >= 0.00001)[0]\n",
    "    columns_to_drop_arg = np.where(std <= 0.00001)[0]\n",
    "    columns_to_mantain = [features_evaluated[i] for i in columns_to_mantain_arg]\n",
    "    columns_to_drop = [features_evaluated[i] for i in columns_to_drop_arg]\n",
    "    # print(features_evaluated[np.where(std == 0)[0]])\n",
    "    dataframe.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "    return dataframe, columns_to_mantain\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPARE DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input general dataframe (folds 0,1,2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25440 entries, 0 to 25439\n",
      "Columns: 285 entries, CLAP to freesound.rhythm.bpm\n",
      "dtypes: float64(261), int64(19), object(5)\n",
      "memory usage: 55.3+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' responses_Freesound, features=prepare_data_models(responses_Freesound, Freesound_features)\\nprint(responses_Freesound) '"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('../data/main_files/SoundLights_complete.csv')\n",
    "\n",
    "print(df.info())\n",
    "\"\"\" responses_Freesound, features=prepare_data_models(responses_Freesound, Freesound_features)\n",
    "print(responses_Freesound) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ARAUS=df[general_info+ARAUS_features]\n",
    "df_Freesound=df[general_info+Freesound_features]\n",
    "df_clap=df[general_info+[\"CLAP\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input dataframe of new audios to validate (fold 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ARAUS.sharpness.avg', 'ARAUS.sharpness.max', 'ARAUS.sharpness.p05',\n",
      "       'ARAUS.sharpness.p10', 'ARAUS.sharpness.p20', 'ARAUS.sharpness.p30',\n",
      "       'ARAUS.sharpness.p40', 'ARAUS.sharpness.p50', 'ARAUS.sharpness.p60',\n",
      "       'ARAUS.sharpness.p70',\n",
      "       ...\n",
      "       'freesound.rhythm.bpm', 'CLAP', 'info.P_ground_truth',\n",
      "       'info.E_ground_truth', 'info.masker_bird', 'info.masker_construction',\n",
      "       'info.masker_silence', 'info.masker_traffic', 'info.masker_water',\n",
      "       'info.masker_wind'],\n",
      "      dtype='object', length=265)\n"
     ]
    }
   ],
   "source": [
    "df_real= pd.read_csv('../data/main_files/SoundLights_fold6.csv')\n",
    "only_important_features=ARAUS_features+Freesound_features+[\"CLAP\", \"info.P_ground_truth\", \"info.E_ground_truth\"]+[\"info.masker_bird\",\"info.masker_construction\",\"info.masker_silence\",\"info.masker_traffic\", \"info.masker_water\",\"info.masker_wind\"]\n",
    "df_fold6=df_real[only_important_features]\n",
    "\n",
    "print(df_fold6.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/rtp1hhtx2tgcw5x4mgt4m00m0000gn/T/ipykernel_12344/1862752673.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fold6[\"info.masker_bird\"]=df_fold6[\"info.masker_bird\"]*masker_gain\n",
      "/var/folders/87/rtp1hhtx2tgcw5x4mgt4m00m0000gn/T/ipykernel_12344/1862752673.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fold6[\"info.masker_construction\"]=df_fold6[\"info.masker_construction\"]*masker_gain\n",
      "/var/folders/87/rtp1hhtx2tgcw5x4mgt4m00m0000gn/T/ipykernel_12344/1862752673.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fold6[\"info.masker_silence\"]=df_fold6[\"info.masker_silence\"]*masker_gain\n",
      "/var/folders/87/rtp1hhtx2tgcw5x4mgt4m00m0000gn/T/ipykernel_12344/1862752673.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fold6[\"info.masker_traffic\"]=df_fold6[\"info.masker_traffic\"]*masker_gain\n",
      "/var/folders/87/rtp1hhtx2tgcw5x4mgt4m00m0000gn/T/ipykernel_12344/1862752673.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fold6[\"info.masker_water\"]=df_fold6[\"info.masker_water\"]*masker_gain\n",
      "/var/folders/87/rtp1hhtx2tgcw5x4mgt4m00m0000gn/T/ipykernel_12344/1862752673.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fold6[\"info.masker_wind\"]=df_fold6[\"info.masker_wind\"]*masker_gain\n"
     ]
    }
   ],
   "source": [
    "masker_gain=20\n",
    "masker_transform=\"None\"\n",
    "df_to_use,features_to_use=prepare_data_models(df_ARAUS.copy(), ARAUS_features,masker_transform, masker_gain)\n",
    "features_to_use=features_to_use+[\"info.masker_bird\",\"info.masker_construction\",\"info.masker_silence\",\"info.masker_traffic\", \"info.masker_water\",\"info.masker_wind\"]\n",
    "\n",
    "if(masker_transform==\"-1,1\"):\n",
    "    df_fold6[\"info.masker_bird\"]=(df_fold6[\"info.masker_bird\"]*2-1)*masker_gain\n",
    "    df_fold6[\"info.masker_construction\"]=(df_fold6[\"info.masker_construction\"]*2-1)*masker_gain\n",
    "    df_fold6[\"info.masker_silence\"]=(df_fold6[\"info.masker_silence\"]*2-1)*masker_gain\n",
    "    df_fold6[\"info.masker_traffic\"]=(df_fold6[\"info.masker_traffic\"]*2-1)*masker_gain\n",
    "    df_fold6[\"info.masker_water\"]=(df_fold6[\"info.masker_water\"]*2-1)*masker_gain\n",
    "    df_fold6[\"info.masker_wind\"]=(df_fold6[\"info.masker_wind\"]*2-1)*masker_gain\n",
    "else:\n",
    "    df_fold6[\"info.masker_bird\"]=df_fold6[\"info.masker_bird\"]*masker_gain\n",
    "    df_fold6[\"info.masker_construction\"]=df_fold6[\"info.masker_construction\"]*masker_gain\n",
    "    df_fold6[\"info.masker_silence\"]=df_fold6[\"info.masker_silence\"]*masker_gain\n",
    "    df_fold6[\"info.masker_traffic\"]=df_fold6[\"info.masker_traffic\"]*masker_gain\n",
    "    df_fold6[\"info.masker_water\"]=df_fold6[\"info.masker_water\"]*masker_gain\n",
    "    df_fold6[\"info.masker_wind\"]=df_fold6[\"info.masker_wind\"]*masker_gain\n",
    "#print(df_to_use[[\"info.masker_bird\",\"info.masker_construction\",\"info.masker_silence\",\"info.masker_traffic\", \"info.masker_water\",\"info.masker_wind\"]])\n",
    "#features_to_use=ARAUS_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |         Mean squared error        |             Mean  error            |\n",
      "Fold |--------+--------+--------+--------|--------+--------+--------|---------|\n",
      "     | Train  |   Val  |  Test  |Test(f6)| Train  |   Val  |  Test  | Test(f6)|\n",
      "-----+--------+--------+--------+--------+--------+--------+--------+----------\n",
      "Parameters  0.1 0.5\n",
      "Mean | 0.1239 | 0.1264 | 0.0822 | 0.1594 | 0.2863 | 0.2892 | 0.2486 | 0.3150 |\n",
      "Parameters  0.2 0.5\n",
      "Mean | 0.1250 | 0.1272 | 0.0809 | 0.1229 | 0.2882 | 0.2907 | 0.2445 | 0.2820 |\n",
      "Parameters  0.3 0.5\n",
      "Mean | 0.1266 | 0.1287 | 0.0809 | 0.0960 | 0.2907 | 0.2930 | 0.2419 | 0.2574 |\n",
      "Parameters  0.4 0.5\n",
      "Mean | 0.1286 | 0.1304 | 0.0815 | 0.0754 | 0.2936 | 0.2957 | 0.2406 | 0.2358 |\n",
      "Parameters  0.5 0.5\n",
      "Mean | 0.1307 | 0.1325 | 0.0825 | 0.0621 | 0.2966 | 0.2987 | 0.2401 | 0.2150 |\n",
      "Parameters  0.6 0.5\n",
      "Mean | 0.1330 | 0.1345 | 0.0837 | 0.0571 | 0.2997 | 0.3014 | 0.2402 | 0.2037 |\n",
      "Parameters  0.7 0.5\n",
      "Mean | 0.1354 | 0.1364 | 0.0852 | 0.0578 | 0.3028 | 0.3039 | 0.2415 | 0.2008 |\n",
      "Parameters  0.8 0.5\n",
      "Mean | 0.1371 | 0.1378 | 0.0866 | 0.0605 | 0.3051 | 0.3059 | 0.2434 | 0.2041 |\n",
      "Parameters  0.9 0.5\n",
      "Mean | 0.1384 | 0.1391 | 0.0880 | 0.0626 | 0.3068 | 0.3076 | 0.2454 | 0.2076 |\n",
      "Parameters  1 0.5\n",
      "Mean | 0.1397 | 0.1403 | 0.0896 | 0.0643 | 0.3085 | 0.3092 | 0.2478 | 0.2108 |\n",
      "Best parameters were  (0.7, 0.5)  giving a mean of  0.22113783618373212\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "# Suppress ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "# Define your ElasticNet model with specific hyperparameters\n",
    "alpha = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1] \n",
    "l1_ratio = 0.5\n",
    "print('     |         Mean squared error        |             Mean  error            |')\n",
    "print('Fold |--------+--------+--------+--------|--------+--------+--------|---------|')\n",
    "print('     | Train  |   Val  |  Test  |Test(f6)| Train  |   Val  |  Test  | Test(f6)|')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+--------+----------')\n",
    "\n",
    "\n",
    "prev_mean=9999\n",
    "for value in alpha:\n",
    "\n",
    "    model = ElasticNet(alpha=value, l1_ratio=l1_ratio, selection=\"random\")\n",
    "    #print(f'Investigating performance of {model} model...')\n",
    "\n",
    "    MSEs_train = []\n",
    "    MSEs_val = []\n",
    "    MSEs_test = []\n",
    "    MSEs_fold6 = []\n",
    "    MEs_train = []\n",
    "    MEs_val = []\n",
    "    MEs_test = []\n",
    "    MEs_fold6 = []\n",
    "\n",
    "    \n",
    "    for val_fold in [1,2,3,4,5]:\n",
    "        \n",
    "        # Extract dataframes\n",
    "        df_train = df_to_use[(df_to_use['info.fold'] != val_fold) & (df_to_use['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "        df_val   = df_to_use[df_to_use['info.fold'] == val_fold]\n",
    "        df_test  = df_to_use[df_to_use['info.fold'] == 0] \n",
    "\n",
    "        # Get ground-truth labels\n",
    "        Y_train = df_train['info.P_ground_truth'].values\n",
    "        Y_val = df_val['info.P_ground_truth'].values\n",
    "        Y_test = df_test['info.P_ground_truth'].values\n",
    "        Y_fold6 = df_fold6['info.P_ground_truth'].values\n",
    "\n",
    "\n",
    "        # Get feature matrices\n",
    "        X_train = df_train[features_to_use].values\n",
    "        X_val =df_val[features_to_use].values\n",
    "        X_test = df_test[features_to_use].values\n",
    "        X_fold6 = df_fold6[features_to_use].values\n",
    "\n",
    "        # Get features normalized_data = (data - mean) / (std)\n",
    "        \"\"\" X_train, mean, std=normalize_columns(X_train)\n",
    "        X_val= (X_val - mean) / (std)\n",
    "        X_test= (X_test - mean) / (std)\n",
    "        X_fold6= (X_fold6 - mean) / (std) \"\"\"\n",
    "        # Get features normalized_data = (data - min) / (max-min)\n",
    "        \"\"\" X_train, min, max=normalize_columns_minmax(X_train)\n",
    "        X_val= (X_val - min) / (max - min)\n",
    "        X_test= (X_test - min) / (max - min)\n",
    "        X_fold6= (X_fold6 - min) / (max - min) \"\"\"\n",
    "\n",
    "        # Fit model\n",
    "        X_LR = model.fit(X_train, Y_train)\n",
    "\n",
    "        # Get MSEs\n",
    "        MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "        MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "        MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "        MSE_fold6 = np.mean((clip(X_LR.predict(X_fold6)) - Y_fold6)**2)\n",
    "        ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "        ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "        ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "        ME_fold6 = np.mean(np.abs(clip(X_LR.predict(X_fold6)) - Y_fold6))\n",
    "\n",
    "        # Add metrics\n",
    "        MSEs_train.append(MSE_train)\n",
    "        MSEs_val.append(MSE_val)\n",
    "        MSEs_test.append(MSE_test)\n",
    "        MSEs_fold6.append(MSE_fold6)\n",
    "        MEs_train.append(ME_train)\n",
    "        MEs_val.append(ME_val)\n",
    "        MEs_test.append(ME_test)\n",
    "        MEs_fold6.append(ME_fold6)\n",
    "\n",
    "        #print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "    print(\"Parameters \",value, l1_ratio )\n",
    "    print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MSEs_fold6):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} | {np.mean(MEs_fold6):.4f} |')\n",
    "\n",
    "    current_mean=(np.mean(MEs_test)+np.mean(MEs_fold6))/2\n",
    "    if current_mean<prev_mean:\n",
    "        prev_mean=current_mean\n",
    "        chosen=(value, l1_ratio)\n",
    "\n",
    "    \n",
    "print(\"Best parameters were \", chosen, \" giving a mean of \", prev_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust l1_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |         Mean squared error        |             Mean  error            |\n",
      "Fold |--------+--------+--------+--------|--------+--------+--------|---------|\n",
      "     | Train  |   Val  |  Test  |Test(f6)| Train  |   Val  |  Test  | Test(f6)|\n",
      "-----+--------+--------+--------+--------+--------+--------+--------+----------\n",
      "Parameters  0.7 0.1\n",
      "Mean | 0.1244 | 0.1267 | 0.0812 | 0.1398 | 0.2871 | 0.2898 | 0.2460 | 0.2977 |\n",
      "Parameters  0.7 0.2\n",
      "Mean | 0.1263 | 0.1284 | 0.0808 | 0.0992 | 0.2903 | 0.2926 | 0.2422 | 0.2605 |\n",
      "Parameters  0.7 0.3\n",
      "Mean | 0.1290 | 0.1308 | 0.0817 | 0.0717 | 0.2943 | 0.2963 | 0.2405 | 0.2310 |\n",
      "Parameters  0.7 0.4\n",
      "Mean | 0.1321 | 0.1337 | 0.0831 | 0.0582 | 0.2985 | 0.3003 | 0.2400 | 0.2076 |\n",
      "Parameters  0.7 0.5\n",
      "Mean | 0.1354 | 0.1364 | 0.0852 | 0.0578 | 0.3028 | 0.3039 | 0.2415 | 0.2008 |\n",
      "Parameters  0.7 0.6\n",
      "Mean | 0.1376 | 0.1384 | 0.0869 | 0.0613 | 0.3058 | 0.3066 | 0.2440 | 0.2057 |\n",
      "Parameters  0.7 0.7\n",
      "Mean | 0.1394 | 0.1400 | 0.0892 | 0.0639 | 0.3081 | 0.3088 | 0.2473 | 0.2101 |\n",
      "Parameters  0.7 0.8\n",
      "Mean | 0.1412 | 0.1418 | 0.0916 | 0.0664 | 0.3105 | 0.3111 | 0.2508 | 0.2143 |\n",
      "Parameters  0.7 0.9\n",
      "Mean | 0.1433 | 0.1438 | 0.0943 | 0.0690 | 0.3130 | 0.3136 | 0.2543 | 0.2186 |\n",
      "Best parameters were  (0.7, 0.5)  giving a mean of  0.2211388561471332\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "# Suppress ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "# Define your ElasticNet model with specific hyperparameters\n",
    "alpha = 0.7\n",
    "l1_ratio = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9] #0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9\n",
    "print('     |         Mean squared error        |             Mean  error            |')\n",
    "print('Fold |--------+--------+--------+--------|--------+--------+--------|---------|')\n",
    "print('     | Train  |   Val  |  Test  |Test(f6)| Train  |   Val  |  Test  | Test(f6)|')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+--------+----------')\n",
    "\n",
    "\n",
    "prev_mean=9999\n",
    "for value in l1_ratio:\n",
    "\n",
    "    model = ElasticNet(alpha=alpha, l1_ratio=value, selection=\"random\")\n",
    "    #print(f'Investigating performance of {model} model...')\n",
    "\n",
    "    MSEs_train = []\n",
    "    MSEs_val = []\n",
    "    MSEs_test = []\n",
    "    MSEs_fold6 = []\n",
    "    MEs_train = []\n",
    "    MEs_val = []\n",
    "    MEs_test = []\n",
    "    MEs_fold6 = []\n",
    "\n",
    "    \n",
    "    for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "        \n",
    "        # Extract dataframes\n",
    "        df_train = df_to_use[(df_to_use['info.fold'] != val_fold) & (df_to_use['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "        df_val   = df_to_use[df_to_use['info.fold'] == val_fold]\n",
    "        df_test  = df_to_use[df_to_use['info.fold'] == 0] \n",
    "\n",
    "        # Get ground-truth labels\n",
    "        Y_train = df_train['info.P_ground_truth'].values\n",
    "        Y_val = df_val['info.P_ground_truth'].values\n",
    "        Y_test = df_test['info.P_ground_truth'].values\n",
    "        Y_fold6 = df_fold6['info.P_ground_truth'].values\n",
    "\n",
    "\n",
    "        # Get feature matrices\n",
    "        X_train = df_train[features_to_use].values\n",
    "        X_val =df_val[features_to_use].values\n",
    "        X_test = df_test[features_to_use].values\n",
    "        X_fold6 = df_fold6[features_to_use].values\n",
    "\n",
    "       # Get features normalized_data = (data - mean) / (std)\n",
    "        \"\"\" X_train, mean, std=normalize_columns(X_train)\n",
    "        X_val= (X_val - mean) / (std)\n",
    "        X_test= (X_test - mean) / (std)\n",
    "        X_fold6= (X_fold6 - mean) / (std) \"\"\"\n",
    "        # Get features normalized_data = (data - min) / (max-min)\n",
    "        \"\"\" X_train, min, max=normalize_columns_minmax(X_train)\n",
    "        X_val= (X_val - min) / (max - min)\n",
    "        X_test= (X_test - min) / (max - min)\n",
    "        X_fold6= (X_fold6 - min) / (max - min) \"\"\"\n",
    "\n",
    "        # Fit model\n",
    "        X_LR = model.fit(X_train, Y_train)\n",
    "\n",
    "        # Get MSEs\n",
    "        MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "        MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "        MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "        MSE_fold6 = np.mean((clip(X_LR.predict(X_fold6)) - Y_fold6)**2)\n",
    "        ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "        ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "        ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "        ME_fold6 = np.mean(np.abs(clip(X_LR.predict(X_fold6)) - Y_fold6))\n",
    "\n",
    "        # Add metrics\n",
    "        MSEs_train.append(MSE_train)\n",
    "        MSEs_val.append(MSE_val)\n",
    "        MSEs_test.append(MSE_test)\n",
    "        MSEs_fold6.append(MSE_fold6)\n",
    "        MEs_train.append(ME_train)\n",
    "        MEs_val.append(ME_val)\n",
    "        MEs_test.append(ME_test)\n",
    "        MEs_fold6.append(ME_fold6)\n",
    "\n",
    "        #print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "    print(\"Parameters \",alpha, value )\n",
    "    print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MSEs_fold6):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} | {np.mean(MEs_fold6):.4f} |')\n",
    "    \n",
    "    current_mean=(np.mean(MEs_test)+np.mean(MEs_fold6))/2\n",
    "    if current_mean<prev_mean:\n",
    "        prev_mean=current_mean\n",
    "        chosen=(alpha, value)\n",
    "\n",
    "    \n",
    "print(\"Best parameters were \", chosen, \" giving a mean of \", prev_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
