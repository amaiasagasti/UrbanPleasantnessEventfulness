{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from SoundLights.dataset.features_groups import  general_info, ARAUS_features, Freesound_features, mix_features, masker_features, clap_features\n",
    "from SoundLights.models.models_functions import clip, normalize_columns, normalize_columns_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_models(dataframe, features_evaluated, masker_transform:str=\"None\", maskers_gain: float = 1):\n",
    "\n",
    "    # Drop string columns\n",
    "    \"\"\"dataframe = dataframe.drop(\"info.file\", axis=1)\n",
    "    dataframe = dataframe.drop(\"info.participant\", axis=1)\"\"\"\n",
    "\n",
    "    # Maskers colum, increase values\n",
    "    if(masker_transform==\"-1,1\"):\n",
    "        dataframe[\"info.masker_bird\"] = (dataframe[\"info.masker_bird\"]*2-1) * maskers_gain\n",
    "        dataframe[\"info.masker_construction\"] = (\n",
    "            (dataframe[\"info.masker_construction\"]*2-1) * maskers_gain\n",
    "        )\n",
    "        dataframe[\"info.masker_traffic\"] = (dataframe[\"info.masker_traffic\"]*2-1) * maskers_gain\n",
    "        dataframe[\"info.masker_silence\"] = (dataframe[\"info.masker_silence\"]*2-1) * maskers_gain\n",
    "        dataframe[\"info.masker_water\"] = (dataframe[\"info.masker_water\"]*2-1) * maskers_gain\n",
    "        dataframe[\"info.masker_wind\"] = (dataframe[\"info.masker_wind\"]*2-1) * maskers_gain\n",
    "    else:\n",
    "        dataframe[\"info.masker_bird\"] = (dataframe[\"info.masker_bird\"]) * maskers_gain\n",
    "        dataframe[\"info.masker_construction\"] = (\n",
    "            dataframe[\"info.masker_construction\"] * maskers_gain\n",
    "        )\n",
    "        dataframe[\"info.masker_traffic\"] = dataframe[\"info.masker_traffic\"] * maskers_gain\n",
    "        dataframe[\"info.masker_silence\"] = dataframe[\"info.masker_silence\"] * maskers_gain\n",
    "        dataframe[\"info.masker_water\"] = dataframe[\"info.masker_water\"] * maskers_gain\n",
    "        dataframe[\"info.masker_wind\"] = dataframe[\"info.masker_wind\"] * maskers_gain\n",
    "\n",
    "    # For fold 0, group data\n",
    "    dataframe_fold0 = dataframe[dataframe[\"info.fold\"] == 0]\n",
    "    # Drop string columns\n",
    "    print(\"\\n dataframe fold 0 before anything\", dataframe_fold0.info())\n",
    "    print(\" ----------------------------- \")\n",
    "    dataframe_fold0 = dataframe_fold0.drop(\"info.file\", axis=1)\n",
    "    dataframe_fold0 = dataframe_fold0.drop(\"info.participant\", axis=1)\n",
    "    dataframe_fold0 = dataframe_fold0.groupby(\n",
    "        [\"info.soundscape\", \"info.masker\", \"info.smr\"]\n",
    "    ).mean()#.reset_index()  # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "    print(\"\\n dataframe fold 0 after drop and groupby\", dataframe_fold0.info())\n",
    "    print(\" ----------------------------- \")\n",
    "    #print(\"\\n dataframe fold 0 has infoo.soundscape????\", dataframe_fold0[\"info.soundscape\"])\n",
    "    dataframe_filtered = dataframe[\n",
    "        dataframe[\"info.fold\"] != 0\n",
    "    ]  # Filter rows where 'fold' column is not equal to 0\n",
    "    print(\"\\n dataframe fildered info\", dataframe_filtered.info())\n",
    "    print(\" ----------------------------- \")\n",
    "    dataframe = pd.concat(\n",
    "        [dataframe_fold0, dataframe_filtered], ignore_index=True\n",
    "    )  # Join together\n",
    "\n",
    "    print(\"\\n dataframe concat\", dataframe.columns)\n",
    "    print(\" ----------------------------- \")\n",
    "\n",
    "    # Drop columns with all equal values or std=0\n",
    "    std = np.std(dataframe[features_evaluated], axis=0)\n",
    "    columns_to_mantain_arg = np.where(std >= 0.00001)[0]\n",
    "    columns_to_drop_arg = np.where(std < 0.00001)[0]\n",
    "    columns_to_mantain = [features_evaluated[i] for i in columns_to_mantain_arg]\n",
    "    columns_to_drop = [features_evaluated[i] for i in columns_to_drop_arg]\n",
    "    print(\"columns to drop \", columns_to_drop)\n",
    "    print(\" ----------------------------- \")\n",
    "    # print(features_evaluated[np.where(std == 0)[0]])\n",
    "    dataframe.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "    return dataframe, columns_to_mantain\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPARE DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input general dataframe (folds 0,1,2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25440 entries, 0 to 25439\n",
      "Columns: 285 entries, CLAP to freesound.rhythm.bpm\n",
      "dtypes: float64(261), int64(19), object(5)\n",
      "memory usage: 55.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv('../data/main_files/SoundLights_complete.csv')\n",
    "\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into sections of data to use (ARAUS, Freesound or CLAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARAUS features dataframe\n",
    "df_ARAUS=df[general_info+ARAUS_features]\n",
    "# Freesound features dataframe\n",
    "df_Freesound=df[general_info+Freesound_features]\n",
    "# CLAP embeddings dataframe\n",
    "df_clap=df[general_info+[\"CLAP\"]]\n",
    "#print(df_clap[\"CLAP\"].values[1])\n",
    "#print(df_clap[\"info.P_ground_truth\"].values[1])\n",
    "all_columns=general_info+clap_features\n",
    "full_list=[]\n",
    "for index, row in df_clap.iterrows():\n",
    "    string_list=row[\"CLAP\"].split(\"[\")[2].split(\"]\")[0].split(\",\")\n",
    "    clap_list = [float(item) for item in string_list]\n",
    "    #clap_list=clap_list[0:101] ##############################!!!!!!!!!!!!\n",
    "    complete_new_row=list(row[general_info].values)+clap_list\n",
    "    full_list.append(complete_new_row)\n",
    "df_clap=pd.DataFrame(data=full_list, columns=all_columns)\n",
    "#print(df_clap.iloc[1][[\"info.P_ground_truth\", \"clap_0\",\"clap_1\",\"clap_2\" ]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input dataframe of new audios to validate (fold 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real= pd.read_csv('../data/main_files/SoundLights_fold6.csv')\n",
    "# Adapt CLAP features\n",
    "df_fold6=df_real[ARAUS_features+Freesound_features+masker_features+[\"info.P_ground_truth\", \"info.E_ground_truth\", \"CLAP\"]]\n",
    "all_columns=ARAUS_features+Freesound_features+masker_features+[\"info.P_ground_truth\", \"info.E_ground_truth\"]+clap_features\n",
    "full_list=[]\n",
    "for index, row in df_fold6.iterrows():\n",
    "    string_list=row[\"CLAP\"].split(\"[\")[1].split(\"]\")[0].split(\",\")\n",
    "    clap_list = [float(item) for item in string_list]\n",
    "    #clap_list=clap_list[0:101] ##############################!!!!!!!!!!!!\n",
    "    complete_new_row=list(row[ARAUS_features+Freesound_features+masker_features+[\"info.P_ground_truth\", \"info.E_ground_truth\"]].values)+clap_list\n",
    "    full_list.append(complete_new_row)\n",
    "df_fold6=pd.DataFrame(data=full_list, columns=all_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select data to evaluate and adapt masker features if desired\n",
    "\n",
    "Here is where changes have to be made to try different configurations\n",
    "\n",
    "1) Which dataframe/set of features to evaluate. Change input df and features to prepare_data_models()\n",
    "2) Decide if maskers are used or not by adding them to features_to_use\n",
    "3) Decide if maskers are transformed by changing masker_gain and/or masker_transform\n",
    "4) To add normalizations, discomment the code that normalises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 240 entries, 0 to 239\n",
      "Columns: 145 entries, info.file to ARAUS.energy_frequency.20000_0\n",
      "dtypes: float64(122), int64(19), object(4)\n",
      "memory usage: 273.8+ KB\n",
      "\n",
      " dataframe fold 0 before anything None\n",
      " ----------------------------- \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 48 entries, ('R1001_segment_binaural_44100.wav', 'bird_10001.wav', 0) to ('R1008_segment_binaural_44100.wav', 'wind_10001.wav', 0)\n",
      "Columns: 140 entries, info.fold to ARAUS.energy_frequency.20000_0\n",
      "dtypes: float64(140)\n",
      "memory usage: 52.9+ KB\n",
      "\n",
      " dataframe fold 0 after drop and groupby None\n",
      " ----------------------------- \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25200 entries, 240 to 25439\n",
      "Columns: 145 entries, info.file to ARAUS.energy_frequency.20000_0\n",
      "dtypes: float64(122), int64(19), object(4)\n",
      "memory usage: 28.1+ MB\n",
      "\n",
      " dataframe fildered info None\n",
      " ----------------------------- \n",
      "\n",
      " dataframe concat Index(['info.fold', 'info.stimulus_index', 'info.wav_gain', 'info.time_taken',\n",
      "       'info.is_attention', 'info.pleasant', 'info.eventful', 'info.chaotic',\n",
      "       'info.vibrant', 'info.uneventful',\n",
      "       ...\n",
      "       'ARAUS.energy_frequency.08000_0', 'ARAUS.energy_frequency.10000_0',\n",
      "       'ARAUS.energy_frequency.12500_0', 'ARAUS.energy_frequency.16000_0',\n",
      "       'ARAUS.energy_frequency.20000_0', 'info.file', 'info.participant',\n",
      "       'info.soundscape', 'info.masker', 'info.smr'],\n",
      "      dtype='object', length=145)\n",
      " ----------------------------- \n",
      "columns to drop  ['ARAUS.energy_frequency.00005_0', 'ARAUS.energy_frequency.00008_0', 'ARAUS.energy_frequency.00010_0', 'ARAUS.energy_frequency.00020_0']\n",
      " ----------------------------- \n"
     ]
    }
   ],
   "source": [
    "#!!!!!! CHANGE\n",
    "masker_gain=1\n",
    "masker_transform=\"None\" #\"-1,1\"\n",
    "#!!!!!! CHANGE\n",
    "\n",
    "df_to_use,features_to_use=prepare_data_models(df_ARAUS.copy(), ARAUS_features,masker_transform, masker_gain) #!!!!!! CHANGE DATAFRAME AND FEATURES\n",
    "\n",
    "#!!!!!! CHANGE\n",
    "features_to_use=features_to_use#+[\"info.masker_bird\",\"info.masker_construction\",\"info.masker_silence\",\"info.masker_traffic\", \"info.masker_water\",\"info.masker_wind\"] \n",
    "#!!!!!! CHANGE\n",
    "pd.options.mode.chained_assignment = None  # Ignore warning, default='warn'\n",
    "if(masker_transform==\"-1,1\"):\n",
    "    df_fold6[\"info.masker_bird\"]=(df_fold6[\"info.masker_bird\"]*2-1)*masker_gain\n",
    "    df_fold6[\"info.masker_construction\"]=(df_fold6[\"info.masker_construction\"]*2-1)*masker_gain\n",
    "    df_fold6[\"info.masker_silence\"]=(df_fold6[\"info.masker_silence\"]*2-1)*masker_gain\n",
    "    df_fold6[\"info.masker_traffic\"]=(df_fold6[\"info.masker_traffic\"]*2-1)*masker_gain\n",
    "    df_fold6[\"info.masker_water\"]=(df_fold6[\"info.masker_water\"]*2-1)*masker_gain\n",
    "    df_fold6[\"info.masker_wind\"]=(df_fold6[\"info.masker_wind\"]*2-1)*masker_gain\n",
    "else:\n",
    "    df_fold6[\"info.masker_bird\"]=df_fold6[\"info.masker_bird\"]*masker_gain\n",
    "    df_fold6[\"info.masker_construction\"]=df_fold6[\"info.masker_construction\"]*masker_gain\n",
    "    df_fold6[\"info.masker_silence\"]=df_fold6[\"info.masker_silence\"]*masker_gain\n",
    "    df_fold6[\"info.masker_traffic\"]=df_fold6[\"info.masker_traffic\"]*masker_gain\n",
    "    df_fold6[\"info.masker_water\"]=df_fold6[\"info.masker_water\"]*masker_gain\n",
    "    df_fold6[\"info.masker_wind\"]=df_fold6[\"info.masker_wind\"]*masker_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |         Mean squared error        |             Mean  error            |\n",
      "Fold |--------+--------+--------+--------|--------+--------+--------|---------|\n",
      "     | Train  |   Val  |  Test  |Test(f6)| Train  |   Val  |  Test  | Test(f6)|\n",
      "-----+--------+--------+--------+--------+--------+--------+--------+----------\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Parameters  0.2 0.5\n",
      "Mean | 0.1308 | 0.1329 | 0.0323 | 0.0670 | 0.2983 | 0.3006 | 0.1433 | 0.2161 |\n",
      "Best parameters were  (0.2, 0.5)  giving a mean of  0.17972346808081602\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "# Suppress ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "from sklearn.linear_model import ElasticNet\n",
    "# Define your ElasticNet model with specific hyperparameters\n",
    "alpha = [0.2] #0.1,0.2,0,3,0.4,0.5,0.6,0.7,0.8,0.9,1\n",
    "l1_ratio = 0.5\n",
    "print('     |         Mean squared error        |             Mean  error            |')\n",
    "print('Fold |--------+--------+--------+--------|--------+--------+--------|---------|')\n",
    "print('     | Train  |   Val  |  Test  |Test(f6)| Train  |   Val  |  Test  | Test(f6)|')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+--------+----------')\n",
    "\n",
    "prev_mean=9999\n",
    "for value in alpha:\n",
    "\n",
    "    model = ElasticNet(alpha=value, l1_ratio=l1_ratio, selection=\"random\")\n",
    "    #print(f'Investigating performance of {model} model...')\n",
    "\n",
    "    MSEs_train = []\n",
    "    MSEs_val = []\n",
    "    MSEs_test = []\n",
    "    MSEs_fold6 = []\n",
    "    MEs_train = []\n",
    "    MEs_val = []\n",
    "    MEs_test = []\n",
    "    MEs_fold6 = []\n",
    "\n",
    "    \n",
    "    for val_fold in [1,2,3,4,5]:\n",
    "        \n",
    "        # Extract dataframes\n",
    "        df_train = df_to_use[(df_to_use['info.fold'] != val_fold) & (df_to_use['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "        df_val   = df_to_use[df_to_use['info.fold'] == val_fold]\n",
    "        df_test  = df_to_use[df_to_use['info.fold'] == 0] \n",
    "\n",
    "\n",
    "        # Get ground-truth labels\n",
    "        Y_train = df_train['info.E_ground_truth'].values#[0:10]\n",
    "        Y_val = df_val['info.E_ground_truth'].values\n",
    "        Y_test = df_test['info.E_ground_truth'].values\n",
    "        Y_fold6 = df_fold6['info.E_ground_truth'].values\n",
    "\n",
    "\n",
    "        # Get feature matrices\n",
    "        X_train = df_train[features_to_use].values#[:,0:100]\n",
    "        X_val =df_val[features_to_use].values#[:,0:100]\n",
    "        X_test = df_test[features_to_use].values#[:,0:100]\n",
    "        X_fold6 = df_fold6[features_to_use].values#[:,0:100]\n",
    "\n",
    "        # Get features normalized_data = (data - mean) / (std)\n",
    "        \"\"\" X_train, mean, std=normalize_columns(X_train)\n",
    "        X_val= (X_val - mean) / (std)\n",
    "        X_test= (X_test - mean) / (std)\n",
    "        X_fold6= (X_fold6 - mean) / (std) \"\"\"\n",
    "        # Get features normalized_data = (data - min) / (max-min)\n",
    "        \"\"\" X_train, min, max=normalize_columns_minmax(X_train)\n",
    "        X_val= (X_val - min) / (max - min)\n",
    "        X_test= (X_test - min) / (max - min)\n",
    "        X_fold6= (X_fold6 - min) / (max - min) \"\"\"\n",
    "\n",
    "        # Fit model\n",
    "        X_LR = model.fit(X_train, Y_train)\n",
    "        print(\".\")\n",
    "        #print(\"iterations \", X_LR.n_iter_, X_LR.n_features_in_)\n",
    "\n",
    "        # Get MSEs\n",
    "        MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "        MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "        MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "        MSE_fold6 = np.mean((clip(X_LR.predict(X_fold6)) - Y_fold6)**2)\n",
    "        ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "        ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "        ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "        ME_fold6 = np.mean(np.abs(clip(X_LR.predict(X_fold6)) - Y_fold6))\n",
    "\n",
    "        # Add metrics\n",
    "        MSEs_train.append(MSE_train)\n",
    "        MSEs_val.append(MSE_val)\n",
    "        MSEs_test.append(MSE_test)\n",
    "        MSEs_fold6.append(MSE_fold6)\n",
    "        MEs_train.append(ME_train)\n",
    "        MEs_val.append(ME_val)\n",
    "        MEs_test.append(ME_test)\n",
    "        MEs_fold6.append(ME_fold6)\n",
    "\n",
    "        #print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "    print(\"Parameters \",value, l1_ratio )\n",
    "    print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MSEs_fold6):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} | {np.mean(MEs_fold6):.4f} |')\n",
    "\n",
    "    current_mean=(np.mean(MEs_test)+np.mean(MEs_fold6))/2\n",
    "    if current_mean<prev_mean:\n",
    "        prev_mean=current_mean\n",
    "        chosen=(value, l1_ratio)\n",
    "\n",
    "    \n",
    "print(\"Best parameters were \", chosen, \" giving a mean of \", prev_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust l1_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |         Mean squared error        |             Mean  error            |\n",
      "Fold |--------+--------+--------+--------|--------+--------+--------|---------|\n",
      "     | Train  |   Val  |  Test  |Test(f6)| Train  |   Val  |  Test  | Test(f6)|\n",
      "-----+--------+--------+--------+--------+--------+--------+--------+----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_ElasticNet.ipynb Cell 16\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_ElasticNet.ipynb#X21sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" X_train, min, max=normalize_columns_minmax(X_train)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_ElasticNet.ipynb#X21sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mX_val= (X_val - min) / (max - min)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_ElasticNet.ipynb#X21sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mX_test= (X_test - min) / (max - min)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_ElasticNet.ipynb#X21sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mX_fold6= (X_fold6 - min) / (max - min) \"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_ElasticNet.ipynb#X21sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# Fit model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_ElasticNet.ipynb#X21sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m X_LR \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_ElasticNet.ipynb#X21sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m# Get MSEs\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_ElasticNet.ipynb#X21sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m MSE_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean((clip(X_LR\u001b[39m.\u001b[39mpredict(X_train)) \u001b[39m-\u001b[39m Y_train)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/araus-mac/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:1054\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1053\u001b[0m     this_Xy \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1054\u001b[0m _, this_coef, this_dual_gap, this_iter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath(\n\u001b[1;32m   1055\u001b[0m     X,\n\u001b[1;32m   1056\u001b[0m     y[:, k],\n\u001b[1;32m   1057\u001b[0m     l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[1;32m   1058\u001b[0m     eps\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1059\u001b[0m     n_alphas\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1060\u001b[0m     alphas\u001b[39m=\u001b[39;49m[alpha],\n\u001b[1;32m   1061\u001b[0m     precompute\u001b[39m=\u001b[39;49mprecompute,\n\u001b[1;32m   1062\u001b[0m     Xy\u001b[39m=\u001b[39;49mthis_Xy,\n\u001b[1;32m   1063\u001b[0m     copy_X\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1064\u001b[0m     coef_init\u001b[39m=\u001b[39;49mcoef_[k],\n\u001b[1;32m   1065\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1066\u001b[0m     return_n_iter\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1067\u001b[0m     positive\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpositive,\n\u001b[1;32m   1068\u001b[0m     check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1069\u001b[0m     \u001b[39m# from here on **params\u001b[39;49;00m\n\u001b[1;32m   1070\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m   1071\u001b[0m     X_offset\u001b[39m=\u001b[39;49mX_offset,\n\u001b[1;32m   1072\u001b[0m     X_scale\u001b[39m=\u001b[39;49mX_scale,\n\u001b[1;32m   1073\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1074\u001b[0m     random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m   1075\u001b[0m     selection\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselection,\n\u001b[1;32m   1076\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1077\u001b[0m )\n\u001b[1;32m   1078\u001b[0m coef_[k] \u001b[39m=\u001b[39m this_coef[:, \u001b[39m0\u001b[39m]\n\u001b[1;32m   1079\u001b[0m dual_gaps_[k] \u001b[39m=\u001b[39m this_dual_gap[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/araus-mac/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648\u001b[0m, in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    634\u001b[0m     model \u001b[39m=\u001b[39m cd_fast\u001b[39m.\u001b[39menet_coordinate_descent_gram(\n\u001b[1;32m    635\u001b[0m         coef_,\n\u001b[1;32m    636\u001b[0m         l1_reg,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         positive,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[1;32m    647\u001b[0m \u001b[39melif\u001b[39;00m precompute \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m--> 648\u001b[0m     model \u001b[39m=\u001b[39m cd_fast\u001b[39m.\u001b[39;49menet_coordinate_descent(\n\u001b[1;32m    649\u001b[0m         coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n\u001b[1;32m    650\u001b[0m     )\n\u001b[1;32m    651\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    652\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    653\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPrecompute should be one of True, False, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or array-like. Got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    654\u001b[0m         \u001b[39m%\u001b[39m precompute\n\u001b[1;32m    655\u001b[0m     )\n",
      "File \u001b[0;32msklearn/linear_model/_cd_fast.pyx:251\u001b[0m, in \u001b[0;36msklearn.linear_model._cd_fast.enet_coordinate_descent\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/araus-mac/lib/python3.10/site-packages/numpy/core/getlimits.py:486\u001b[0m, in \u001b[0;36mfinfo.__new__\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m, dtype):\n\u001b[1;32m    485\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m         obj \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_finfo_cache\u001b[39m.\u001b[39;49mget(dtype)  \u001b[39m# most common path\u001b[39;00m\n\u001b[1;32m    487\u001b[0m         \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m             \u001b[39mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "# Suppress ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "# Define your ElasticNet model with specific hyperparameters\n",
    "alpha = 0.1\n",
    "l1_ratio = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9] #0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9\n",
    "print('     |         Mean squared error        |             Mean  error            |')\n",
    "print('Fold |--------+--------+--------+--------|--------+--------+--------|---------|')\n",
    "print('     | Train  |   Val  |  Test  |Test(f6)| Train  |   Val  |  Test  | Test(f6)|')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+--------+----------')\n",
    "\n",
    "\n",
    "prev_mean=9999\n",
    "for value in l1_ratio:\n",
    "\n",
    "    model = ElasticNet(alpha=alpha, l1_ratio=value, selection=\"random\")\n",
    "    #print(f'Investigating performance of {model} model...')\n",
    "\n",
    "    MSEs_train = []\n",
    "    MSEs_val = []\n",
    "    MSEs_test = []\n",
    "    MSEs_fold6 = []\n",
    "    MEs_train = []\n",
    "    MEs_val = []\n",
    "    MEs_test = []\n",
    "    MEs_fold6 = []\n",
    "\n",
    "    \n",
    "    for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "        \n",
    "        # Extract dataframes\n",
    "        df_train = df_to_use[(df_to_use['info.fold'] != val_fold) & (df_to_use['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "        df_val   = df_to_use[df_to_use['info.fold'] == val_fold]\n",
    "        df_test  = df_to_use[df_to_use['info.fold'] == 0] \n",
    "\n",
    "        # Get ground-truth labels\n",
    "        Y_train = df_train['info.E_ground_truth'].values\n",
    "        Y_val = df_val['info.E_ground_truth'].values\n",
    "        Y_test = df_test['info.E_ground_truth'].values\n",
    "        Y_fold6 = df_fold6['info.E_ground_truth'].values\n",
    "\n",
    "\n",
    "        # Get feature matrices\n",
    "        X_train = df_train[features_to_use].values\n",
    "        X_val =df_val[features_to_use].values\n",
    "        X_test = df_test[features_to_use].values\n",
    "        X_fold6 = df_fold6[features_to_use].values\n",
    "\n",
    "       # Get features normalized_data = (data - mean) / (std)\n",
    "        \"\"\" X_train, mean, std=normalize_columns(X_train)\n",
    "        X_val= (X_val - mean) / (std)\n",
    "        X_test= (X_test - mean) / (std)\n",
    "        X_fold6= (X_fold6 - mean) / (std) \"\"\"\n",
    "        # Get features normalized_data = (data - min) / (max-min)\n",
    "        \"\"\" X_train, min, max=normalize_columns_minmax(X_train)\n",
    "        X_val= (X_val - min) / (max - min)\n",
    "        X_test= (X_test - min) / (max - min)\n",
    "        X_fold6= (X_fold6 - min) / (max - min) \"\"\"\n",
    "\n",
    "        # Fit model\n",
    "        X_LR = model.fit(X_train, Y_train)\n",
    "\n",
    "        # Get MSEs\n",
    "        MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "        MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "        MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "        MSE_fold6 = np.mean((clip(X_LR.predict(X_fold6)) - Y_fold6)**2)\n",
    "        ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "        ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "        ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "        ME_fold6 = np.mean(np.abs(clip(X_LR.predict(X_fold6)) - Y_fold6))\n",
    "\n",
    "        # Add metrics\n",
    "        MSEs_train.append(MSE_train)\n",
    "        MSEs_val.append(MSE_val)\n",
    "        MSEs_test.append(MSE_test)\n",
    "        MSEs_fold6.append(MSE_fold6)\n",
    "        MEs_train.append(ME_train)\n",
    "        MEs_val.append(ME_val)\n",
    "        MEs_test.append(ME_test)\n",
    "        MEs_fold6.append(ME_fold6)\n",
    "\n",
    "        #print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "    print(\"Parameters \",alpha, value )\n",
    "    print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MSEs_fold6):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} | {np.mean(MEs_fold6):.4f} |')\n",
    "    \n",
    "    current_mean=(np.mean(MEs_test)+np.mean(MEs_fold6))/2\n",
    "    if current_mean<prev_mean:\n",
    "        prev_mean=current_mean\n",
    "        chosen=(alpha, value)\n",
    "\n",
    "    \n",
    "print(\"Best parameters were \", chosen, \" giving a mean of \", prev_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |         Mean squared error        |             Mean  error            |\n",
      "Fold |--------+--------+--------+--------|--------+--------+--------|---------|\n",
      "     | Train  |   Val  |  Test  |Test(f6)| Train  |   Val  |  Test  | Test(f6)|\n",
      "-----+--------+--------+--------+--------+--------+--------+--------+----------\n",
      "Parameters  0.1 0.5\n",
      "Mean | 0.0000 | 0.1553 | 0.1192 | 0.0877 | 0.0000 | 0.3277 | 0.2867 | 0.2509 |\n",
      "Parameters  0.2 0.5\n",
      "Mean | 0.0000 | 0.1553 | 0.1192 | 0.0877 | 0.0000 | 0.3277 | 0.2867 | 0.2509 |\n",
      "Parameters  0.3 0.5\n",
      "Mean | 0.0000 | 0.1553 | 0.1192 | 0.0877 | 0.0000 | 0.3277 | 0.2867 | 0.2509 |\n",
      "Parameters  0.4 0.5\n",
      "Mean | 0.0000 | 0.1553 | 0.1192 | 0.0877 | 0.0000 | 0.3277 | 0.2867 | 0.2509 |\n",
      "Parameters  0.5 0.5\n",
      "Mean | 0.0000 | 0.1553 | 0.1192 | 0.0877 | 0.0000 | 0.3277 | 0.2867 | 0.2509 |\n",
      "Parameters  0.6 0.5\n",
      "Mean | 0.0000 | 0.1553 | 0.1192 | 0.0877 | 0.0000 | 0.3277 | 0.2867 | 0.2509 |\n",
      "Parameters  0.7 0.5\n",
      "Mean | 0.0000 | 0.1553 | 0.1192 | 0.0877 | 0.0000 | 0.3277 | 0.2867 | 0.2509 |\n",
      "Parameters  0.8 0.5\n",
      "Mean | 0.0000 | 0.1553 | 0.1192 | 0.0877 | 0.0000 | 0.3277 | 0.2867 | 0.2509 |\n",
      "Parameters  0.9 0.5\n",
      "Mean | 0.0000 | 0.1553 | 0.1192 | 0.0877 | 0.0000 | 0.3277 | 0.2867 | 0.2509 |\n",
      "Parameters  1 0.5\n",
      "Mean | 0.0000 | 0.1553 | 0.1192 | 0.0877 | 0.0000 | 0.3277 | 0.2867 | 0.2509 |\n",
      "Best parameters were  (0.1, 0.9)  giving a mean of  0.21131112458302825\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "# Suppress ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "# Define your ElasticNet model with specific hyperparameters\n",
    "alpha = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1] \n",
    "l1_ratio = 0.5\n",
    "print('     |         Mean squared error        |             Mean  error            |')\n",
    "print('Fold |--------+--------+--------+--------|--------+--------+--------|---------|')\n",
    "print('     | Train  |   Val  |  Test  |Test(f6)| Train  |   Val  |  Test  | Test(f6)|')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+--------+----------')\n",
    "\n",
    "\n",
    "for value in alpha:\n",
    "\n",
    "    MSEs_train = []\n",
    "    MSEs_val = []\n",
    "    MSEs_test = []\n",
    "    MSEs_fold6 = []\n",
    "    MEs_train = []\n",
    "    MEs_val = []\n",
    "    MEs_test = []\n",
    "    MEs_fold6 = []\n",
    "\n",
    "    \n",
    "    for val_fold in [1,2,3,4,5]:\n",
    "        \n",
    "        # Extract dataframes\n",
    "        df_train = df_to_use[(df_to_use['info.fold'] != val_fold) & (df_to_use['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "        df_val   = df_to_use[df_to_use['info.fold'] == val_fold]\n",
    "        df_test  = df_to_use[df_to_use['info.fold'] == 0] \n",
    "\n",
    "        # Get ground-truth labels\n",
    "        Y_train = np.mean(df_train['info.P_ground_truth'].values)\n",
    "        Y_val = df_val['info.P_ground_truth'].values\n",
    "        Y_test = df_test['info.P_ground_truth'].values\n",
    "        Y_fold6 = df_fold6['info.P_ground_truth'].values\n",
    "\n",
    "\n",
    "        #Get feature matrices\n",
    "        \"\"\" X_train = df_train[features_to_use].values#[0:1000,:]\n",
    "        X_val =df_val[features_to_use].values\n",
    "        X_test = df_test[features_to_use].values\n",
    "        X_fold6 = df_fold6[features_to_use].values \"\"\"\n",
    "\n",
    "        # Get features normalized_data = (data - mean) / (std)\n",
    "        \"\"\" X_train, mean, std=normalize_columns(X_train)\n",
    "        X_val= (X_val - mean) / (std)\n",
    "        X_test= (X_test - mean) / (std)\n",
    "        X_fold6= (X_fold6 - mean) / (std) \"\"\"\n",
    "        # Get features normalized_data = (data - min) / (max-min)\n",
    "        \"\"\" X_train, min, max=normalize_columns_minmax(X_train)\n",
    "        X_val= (X_val - min) / (max - min)\n",
    "        X_test= (X_test - min) / (max - min)\n",
    "        X_fold6= (X_fold6 - min) / (max - min) \"\"\"\n",
    "\n",
    "        # Fit model\n",
    "        \"\"\" X_LR = model.fit(X_train, Y_train) \"\"\"\n",
    "\n",
    "        # Get MSEs\n",
    "        MSE_train = np.mean( (Y_train- Y_train)**2)\n",
    "        MSE_val = np.mean((Y_train - Y_val)**2)\n",
    "        MSE_test = np.mean((Y_train- Y_test)**2)\n",
    "        MSE_fold6 = np.mean((Y_train - Y_fold6)**2)\n",
    "        ME_train = np.mean(np.abs(Y_train - Y_train))\n",
    "        ME_val = np.mean(np.abs(Y_train - Y_val))\n",
    "        ME_test = np.mean(np.abs(Y_train - Y_test))\n",
    "        ME_fold6 = np.mean(np.abs(Y_train - Y_fold6))\n",
    "\n",
    "        # Add metrics\n",
    "        MSEs_train.append(MSE_train)\n",
    "        MSEs_val.append(MSE_val)\n",
    "        MSEs_test.append(MSE_test)\n",
    "        MSEs_fold6.append(MSE_fold6)\n",
    "        MEs_train.append(ME_train)\n",
    "        MEs_val.append(ME_val)\n",
    "        MEs_test.append(ME_test)\n",
    "        MEs_fold6.append(ME_fold6)\n",
    "\n",
    "        #print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "    print(\"Parameters \",value, l1_ratio )\n",
    "    print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MSEs_fold6):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} | {np.mean(MEs_fold6):.4f} |')\n",
    "\n",
    "    current_mean=(np.mean(MEs_test)+np.mean(MEs_fold6))/2\n",
    "    if current_mean<prev_mean:\n",
    "        prev_mean=current_mean\n",
    "        chosen=(value, l1_ratio)\n",
    "\n",
    "    \n",
    "print(\"Best parameters were \", chosen, \" giving a mean of \", prev_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
