{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from SoundLights.dataset.features_groups import  general_info, ARAUS_features, Freesound_features, mix_features, masker_features, clap_features\n",
    "from SoundLights.models.models_functions import clip, normalize_columns, normalize_columns_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_models(dataframe, features_evaluated, masker_transform:str=\"None\", maskers_gain: float = 1):\n",
    "\n",
    "    # Drop string columns\n",
    "    \"\"\"dataframe = dataframe.drop(\"info.file\", axis=1)\n",
    "    dataframe = dataframe.drop(\"info.participant\", axis=1)\"\"\"\n",
    "\n",
    "    # Maskers colum, increase values\n",
    "    if(masker_transform==\"-1,1\"):\n",
    "        dataframe[\"info.masker_bird\"] = (dataframe[\"info.masker_bird\"]*2-1) * maskers_gain\n",
    "        dataframe[\"info.masker_construction\"] = (\n",
    "            (dataframe[\"info.masker_construction\"]*2-1) * maskers_gain\n",
    "        )\n",
    "        dataframe[\"info.masker_traffic\"] = (dataframe[\"info.masker_traffic\"]*2-1) * maskers_gain\n",
    "        dataframe[\"info.masker_silence\"] = (dataframe[\"info.masker_silence\"]*2-1) * maskers_gain\n",
    "        dataframe[\"info.masker_water\"] = (dataframe[\"info.masker_water\"]*2-1) * maskers_gain\n",
    "        dataframe[\"info.masker_wind\"] = (dataframe[\"info.masker_wind\"]*2-1) * maskers_gain\n",
    "    else:\n",
    "        dataframe[\"info.masker_bird\"] = (dataframe[\"info.masker_bird\"]) * maskers_gain\n",
    "        dataframe[\"info.masker_construction\"] = (\n",
    "            dataframe[\"info.masker_construction\"] * maskers_gain\n",
    "        )\n",
    "        dataframe[\"info.masker_traffic\"] = dataframe[\"info.masker_traffic\"] * maskers_gain\n",
    "        dataframe[\"info.masker_silence\"] = dataframe[\"info.masker_silence\"] * maskers_gain\n",
    "        dataframe[\"info.masker_water\"] = dataframe[\"info.masker_water\"] * maskers_gain\n",
    "        dataframe[\"info.masker_wind\"] = dataframe[\"info.masker_wind\"] * maskers_gain\n",
    "\n",
    "    # For fold 0, group data\n",
    "    dataframe_fold0 = dataframe[dataframe[\"info.fold\"] == 0]\n",
    "    # Drop string columns\n",
    "    print(\"\\n dataframe fold 0 before anything\", dataframe_fold0.info())\n",
    "    print(\" ----------------------------- \")\n",
    "    dataframe_fold0 = dataframe_fold0.drop(\"info.file\", axis=1)\n",
    "    dataframe_fold0 = dataframe_fold0.drop(\"info.participant\", axis=1)\n",
    "    dataframe_fold0 = dataframe_fold0.groupby(\n",
    "        [\"info.soundscape\", \"info.masker\", \"info.smr\"]\n",
    "    ).mean()#.reset_index()  # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "    print(\"\\n dataframe fold 0 after drop and groupby\", dataframe_fold0.info())\n",
    "    print(\" ----------------------------- \")\n",
    "    #print(\"\\n dataframe fold 0 has infoo.soundscape????\", dataframe_fold0[\"info.soundscape\"])\n",
    "    dataframe_filtered = dataframe[\n",
    "        dataframe[\"info.fold\"] != 0\n",
    "    ]  # Filter rows where 'fold' column is not equal to 0\n",
    "    print(\"\\n dataframe fildered info\", dataframe_filtered.info())\n",
    "    print(\" ----------------------------- \")\n",
    "    dataframe = pd.concat(\n",
    "        [dataframe_fold0, dataframe_filtered], ignore_index=True\n",
    "    )  # Join together\n",
    "\n",
    "    print(\"\\n dataframe concat\", dataframe.columns)\n",
    "    print(\" ----------------------------- \")\n",
    "\n",
    "    # Drop columns with all equal values or std=0\n",
    "    std = np.std(dataframe[features_evaluated], axis=0)\n",
    "    columns_to_mantain_arg = np.where(std >= 0.00001)[0]\n",
    "    columns_to_drop_arg = np.where(std < 0.00001)[0]\n",
    "    columns_to_mantain = [features_evaluated[i] for i in columns_to_mantain_arg]\n",
    "    columns_to_drop = [features_evaluated[i] for i in columns_to_drop_arg]\n",
    "    print(\"columns to drop \", columns_to_drop)\n",
    "    print(\" ----------------------------- \")\n",
    "    # print(features_evaluated[np.where(std == 0)[0]])\n",
    "    dataframe.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "    return dataframe, columns_to_mantain\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPARE DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input general dataframe (folds 0,1,2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25440 entries, 0 to 25439\n",
      "Columns: 285 entries, CLAP to freesound.rhythm.bpm\n",
      "dtypes: float64(261), int64(19), object(5)\n",
      "memory usage: 55.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv('../data/main_files/SoundLights_complete.csv')\n",
    "\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into sections of data to use (ARAUS, Freesound or CLAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARAUS features dataframe\n",
    "df_ARAUS=df[general_info+ARAUS_features]\n",
    "# Freesound features dataframe\n",
    "df_Freesound=df[general_info+Freesound_features]\n",
    "# CLAP embeddings dataframe\n",
    "df_clap=df[general_info+[\"CLAP\"]]\n",
    "#print(df_clap[\"CLAP\"].values[1])\n",
    "#print(df_clap[\"info.P_ground_truth\"].values[1])\n",
    "all_columns=general_info+clap_features\n",
    "full_list=[]\n",
    "for index, row in df_clap.iterrows():\n",
    "    string_list=row[\"CLAP\"].split(\"[\")[2].split(\"]\")[0].split(\",\")\n",
    "    clap_list = [float(item) for item in string_list]\n",
    "    #clap_list=clap_list[0:101] ##############################!!!!!!!!!!!!\n",
    "    complete_new_row=list(row[general_info].values)+clap_list\n",
    "    full_list.append(complete_new_row)\n",
    "df_clap=pd.DataFrame(data=full_list, columns=all_columns)\n",
    "#print(df_clap.iloc[1][[\"info.P_ground_truth\", \"clap_0\",\"clap_1\",\"clap_2\" ]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input dataframe of new audios to validate (fold 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real= pd.read_csv('../data/main_files/SoundLights_fold6.csv')\n",
    "# Adapt CLAP features\n",
    "df_fold6=df_real[ARAUS_features+Freesound_features+masker_features+[\"info.P_ground_truth\", \"info.E_ground_truth\", \"CLAP\"]]\n",
    "all_columns=ARAUS_features+Freesound_features+masker_features+[\"info.P_ground_truth\", \"info.E_ground_truth\"]+clap_features\n",
    "full_list=[]\n",
    "for index, row in df_fold6.iterrows():\n",
    "    string_list=row[\"CLAP\"].split(\"[\")[1].split(\"]\")[0].split(\",\")\n",
    "    clap_list = [float(item) for item in string_list]\n",
    "    #clap_list=clap_list[0:101] ##############################!!!!!!!!!!!!\n",
    "    complete_new_row=list(row[ARAUS_features+Freesound_features+masker_features+[\"info.P_ground_truth\", \"info.E_ground_truth\"]].values)+clap_list\n",
    "    full_list.append(complete_new_row)\n",
    "df_fold6=pd.DataFrame(data=full_list, columns=all_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select data to evaluate and adapt masker features if desired\n",
    "\n",
    "Here is where changes have to be made to try different configurations\n",
    "\n",
    "1) Which dataframe/set of features to evaluate. Change input df and features to prepare_data_models()\n",
    "2) Decide if maskers are used or not by adding them to features_to_use\n",
    "3) Decide if maskers are transformed by changing masker_gain and/or masker_transform\n",
    "4) To add normalizations, discomment the code that normalises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 240 entries, 0 to 239\n",
      "Columns: 145 entries, info.file to ARAUS.energy_frequency.20000_0\n",
      "dtypes: float64(122), int64(19), object(4)\n",
      "memory usage: 273.8+ KB\n",
      "\n",
      " dataframe fold 0 before anything None\n",
      " ----------------------------- \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 48 entries, ('R1001_segment_binaural_44100.wav', 'bird_10001.wav', 0) to ('R1008_segment_binaural_44100.wav', 'wind_10001.wav', 0)\n",
      "Columns: 140 entries, info.fold to ARAUS.energy_frequency.20000_0\n",
      "dtypes: float64(140)\n",
      "memory usage: 52.9+ KB\n",
      "\n",
      " dataframe fold 0 after drop and groupby None\n",
      " ----------------------------- \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25200 entries, 240 to 25439\n",
      "Columns: 145 entries, info.file to ARAUS.energy_frequency.20000_0\n",
      "dtypes: float64(122), int64(19), object(4)\n",
      "memory usage: 28.1+ MB\n",
      "\n",
      " dataframe fildered info None\n",
      " ----------------------------- \n",
      "\n",
      " dataframe concat Index(['info.fold', 'info.stimulus_index', 'info.wav_gain', 'info.time_taken',\n",
      "       'info.is_attention', 'info.pleasant', 'info.eventful', 'info.chaotic',\n",
      "       'info.vibrant', 'info.uneventful',\n",
      "       ...\n",
      "       'ARAUS.energy_frequency.08000_0', 'ARAUS.energy_frequency.10000_0',\n",
      "       'ARAUS.energy_frequency.12500_0', 'ARAUS.energy_frequency.16000_0',\n",
      "       'ARAUS.energy_frequency.20000_0', 'info.file', 'info.participant',\n",
      "       'info.soundscape', 'info.masker', 'info.smr'],\n",
      "      dtype='object', length=145)\n",
      " ----------------------------- \n",
      "columns to drop  ['ARAUS.energy_frequency.00005_0', 'ARAUS.energy_frequency.00008_0', 'ARAUS.energy_frequency.00010_0', 'ARAUS.energy_frequency.00020_0']\n",
      " ----------------------------- \n"
     ]
    }
   ],
   "source": [
    "#!!!!!! CHANGE\n",
    "masker_gain=1\n",
    "masker_transform=\"None\" #\"-1,1\"\n",
    "#!!!!!! CHANGE\n",
    "\n",
    "df_to_use,features_to_use=prepare_data_models(df_ARAUS.copy(), ARAUS_features,masker_transform, masker_gain) #!!!!!! CHANGE DATAFRAME AND FEATURES\n",
    "\n",
    "#!!!!!! CHANGE\n",
    "features_to_use=features_to_use#+[\"info.masker_bird\",\"info.masker_construction\",\"info.masker_silence\",\"info.masker_traffic\", \"info.masker_water\",\"info.masker_wind\"] \n",
    "#!!!!!! CHANGE\n",
    "pd.options.mode.chained_assignment = None  # Ignore warning, default='warn'\n",
    "if(masker_transform==\"-1,1\"):\n",
    "    df_fold6[\"info.masker_bird\"]=(df_fold6[\"info.masker_bird\"]*2-1)*masker_gain\n",
    "    df_fold6[\"info.masker_construction\"]=(df_fold6[\"info.masker_construction\"]*2-1)*masker_gain\n",
    "    df_fold6[\"info.masker_silence\"]=(df_fold6[\"info.masker_silence\"]*2-1)*masker_gain\n",
    "    df_fold6[\"info.masker_traffic\"]=(df_fold6[\"info.masker_traffic\"]*2-1)*masker_gain\n",
    "    df_fold6[\"info.masker_water\"]=(df_fold6[\"info.masker_water\"]*2-1)*masker_gain\n",
    "    df_fold6[\"info.masker_wind\"]=(df_fold6[\"info.masker_wind\"]*2-1)*masker_gain\n",
    "else:\n",
    "    df_fold6[\"info.masker_bird\"]=df_fold6[\"info.masker_bird\"]*masker_gain\n",
    "    df_fold6[\"info.masker_construction\"]=df_fold6[\"info.masker_construction\"]*masker_gain\n",
    "    df_fold6[\"info.masker_silence\"]=df_fold6[\"info.masker_silence\"]*masker_gain\n",
    "    df_fold6[\"info.masker_traffic\"]=df_fold6[\"info.masker_traffic\"]*masker_gain\n",
    "    df_fold6[\"info.masker_water\"]=df_fold6[\"info.masker_water\"]*masker_gain\n",
    "    df_fold6[\"info.masker_wind\"]=df_fold6[\"info.masker_wind\"]*masker_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for best parameters - ARAUS or Freesound features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |         Mean squared error        |             Mean  error            |\n",
      "Fold |--------+--------+--------+--------|--------+--------+--------|---------|\n",
      "     | Train  |   Val  |  Test  |Test(f6)| Train  |   Val  |  Test  | Test(f6)|\n",
      "-----+--------+--------+--------+--------+--------+--------+--------+----------\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Parameters  10\n",
      "Mean | 0.0335 | 0.1494 | 0.0846 | 0.1030 | 0.1343 | 0.3133 | 0.2351 | 0.2475 |\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Parameters  20\n",
      "Mean | 0.0303 | 0.1421 | 0.0809 | 0.0828 | 0.1294 | 0.3067 | 0.2343 | 0.2223 |\n",
      ".\n",
      ".\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_RFR.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_RFR.ipynb#X16sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" X_train, min, max=normalize_columns_minmax(X_train)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_RFR.ipynb#X16sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mX_val= (X_val - min) / (max - min)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_RFR.ipynb#X16sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mX_test= (X_test - min) / (max - min)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_RFR.ipynb#X16sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mX_fold6= (X_fold6 - min) / (max - min) \"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_RFR.ipynb#X16sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m# Fit model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_RFR.ipynb#X16sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m X_LR \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_RFR.ipynb#X16sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_RFR.ipynb#X16sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m#print(\"iterations \", X_LR.n_iter_, X_LR.n_features_in_)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_RFR.ipynb#X16sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amaiasagastimartinez/Desktop/Master/Master-Thesis/Code/src/Find_best_params_RFR.ipynb#X16sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39m# Get MSEs\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/araus-mac/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    477\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    478\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    479\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    480\u001b[0m )(\n\u001b[1;32m    481\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    482\u001b[0m         t,\n\u001b[1;32m    483\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    484\u001b[0m         X,\n\u001b[1;32m    485\u001b[0m         y,\n\u001b[1;32m    486\u001b[0m         sample_weight,\n\u001b[1;32m    487\u001b[0m         i,\n\u001b[1;32m    488\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    489\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    490\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    491\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    492\u001b[0m     )\n\u001b[1;32m    493\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    494\u001b[0m )\n\u001b[1;32m    496\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/miniconda3/envs/araus-mac/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniconda3/envs/araus-mac/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniconda3/envs/araus-mac/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/araus-mac/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    187\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 189\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    190\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/araus-mac/lib/python3.10/site-packages/sklearn/tree/_classes.py:1342\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1314\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \n\u001b[1;32m   1316\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1342\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   1343\u001b[0m         X,\n\u001b[1;32m   1344\u001b[0m         y,\n\u001b[1;32m   1345\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1346\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m   1347\u001b[0m     )\n\u001b[1;32m   1348\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/araus-mac/lib/python3.10/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "# Suppress ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print('     |         Mean squared error        |             Mean  error            |')\n",
    "print('Fold |--------+--------+--------+--------|--------+--------+--------|---------|')\n",
    "print('     | Train  |   Val  |  Test  |Test(f6)| Train  |   Val  |  Test  | Test(f6)|')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+--------+----------')\n",
    "n_estimators=[10,20,50,100, 150, 180, 200, 250, 300, 350, 400, 500]\n",
    "\n",
    "prev_mean=9999\n",
    "for value in n_estimators:\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=value, random_state=0)\n",
    "    #print(f'Investigating performance of {model} model...')\n",
    "\n",
    "    MSEs_train = []\n",
    "    MSEs_val = []\n",
    "    MSEs_test = []\n",
    "    MSEs_fold6 = []\n",
    "    MEs_train = []\n",
    "    MEs_val = []\n",
    "    MEs_test = []\n",
    "    MEs_fold6 = []\n",
    "\n",
    "    \n",
    "    for val_fold in [1,2,3,4,5]:\n",
    "        \n",
    "        # Extract dataframes\n",
    "        df_train = df_to_use[(df_to_use['info.fold'] != val_fold) & (df_to_use['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "        df_val   = df_to_use[df_to_use['info.fold'] == val_fold]\n",
    "        df_test  = df_to_use[df_to_use['info.fold'] == 0] \n",
    "\n",
    "\n",
    "        # Get ground-truth labels\n",
    "        Y_train = df_train['info.P_ground_truth'].values#[0:10]\n",
    "        Y_val = df_val['info.P_ground_truth'].values\n",
    "        Y_test = df_test['info.P_ground_truth'].values\n",
    "        Y_fold6 = df_fold6['info.P_ground_truth'].values\n",
    "\n",
    "\n",
    "        # Get feature matrices\n",
    "        X_train = df_train[features_to_use].values#[:,0:100]\n",
    "        X_val =df_val[features_to_use].values#[:,0:100]\n",
    "        X_test = df_test[features_to_use].values#[:,0:100]\n",
    "        X_fold6 = df_fold6[features_to_use].values#[:,0:100]\n",
    "\n",
    "        # Get features normalized_data = (data - mean) / (std)\n",
    "        \"\"\" X_train, mean, std=normalize_columns(X_train)\n",
    "        X_val= (X_val - mean) / (std)\n",
    "        X_test= (X_test - mean) / (std)\n",
    "        X_fold6= (X_fold6 - mean) / (std) \"\"\"\n",
    "        # Get features normalized_data = (data - min) / (max-min)\n",
    "        \"\"\" X_train, min, max=normalize_columns_minmax(X_train)\n",
    "        X_val= (X_val - min) / (max - min)\n",
    "        X_test= (X_test - min) / (max - min)\n",
    "        X_fold6= (X_fold6 - min) / (max - min) \"\"\"\n",
    "\n",
    "        # Fit model\n",
    "        X_LR = model.fit(X_train, Y_train)\n",
    "        print(\".\")\n",
    "        #print(\"iterations \", X_LR.n_iter_, X_LR.n_features_in_)\n",
    "\n",
    "        # Get MSEs\n",
    "        MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "        MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "        MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "        MSE_fold6 = np.mean((clip(X_LR.predict(X_fold6)) - Y_fold6)**2)\n",
    "        ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "        ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "        ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "        ME_fold6 = np.mean(np.abs(clip(X_LR.predict(X_fold6)) - Y_fold6))\n",
    "\n",
    "        # Add metrics\n",
    "        MSEs_train.append(MSE_train)\n",
    "        MSEs_val.append(MSE_val)\n",
    "        MSEs_test.append(MSE_test)\n",
    "        MSEs_fold6.append(MSE_fold6)\n",
    "        MEs_train.append(ME_train)\n",
    "        MEs_val.append(ME_val)\n",
    "        MEs_test.append(ME_test)\n",
    "        MEs_fold6.append(ME_fold6)\n",
    "\n",
    "        #print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "    print(\"Parameters \",value)\n",
    "    print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MSEs_fold6):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} | {np.mean(MEs_fold6):.4f} |')\n",
    "\n",
    "    current_mean=(np.mean(MEs_val)+np.mean(MEs_test)+np.mean(MEs_fold6))/3\n",
    "    if current_mean<prev_mean:\n",
    "        prev_mean=current_mean\n",
    "        chosen=(value)\n",
    "\n",
    "    \n",
    "print(\"Best parameters were \", chosen, \" giving a mean of \", prev_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
