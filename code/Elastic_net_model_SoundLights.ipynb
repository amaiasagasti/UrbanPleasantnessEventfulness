{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from SoundLights.features_groups import  ARAUS_features, Freesound_features, mix_features\n",
    "\n",
    "normalise = lambda X: (X-np.mean(X,axis=0,keepdims=True))/np.std(X,axis=0,keepdims=True) # Normalise an (n,p) numpy array to mean 0, variance 1.\n",
    "clip = lambda x, x_min = -1, x_max = 1: np.where(np.where(x < x_min,x_min,x) > x_max, x_max, np.where(x < x_min,x_min,x)) # Clip an array to values between x_min and x_max."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARAUS.sharpness.avg', 'ARAUS.sharpness.max', 'ARAUS.sharpness.p05', 'ARAUS.sharpness.p10', 'ARAUS.sharpness.p20', 'ARAUS.sharpness.p30', 'ARAUS.sharpness.p40', 'ARAUS.sharpness.p50', 'ARAUS.sharpness.p60', 'ARAUS.sharpness.p70', 'ARAUS.sharpness.p80', 'ARAUS.sharpness.p90', 'ARAUS.sharpness.p95', 'ARAUS.loudness.avg', 'ARAUS.loudness.max', 'ARAUS.loudness.p05', 'ARAUS.loudness.p10', 'ARAUS.loudness.p20', 'ARAUS.loudness.p30', 'ARAUS.loudness.p40', 'ARAUS.loudness.p50', 'ARAUS.loudness.p60', 'ARAUS.loudness.p70', 'ARAUS.loudness.p80', 'ARAUS.loudness.p90', 'ARAUS.loudness.p95', 'ARAUS.fluctuation.avg', 'ARAUS.fluctuation.max', 'ARAUS.fluctuation.p05', 'ARAUS.fluctuation.p10', 'ARAUS.fluctuation.p20', 'ARAUS.fluctuation.p30', 'ARAUS.fluctuation.p40', 'ARAUS.fluctuation.p50', 'ARAUS.fluctuation.p60', 'ARAUS.fluctuation.p70', 'ARAUS.fluctuation.p80', 'ARAUS.fluctuation.p90', 'ARAUS.fluctuation.p95', 'ARAUS.LA.avg', 'ARAUS.LA.min', 'ARAUS.LA.max', 'ARAUS.LA.p05', 'ARAUS.LA.p10', 'ARAUS.LA.p20', 'ARAUS.LA.p30', 'ARAUS.LA.p40', 'ARAUS.LA.p50', 'ARAUS.LA.p60', 'ARAUS.LA.p70', 'ARAUS.LA.p80', 'ARAUS.LA.p90', 'ARAUS.LA.p95', 'ARAUS.LC.avg', 'ARAUS.LC.min', 'ARAUS.LC.max', 'ARAUS.LC.p05', 'ARAUS.LC.p10', 'ARAUS.LC.p20', 'ARAUS.LC.p30', 'ARAUS.LC.p40', 'ARAUS.LC.p50', 'ARAUS.LC.p60', 'ARAUS.LC.p70', 'ARAUS.LC.p80', 'ARAUS.LC.p90', 'ARAUS.LC.p95', 'ARAUS.roughness.avg', 'ARAUS.roughness.max', 'ARAUS.roughness.p05', 'ARAUS.roughness.p10', 'ARAUS.roughness.p20', 'ARAUS.roughness.p30', 'ARAUS.roughness.p40', 'ARAUS.roughness.p50', 'ARAUS.roughness.p60', 'ARAUS.roughness.p70', 'ARAUS.roughness.p80', 'ARAUS.roughness.p90', 'ARAUS.roughness.p95', 'ARAUS.energy_frequency.00006_3', 'ARAUS.energy_frequency.00012_5', 'ARAUS.energy_frequency.00016_0', 'ARAUS.energy_frequency.00025_0', 'ARAUS.energy_frequency.00031_5', 'ARAUS.energy_frequency.00040_0', 'ARAUS.energy_frequency.00050_0', 'ARAUS.energy_frequency.00063_0', 'ARAUS.energy_frequency.00080_0', 'ARAUS.energy_frequency.00100_0', 'ARAUS.energy_frequency.00125_0', 'ARAUS.energy_frequency.00160_0', 'ARAUS.energy_frequency.00200_0', 'ARAUS.energy_frequency.00250_0', 'ARAUS.energy_frequency.00315_0', 'ARAUS.energy_frequency.00400_0', 'ARAUS.energy_frequency.00500_0', 'ARAUS.energy_frequency.00630_0', 'ARAUS.energy_frequency.00800_0', 'ARAUS.energy_frequency.01000_0', 'ARAUS.energy_frequency.01250_0', 'ARAUS.energy_frequency.01600_0', 'ARAUS.energy_frequency.02000_0', 'ARAUS.energy_frequency.02500_0', 'ARAUS.energy_frequency.03150_0', 'ARAUS.energy_frequency.04000_0', 'ARAUS.energy_frequency.05000_0', 'ARAUS.energy_frequency.06300_0', 'ARAUS.energy_frequency.08000_0', 'ARAUS.energy_frequency.10000_0', 'ARAUS.energy_frequency.12500_0', 'ARAUS.energy_frequency.16000_0', 'ARAUS.energy_frequency.20000_0']\n"
     ]
    }
   ],
   "source": [
    "responses_ARAUS= pd.read_csv(os.path.join('..','data','SoundLights_ARAUS.csv'), dtype = {'info.participant':str}) #, dtype = {'participant':str}\n",
    "responses_ARAUS=responses_ARAUS.drop(\"info.file\", axis=1)\n",
    "responses_ARAUS=responses_ARAUS.drop(\"info.participant\", axis=1)\n",
    "\n",
    "# Drop columns that contain all zero values\n",
    "# Store column names before dropping\n",
    "columns_before = responses_ARAUS.columns.tolist()\n",
    "# Drop zero-columns\n",
    "responses_ARAUS = responses_ARAUS.loc[:, (responses_ARAUS != 0).any(axis=0)]\n",
    "# Store column names after dropping\n",
    "columns_after = responses_ARAUS.columns.tolist()\n",
    "# Determine which columns were dropped\n",
    "columns_dropped = [col for col in columns_before if col not in columns_after]\n",
    "# Drop those columns from ARAUS_features\n",
    "ARAUS_features = [col for col in ARAUS_features if col not in columns_dropped]\n",
    "print(ARAUS_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_Freesound= pd.read_csv(os.path.join('..','data','SoundLights_Freesound.csv')) #, dtype = {'participant':str}\n",
    "responses_Freesound=responses_Freesound.drop(\"info.file\", axis=1)\n",
    "responses_Freesound=responses_Freesound.drop(\"info.participant\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_Mix= pd.read_csv(os.path.join('..','data','SoundLights_mix.csv')) #, dtype = {'participant':str}\n",
    "responses_Mix=responses_Mix.drop(\"info.file\", axis=1)\n",
    "responses_Mix=responses_Mix.drop(\"info.participant\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) PLEASANTNESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) ARAUS - With default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating performance of ElasticNet() model...\n",
      "     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "   1 | 0.1439 | 0.1415 | 0.0901 | 0.3134 | 0.3103 | 0.2468 |  0.2171 | 20160 |  5040 |  48  |  113  |   2   |\n",
      "   2 | 0.1447 | 0.1377 | 0.0931 | 0.3146 | 0.3045 | 0.2513 |  0.2331 | 20160 |  5040 |  48  |  113  |   2   |\n",
      "   3 | 0.1421 | 0.1504 | 0.0928 | 0.3110 | 0.3203 | 0.2509 |  0.1883 | 20160 |  5040 |  48  |  113  |   2   |\n",
      "   4 | 0.1422 | 0.1502 | 0.0933 | 0.3108 | 0.3235 | 0.2516 |  0.2074 | 20160 |  5040 |  48  |  113  |   2   |\n",
      "   5 | 0.1445 | 0.1403 | 0.0904 | 0.3142 | 0.3086 | 0.2472 |  0.1996 | 20160 |  5040 |  48  |  113  |   2   |\n",
      "Mean | 0.1435 | 0.1440 | 0.0919 | 0.3128 | 0.3134 | 0.2496 |\n",
      "\n",
      "ARAUS.loudness.max: -0.005209220763375817\n",
      "ARAUS.energy_frequency.10000_0: -0.0010240021582759258\n"
     ]
    }
   ],
   "source": [
    "model = sklearn.linear_model.ElasticNet()\n",
    "print(f'Investigating performance of {model} model...')\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "MEs_train = []\n",
    "MEs_val = []\n",
    "MEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses_ARAUS[(responses_ARAUS['info.fold'] != val_fold) & (responses_ARAUS['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses_ARAUS[responses_ARAUS['info.fold'] == val_fold]\n",
    "    df_test  = responses_ARAUS[responses_ARAUS['info.fold'] == 0].groupby(['info.soundscape','info.masker','info.smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['info.P_ground_truth'].values\n",
    "    Y_val = df_val['info.P_ground_truth'].values\n",
    "    Y_test = df_test['info.P_ground_truth'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[ARAUS_features].values\n",
    "    X_val =df_val[ARAUS_features].values\n",
    "    X_test = df_test[ARAUS_features].values    \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "    MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "    MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "    ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "    ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "    ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "    MEs_train.append(ME_train)\n",
    "    MEs_val.append(ME_val)\n",
    "    MEs_test.append(ME_test)\n",
    "\n",
    "    # Display important coefficients\n",
    "    \"\"\" coefficients = X_LR.coef_\n",
    "    feature_importances = list(zip(ARAUS_features, coefficients))\n",
    "    feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    for feature, importance in feature_importances:\n",
    "        if float(importance)!=0:\n",
    "            print(f\"{feature}: {importance}\") \"\"\"\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} |')\n",
    "print()\n",
    "\n",
    "\n",
    "coefficients = X_LR.coef_\n",
    "feature_importances = list(zip(ARAUS_features, coefficients))\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "for feature, importance in feature_importances:\n",
    "    if float(importance)!=0:\n",
    "        print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Freesound - With default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating performance of ElasticNet() model...\n",
      "     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amaiasagastimartinez/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.295e+03, tolerance: 3.138e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1 | 0.1261 | 0.1291 | 0.0769 | 0.2877 | 0.2918 | 0.2263 | -1.7373 | 20160 |  5040 |  48  |  139  |  14   |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amaiasagastimartinez/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+03, tolerance: 3.151e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2 | 0.1294 | 0.1166 | 0.0795 | 0.2924 | 0.2758 | 0.2304 | -1.6041 | 20160 |  5040 |  48  |  139  |  15   |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amaiasagastimartinez/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+03, tolerance: 3.109e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3 | 0.1257 | 0.1326 | 0.0792 | 0.2882 | 0.2918 | 0.2259 | -1.5496 | 20160 |  5040 |  48  |  139  |  14   |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amaiasagastimartinez/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+03, tolerance: 3.087e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4 | 0.1248 | 0.1358 | 0.0802 | 0.2859 | 0.3023 | 0.2280 | -1.6148 | 20160 |  5040 |  48  |  139  |  15   |\n",
      "   5 | 0.1256 | 0.1310 | 0.0777 | 0.2867 | 0.2942 | 0.2304 | -1.7943 | 20160 |  5040 |  48  |  139  |  17   |\n",
      "Mean | 0.1263 | 0.1290 | 0.0787 | 0.2882 | 0.2912 | 0.2282 |\n",
      "\n",
      "freesound.lowlevel.mfcc.avg.c0: -0.001948133089964581\n",
      "freesound.lowlevel.mfcc.var.c4: 0.0002039009812083063\n",
      "freesound.lowlevel.mfcc.var.c2: -0.00018790639543036085\n",
      "freesound.lowlevel.mfcc.var.c3: 0.00011957705865956737\n",
      "freesound.lowlevel.mfcc.var.c6: 0.00011847394006583769\n",
      "freesound.lowlevel.spectral_rolloff.avg: 6.288231807923362e-05\n",
      "freesound.lowlevel.mfcc.var.c0: -5.14027003379636e-05\n",
      "freesound.lowlevel.spectral_kurtosis.var: -3.0189709897704384e-05\n",
      "freesound.lowlevel.spectral_centroid.p20: -2.0784049753560968e-05\n",
      "freesound.lowlevel.spectral_rolloff.p80: -1.1197597092819076e-05\n",
      "freesound.lowlevel.mfcc.var.c5: 9.302821612018578e-06\n",
      "freesound.lowlevel.spectral_rolloff.var: -2.9019303640113923e-08\n",
      "freesound.lowlevel.spectral_centroid.var: 2.7846717984170933e-08\n",
      "freesound.lowlevel.spectral_spread.p80: 1.5249555997284477e-08\n",
      "freesound.lowlevel.spectral_spread.p20: -1.522556715723034e-08\n",
      "freesound.lowlevel.spectral_spread.avg: 8.603248000517923e-09\n",
      "freesound.lowlevel.spectral_spread.var: 6.971141603850969e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amaiasagastimartinez/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+03, tolerance: 3.150e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "model = sklearn.linear_model.ElasticNet()\n",
    "print(f'Investigating performance of {model} model...')\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "MEs_train = []\n",
    "MEs_val = []\n",
    "MEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses_Freesound[(responses_Freesound['info.fold'] != val_fold) & (responses_Freesound['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses_Freesound[responses_Freesound['info.fold'] == val_fold]\n",
    "    df_test  = responses_Freesound[responses_Freesound['info.fold'] == 0].groupby(['info.soundscape','info.masker','info.smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['info.P_ground_truth'].values\n",
    "    Y_val = df_val['info.P_ground_truth'].values\n",
    "    Y_test = df_test['info.P_ground_truth'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[Freesound_features].values\n",
    "    X_val =df_val[Freesound_features].values\n",
    "    X_test = df_test[Freesound_features].values    \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "    MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "    MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "    ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "    ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "    ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "    MEs_train.append(ME_train)\n",
    "    MEs_val.append(ME_val)\n",
    "    MEs_test.append(ME_test)\n",
    "\n",
    "    # Display important coefficients\n",
    "    \"\"\" coefficients = X_LR.coef_\n",
    "    feature_importances = list(zip(ARAUS_features, coefficients))\n",
    "    feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    for feature, importance in feature_importances:\n",
    "        if float(importance)!=0:\n",
    "            print(f\"{feature}: {importance}\") \"\"\"\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} |')\n",
    "print()\n",
    "\n",
    "\n",
    "coefficients = X_LR.coef_\n",
    "feature_importances = list(zip(Freesound_features, coefficients))\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "for feature, importance in feature_importances:\n",
    "    if float(importance)!=0:\n",
    "        print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) ARAUS - Defining parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "   1 | 0.1334 | 0.1330 | 0.0740 | 0.2989 | 0.2974 | 0.2309 |  0.5024 | 20160 |  5040 |  48  |  113  |  12   |\n",
      "   2 | 0.1343 | 0.1318 | 0.0774 | 0.2999 | 0.2936 | 0.2345 |  0.1541 | 20160 |  5040 |  48  |  113  |  10   |\n",
      "   3 | 0.1336 | 0.1369 | 0.0747 | 0.2992 | 0.3015 | 0.2307 |  0.7271 | 20160 |  5040 |  48  |  113  |  10   |\n",
      "   4 | 0.1309 | 0.1424 | 0.0795 | 0.2951 | 0.3130 | 0.2404 |  0.3981 | 20160 |  5040 |  48  |  113  |  10   |\n",
      "   5 | 0.1340 | 0.1338 | 0.0720 | 0.2993 | 0.3002 | 0.2259 |  0.4347 | 20160 |  5040 |  48  |  113  |  11   |\n",
      "Mean | 0.1333 | 0.1356 | 0.0755 | 0.2985 | 0.3011 | 0.2325 |\n",
      "\n",
      "ARAUS.energy_frequency.00006_3: -0.011545978614603462\n",
      "ARAUS.energy_frequency.02000_0: -0.004209441493137054\n",
      "ARAUS.LC.max: -0.0035661102463664554\n",
      "ARAUS.energy_frequency.00063_0: -0.002723472713655504\n",
      "ARAUS.energy_frequency.04000_0: 0.0024236118820533804\n",
      "ARAUS.energy_frequency.10000_0: -0.0020115121397994147\n",
      "ARAUS.energy_frequency.00031_5: -0.0018894584726882498\n",
      "ARAUS.energy_frequency.08000_0: -0.0013186421228955738\n",
      "ARAUS.loudness.max: -0.001311372384924452\n",
      "ARAUS.energy_frequency.00200_0: -0.0008724018634401651\n",
      "ARAUS.energy_frequency.20000_0: 8.198509059687406e-05\n",
      "LIST  ['ARAUS.energy_frequency.00006_3', 'ARAUS.energy_frequency.02000_0', 'ARAUS.LC.max', 'ARAUS.energy_frequency.00063_0', 'ARAUS.energy_frequency.04000_0', 'ARAUS.energy_frequency.10000_0', 'ARAUS.energy_frequency.00031_5', 'ARAUS.energy_frequency.08000_0', 'ARAUS.loudness.max', 'ARAUS.energy_frequency.00200_0', 'ARAUS.energy_frequency.20000_0']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "# Define your ElasticNet model with specific hyperparameters\n",
    "alpha = 0.1  # Example value, adjust as needed\n",
    "l1_ratio = 0.7  # Example value, adjust as needed\n",
    "model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, selection=\"random\")\n",
    "#print(f'Investigating performance of {model} model...')\n",
    "\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "MEs_train = []\n",
    "MEs_val = []\n",
    "MEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses_ARAUS[(responses_ARAUS['info.fold'] != val_fold) & (responses_ARAUS['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses_ARAUS[responses_ARAUS['info.fold'] == val_fold]\n",
    "    df_test  = responses_ARAUS[responses_ARAUS['info.fold'] == 0].groupby(['info.soundscape','info.masker','info.smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['info.P_ground_truth'].values\n",
    "    Y_val = df_val['info.P_ground_truth'].values\n",
    "    Y_test = df_test['info.P_ground_truth'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[ARAUS_features].values\n",
    "    X_val =df_val[ARAUS_features].values\n",
    "    X_test = df_test[ARAUS_features].values    \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model.fit(X_train, Y_train)\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "    MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "    MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "    ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "    ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "    ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "    MEs_train.append(ME_train)\n",
    "    MEs_val.append(ME_val)\n",
    "    MEs_test.append(ME_test)\n",
    "\n",
    "    # Display important coefficients\n",
    "    \"\"\" coefficients = X_LR.coef_\n",
    "    feature_importances = list(zip(ARAUS_features, coefficients))\n",
    "    feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    for feature, importance in feature_importances:\n",
    "        if float(importance)!=0:\n",
    "            print(f\"{feature}: {importance}\") \"\"\"\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} |')\n",
    "print()\n",
    "\n",
    "\n",
    "coefficients = X_LR.coef_\n",
    "feature_importances = list(zip(ARAUS_features, coefficients))\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "list_features=[]\n",
    "for feature, importance in feature_importances:\n",
    "    if float(importance)!=0:\n",
    "        print(f\"{feature}: {importance}\")\n",
    "        list_features.append(feature)\n",
    "print(\"LIST \",list_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4) Freesound - Defining parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating performance of ElasticNet(alpha=0.2, selection='random') model...\n",
      "     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amaiasagastimartinez/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e+03, tolerance: 3.138e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1 | 0.1255 | 0.1284 | 0.0750 | 0.2868 | 0.2906 | 0.2239 | -1.7995 | 20160 |  5040 |  48  |  139  |  25   |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amaiasagastimartinez/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+03, tolerance: 3.151e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2 | 0.1286 | 0.1153 | 0.0809 | 0.2911 | 0.2741 | 0.2351 | -1.8058 | 20160 |  5040 |  48  |  139  |  23   |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amaiasagastimartinez/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.267e+03, tolerance: 3.109e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3 | 0.1247 | 0.1327 | 0.0752 | 0.2865 | 0.2912 | 0.2183 | -1.5313 | 20160 |  5040 |  48  |  139  |  23   |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amaiasagastimartinez/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.256e+03, tolerance: 3.087e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4 | 0.1235 | 0.1359 | 0.0803 | 0.2841 | 0.3019 | 0.2306 | -1.8059 | 20160 |  5040 |  48  |  139  |  25   |\n",
      "   5 | 0.1243 | 0.1335 | 0.0767 | 0.2849 | 0.2966 | 0.2307 | -1.7516 | 20160 |  5040 |  48  |  139  |  26   |\n",
      "Mean | 0.1253 | 0.1292 | 0.0776 | 0.2867 | 0.2909 | 0.2277 |\n",
      "\n",
      "freesound.lowlevel.mfcc.avg.c0: -0.0020697146781121665\n",
      "freesound.lowlevel.mfcc.p20.c4: -0.0010782946422394494\n",
      "freesound.lowlevel.mfcc.avg.c1: -0.000509201181315753\n",
      "freesound.lowlevel.mfcc.p20.c5: -0.0003510832550836617\n",
      "freesound.lowlevel.mfcc.p80.c1: -0.000299237713641901\n",
      "freesound.lowlevel.mfcc.var.c6: 0.00028185256423993496\n",
      "freesound.lowlevel.mfcc.var.c2: -0.00024820452445719075\n",
      "freesound.lowlevel.mfcc.var.c7: 0.00019870783259350668\n",
      "freesound.lowlevel.mfcc.var.c4: 0.00014714275683947315\n",
      "freesound.lowlevel.spectral_centroid.p20: -0.00014707458786113845\n",
      "freesound.lowlevel.spectral_centroid.avg: 0.0001363724325270457\n",
      "freesound.lowlevel.mfcc.var.c3: 0.00011446808099579026\n",
      "freesound.lowlevel.spectral_rolloff.avg: 9.175999001950928e-05\n",
      "freesound.lowlevel.spectral_rolloff.p80: -4.595175669754859e-05\n",
      "freesound.lowlevel.spectral_kurtosis.var: -4.4711094470488404e-05\n",
      "freesound.lowlevel.mfcc.var.c0: -4.2803412207596e-05\n",
      "freesound.lowlevel.mfcc.var.c5: 3.6163334827362185e-05\n",
      "freesound.lowlevel.mfcc.var.c8: 3.273983083350733e-05\n",
      "freesound.lowlevel.mfcc.var.c1: -1.429139574696877e-05\n",
      "freesound.lowlevel.spectral_rolloff.p20: 5.106340112695873e-06\n",
      "freesound.lowlevel.spectral_rolloff.var: -3.426042179783331e-08\n",
      "freesound.lowlevel.spectral_spread.p20: -1.9661171663246625e-08\n",
      "freesound.lowlevel.spectral_spread.p80: 1.9375981982704443e-08\n",
      "freesound.lowlevel.spectral_centroid.var: 1.396786688714903e-08\n",
      "freesound.lowlevel.spectral_spread.avg: 6.785656922425532e-09\n",
      "freesound.lowlevel.spectral_spread.var: 2.344912198157933e-15\n",
      "LIST  ['freesound.lowlevel.mfcc.avg.c0', 'freesound.lowlevel.mfcc.p20.c4', 'freesound.lowlevel.mfcc.avg.c1', 'freesound.lowlevel.mfcc.p20.c5', 'freesound.lowlevel.mfcc.p80.c1', 'freesound.lowlevel.mfcc.var.c6', 'freesound.lowlevel.mfcc.var.c2', 'freesound.lowlevel.mfcc.var.c7', 'freesound.lowlevel.mfcc.var.c4', 'freesound.lowlevel.spectral_centroid.p20', 'freesound.lowlevel.spectral_centroid.avg', 'freesound.lowlevel.mfcc.var.c3', 'freesound.lowlevel.spectral_rolloff.avg', 'freesound.lowlevel.spectral_rolloff.p80', 'freesound.lowlevel.spectral_kurtosis.var', 'freesound.lowlevel.mfcc.var.c0', 'freesound.lowlevel.mfcc.var.c5', 'freesound.lowlevel.mfcc.var.c8', 'freesound.lowlevel.mfcc.var.c1', 'freesound.lowlevel.spectral_rolloff.p20', 'freesound.lowlevel.spectral_rolloff.var', 'freesound.lowlevel.spectral_spread.p20', 'freesound.lowlevel.spectral_spread.p80', 'freesound.lowlevel.spectral_centroid.var', 'freesound.lowlevel.spectral_spread.avg', 'freesound.lowlevel.spectral_spread.var']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amaiasagastimartinez/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e+03, tolerance: 3.150e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "# Define your ElasticNet model with specific hyperparameters\n",
    "alpha = 0.2  # Example value, adjust as needed\n",
    "l1_ratio = 0.5  # Example value, adjust as needed\n",
    "model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, selection=\"random\")\n",
    "print(f'Investigating performance of {model} model...')\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "MEs_train = []\n",
    "MEs_val = []\n",
    "MEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses_Freesound[(responses_Freesound['info.fold'] != val_fold) & (responses_Freesound['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses_Freesound[responses_Freesound['info.fold'] == val_fold]\n",
    "    df_test  = responses_Freesound[responses_Freesound['info.fold'] == 0].groupby(['info.soundscape','info.masker','info.smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['info.P_ground_truth'].values\n",
    "    Y_val = df_val['info.P_ground_truth'].values\n",
    "    Y_test = df_test['info.P_ground_truth'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[Freesound_features].values\n",
    "    X_val =df_val[Freesound_features].values\n",
    "    X_test = df_test[Freesound_features].values    \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "    MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "    MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "    ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "    ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "    ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "    MEs_train.append(ME_train)\n",
    "    MEs_val.append(ME_val)\n",
    "    MEs_test.append(ME_test)\n",
    "\n",
    "    # Display important coefficients\n",
    "    \"\"\" coefficients = X_LR.coef_\n",
    "    feature_importances = list(zip(ARAUS_features, coefficients))\n",
    "    feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    for feature, importance in feature_importances:\n",
    "        if float(importance)!=0:\n",
    "            print(f\"{feature}: {importance}\") \"\"\"\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} |')\n",
    "print()\n",
    "\n",
    "\n",
    "coefficients = X_LR.coef_\n",
    "feature_importances = list(zip(Freesound_features, coefficients))\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "list_features=[]\n",
    "for feature, importance in feature_importances:\n",
    "    if float(importance)!=0:\n",
    "        print(f\"{feature}: {importance}\")\n",
    "        list_features.append(feature)\n",
    "print(\"LIST \",list_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_features=['freesound.lowlevel.mfcc.avg.c0', 'freesound.lowlevel.mfcc.p20.c4', 'freesound.lowlevel.mfcc.avg.c1', 'freesound.lowlevel.mfcc.p20.c5', 'freesound.lowlevel.mfcc.p80.c1', 'freesound.lowlevel.mfcc.var.c6', 'freesound.lowlevel.mfcc.var.c2', 'freesound.lowlevel.mfcc.var.c7', 'freesound.lowlevel.mfcc.var.c4', 'freesound.lowlevel.spectral_centroid.p20', 'freesound.lowlevel.spectral_centroid.avg', 'freesound.lowlevel.mfcc.var.c3', 'freesound.lowlevel.spectral_rolloff.avg', 'freesound.lowlevel.spectral_rolloff.p80', 'freesound.lowlevel.spectral_kurtosis.var', 'freesound.lowlevel.mfcc.var.c0', 'freesound.lowlevel.mfcc.var.c5', 'freesound.lowlevel.mfcc.var.c8', 'freesound.lowlevel.mfcc.var.c1', 'freesound.lowlevel.spectral_rolloff.p20', 'freesound.lowlevel.spectral_rolloff.var', 'freesound.lowlevel.spectral_spread.p20', 'freesound.lowlevel.spectral_spread.p80', 'freesound.lowlevel.spectral_centroid.var', 'freesound.lowlevel.spectral_spread.avg', 'freesound.lowlevel.spectral_spread.var','ARAUS.energy_frequency.00006_3', 'ARAUS.energy_frequency.02000_0', 'ARAUS.LC.max', 'ARAUS.energy_frequency.00063_0', 'ARAUS.energy_frequency.04000_0', 'ARAUS.energy_frequency.10000_0', 'ARAUS.energy_frequency.00031_5', 'ARAUS.energy_frequency.08000_0', 'ARAUS.loudness.max', 'ARAUS.energy_frequency.00200_0', 'ARAUS.energy_frequency.20000_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating performance of ElasticNet(alpha=0.2, selection='random') model...\n",
      "     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "   1 | 0.1258 | 0.1285 | 0.0747 | 0.2870 | 0.2907 | 0.2213 | -1.8169 | 20160 |  5040 |  48  |  91   |  17   |\n",
      "   2 | 0.1290 | 0.1153 | 0.0794 | 0.2914 | 0.2741 | 0.2315 | -1.7857 | 20160 |  5040 |  48  |  91   |  17   |\n",
      "   3 | 0.1250 | 0.1321 | 0.0760 | 0.2869 | 0.2902 | 0.2180 | -1.6329 | 20160 |  5040 |  48  |  91   |  18   |\n",
      "   4 | 0.1238 | 0.1344 | 0.0779 | 0.2843 | 0.3005 | 0.2273 | -1.7497 | 20160 |  5040 |  48  |  91   |  20   |\n",
      "   5 | 0.1246 | 0.1328 | 0.0770 | 0.2851 | 0.2955 | 0.2255 | -1.8332 | 20160 |  5040 |  48  |  91   |  20   |\n",
      "Mean | 0.1256 | 0.1286 | 0.0770 | 0.2869 | 0.2902 | 0.2247 |\n",
      "\n",
      "freesound.lowlevel.mfcc.avg.c0: -0.0020894723849968814\n",
      "freesound.lowlevel.mfcc.avg.c4: -0.0009722679690943091\n",
      "ARAUS.loudness.var: 0.000679088883788099\n",
      "freesound.lowlevel.mfcc.avg.c1: -0.0006267757181282818\n",
      "freesound.lowlevel.mfcc.var.c6: 0.00030831428051993434\n",
      "freesound.lowlevel.mfcc.var.c2: -0.0002599279217486825\n",
      "freesound.lowlevel.mfcc.avg.c5: -0.00019168102536284496\n",
      "freesound.lowlevel.mfcc.avg.c3: 0.00018965521444447972\n",
      "freesound.lowlevel.mfcc.var.c4: 0.00013688133239154928\n",
      "freesound.lowlevel.mfcc.var.c7: 0.00012000002398232579\n",
      "freesound.lowlevel.mfcc.var.c5: 0.00011933260109670739\n",
      "freesound.lowlevel.mfcc.var.c3: 9.222555240120862e-05\n",
      "freesound.lowlevel.mfcc.var.c0: -4.999862140556718e-05\n",
      "freesound.lowlevel.spectral_rolloff.avg: 4.311003528470572e-05\n",
      "freesound.lowlevel.spectral_kurtosis.var: -3.9621964113088076e-05\n",
      "freesound.lowlevel.mfcc.var.c1: -2.429629208437076e-05\n",
      "freesound.lowlevel.spectral_rolloff.var: -2.2351420016668408e-08\n",
      "freesound.lowlevel.spectral_centroid.var: -1.9387598911467378e-08\n",
      "freesound.lowlevel.spectral_spread.avg: 5.644795106729263e-09\n",
      "freesound.lowlevel.spectral_spread.var: -2.4740224746267413e-15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "# Define your ElasticNet model with specific hyperparameters\n",
    "alpha = 0.2  # Example value, adjust as needed\n",
    "l1_ratio = 0.5  # Example value, adjust as needed\n",
    "model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, selection=\"random\")\n",
    "print(f'Investigating performance of {model} model...')\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "MEs_train = []\n",
    "MEs_val = []\n",
    "MEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses_Mix[(responses_Mix['info.fold'] != val_fold) & (responses_Mix['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses_Mix[responses_Mix['info.fold'] == val_fold]\n",
    "    df_test  = responses_Mix[responses_Mix['info.fold'] == 0].groupby(['info.soundscape','info.masker','info.smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['info.P_ground_truth'].values\n",
    "    Y_val = df_val['info.P_ground_truth'].values\n",
    "    Y_test = df_test['info.P_ground_truth'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[mix_features].values\n",
    "    X_val =df_val[mix_features].values\n",
    "    X_test = df_test[mix_features].values    \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "    MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "    MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "    ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "    ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "    ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "    MEs_train.append(ME_train)\n",
    "    MEs_val.append(ME_val)\n",
    "    MEs_test.append(ME_test)\n",
    "\n",
    "    # Display important coefficients\n",
    "    \"\"\" coefficients = X_LR.coef_\n",
    "    feature_importances = list(zip(ARAUS_features, coefficients))\n",
    "    feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    for feature, importance in feature_importances:\n",
    "        if float(importance)!=0:\n",
    "            print(f\"{feature}: {importance}\") \"\"\"\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} |')\n",
    "print()\n",
    "\n",
    "\n",
    "coefficients = X_LR.coef_\n",
    "feature_importances = list(zip(mix_features, coefficients))\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "for feature, importance in feature_importances:\n",
    "    if float(importance)!=0:\n",
    "        print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) EVENTFULNESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) With default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating performance of ElasticNet() model...\n",
      "     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "   1 | 0.1393 | 0.1288 | 0.0394 | 0.3107 | 0.2963 | 0.1688 | -0.2925 | 20160 |  5040 |  48  |  113  |   1   |\n",
      "   2 | 0.1378 | 0.1366 | 0.0412 | 0.3088 | 0.3069 | 0.1732 | -0.2851 | 20160 |  5040 |  48  |  113  |   1   |\n",
      "   3 | 0.1390 | 0.1273 | 0.0394 | 0.3102 | 0.2950 | 0.1688 | -0.3629 | 20160 |  5040 |  48  |  113  |   2   |\n",
      "   4 | 0.1372 | 0.1402 | 0.0418 | 0.3083 | 0.3111 | 0.1746 | -0.2774 | 20160 |  5040 |  48  |  113  |   1   |\n",
      "   5 | 0.1336 | 0.1565 | 0.0441 | 0.3032 | 0.3340 | 0.1801 | -0.2803 | 20160 |  5040 |  48  |  113  |   2   |\n",
      "Mean | 0.1374 | 0.1379 | 0.0412 | 0.3082 | 0.3087 | 0.1731 |\n",
      "\n",
      "ARAUS.loudness.max: 0.00942586849673303\n",
      "ARAUS.energy_frequency.00630_0: 1.1967845791489354e-05\n",
      "ARAUS.sharpness.avg: -0.0\n",
      "ARAUS.sharpness.max: -0.0\n",
      "ARAUS.sharpness.p05: -0.0\n",
      "ARAUS.sharpness.p10: -0.0\n",
      "ARAUS.sharpness.p20: -0.0\n",
      "ARAUS.sharpness.p30: -0.0\n",
      "ARAUS.sharpness.p40: -0.0\n",
      "ARAUS.sharpness.p50: -0.0\n",
      "ARAUS.sharpness.p60: -0.0\n",
      "ARAUS.sharpness.p70: -0.0\n",
      "ARAUS.sharpness.p80: -0.0\n",
      "ARAUS.sharpness.p90: -0.0\n",
      "ARAUS.sharpness.p95: -0.0\n",
      "ARAUS.loudness.avg: 0.0\n",
      "ARAUS.loudness.p05: 0.0\n",
      "ARAUS.loudness.p10: 0.0\n",
      "ARAUS.loudness.p20: 0.0\n",
      "ARAUS.loudness.p30: 0.0\n",
      "ARAUS.loudness.p40: 0.0\n",
      "ARAUS.loudness.p50: 0.0\n",
      "ARAUS.loudness.p60: 0.0\n",
      "ARAUS.loudness.p70: 0.0\n",
      "ARAUS.loudness.p80: 0.0\n",
      "ARAUS.loudness.p90: 0.0\n",
      "ARAUS.loudness.p95: 0.0\n",
      "ARAUS.fluctuation.avg: 0.0\n",
      "ARAUS.fluctuation.max: 0.0\n",
      "ARAUS.fluctuation.p05: 0.0\n",
      "ARAUS.fluctuation.p10: 0.0\n",
      "ARAUS.fluctuation.p20: 0.0\n",
      "ARAUS.fluctuation.p30: 0.0\n",
      "ARAUS.fluctuation.p40: 0.0\n",
      "ARAUS.fluctuation.p50: 0.0\n",
      "ARAUS.fluctuation.p60: 0.0\n",
      "ARAUS.fluctuation.p70: 0.0\n",
      "ARAUS.fluctuation.p80: 0.0\n",
      "ARAUS.fluctuation.p90: 0.0\n",
      "ARAUS.fluctuation.p95: 0.0\n",
      "ARAUS.LA.avg: 0.0\n",
      "ARAUS.LA.min: 0.0\n",
      "ARAUS.LA.max: 0.0\n",
      "ARAUS.LA.p05: 0.0\n",
      "ARAUS.LA.p10: 0.0\n",
      "ARAUS.LA.p20: 0.0\n",
      "ARAUS.LA.p30: 0.0\n",
      "ARAUS.LA.p40: 0.0\n",
      "ARAUS.LA.p50: 0.0\n",
      "ARAUS.LA.p60: 0.0\n",
      "ARAUS.LA.p70: 0.0\n",
      "ARAUS.LA.p80: 0.0\n",
      "ARAUS.LA.p90: 0.0\n",
      "ARAUS.LA.p95: 0.0\n",
      "ARAUS.LC.avg: 0.0\n",
      "ARAUS.LC.min: 0.0\n",
      "ARAUS.LC.max: 0.0\n",
      "ARAUS.LC.p05: 0.0\n",
      "ARAUS.LC.p10: 0.0\n",
      "ARAUS.LC.p20: 0.0\n",
      "ARAUS.LC.p30: 0.0\n",
      "ARAUS.LC.p40: 0.0\n",
      "ARAUS.LC.p50: 0.0\n",
      "ARAUS.LC.p60: 0.0\n",
      "ARAUS.LC.p70: 0.0\n",
      "ARAUS.LC.p80: 0.0\n",
      "ARAUS.LC.p90: 0.0\n",
      "ARAUS.LC.p95: 0.0\n",
      "ARAUS.roughness.avg: 0.0\n",
      "ARAUS.roughness.max: 0.0\n",
      "ARAUS.roughness.p05: 0.0\n",
      "ARAUS.roughness.p10: 0.0\n",
      "ARAUS.roughness.p20: 0.0\n",
      "ARAUS.roughness.p30: 0.0\n",
      "ARAUS.roughness.p40: 0.0\n",
      "ARAUS.roughness.p50: 0.0\n",
      "ARAUS.roughness.p60: 0.0\n",
      "ARAUS.roughness.p70: 0.0\n",
      "ARAUS.roughness.p80: 0.0\n",
      "ARAUS.roughness.p90: 0.0\n",
      "ARAUS.roughness.p95: 0.0\n",
      "ARAUS.energy_frequency.00006_3: 0.0\n",
      "ARAUS.energy_frequency.00012_5: 0.0\n",
      "ARAUS.energy_frequency.00016_0: 0.0\n",
      "ARAUS.energy_frequency.00025_0: 0.0\n",
      "ARAUS.energy_frequency.00031_5: 0.0\n",
      "ARAUS.energy_frequency.00040_0: 0.0\n",
      "ARAUS.energy_frequency.00050_0: 0.0\n",
      "ARAUS.energy_frequency.00063_0: 0.0\n",
      "ARAUS.energy_frequency.00080_0: 0.0\n",
      "ARAUS.energy_frequency.00100_0: 0.0\n",
      "ARAUS.energy_frequency.00125_0: 0.0\n",
      "ARAUS.energy_frequency.00160_0: 0.0\n",
      "ARAUS.energy_frequency.00200_0: 0.0\n",
      "ARAUS.energy_frequency.00250_0: 0.0\n",
      "ARAUS.energy_frequency.00315_0: 0.0\n",
      "ARAUS.energy_frequency.00400_0: 0.0\n",
      "ARAUS.energy_frequency.00500_0: 0.0\n",
      "ARAUS.energy_frequency.00800_0: 0.0\n",
      "ARAUS.energy_frequency.01000_0: 0.0\n",
      "ARAUS.energy_frequency.01250_0: 0.0\n",
      "ARAUS.energy_frequency.01600_0: 0.0\n",
      "ARAUS.energy_frequency.02000_0: 0.0\n",
      "ARAUS.energy_frequency.02500_0: 0.0\n",
      "ARAUS.energy_frequency.03150_0: 0.0\n",
      "ARAUS.energy_frequency.04000_0: 0.0\n",
      "ARAUS.energy_frequency.05000_0: 0.0\n",
      "ARAUS.energy_frequency.06300_0: 0.0\n",
      "ARAUS.energy_frequency.08000_0: 0.0\n",
      "ARAUS.energy_frequency.10000_0: 0.0\n",
      "ARAUS.energy_frequency.12500_0: 0.0\n",
      "ARAUS.energy_frequency.16000_0: 0.0\n",
      "ARAUS.energy_frequency.20000_0: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "# Define your ElasticNet model with specific hyperparameters\n",
    "\n",
    "model = ElasticNet()\n",
    "print(f'Investigating performance of {model} model...')\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "MEs_train = []\n",
    "MEs_val = []\n",
    "MEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses_ARAUS[(responses_ARAUS['info.fold'] != val_fold) & (responses_ARAUS['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses_ARAUS[responses_ARAUS['info.fold'] == val_fold]\n",
    "    df_test  = responses_ARAUS[responses_ARAUS['info.fold'] == 0].groupby(['info.soundscape','info.masker','info.smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['info.E_ground_truth'].values\n",
    "    Y_val = df_val['info.E_ground_truth'].values\n",
    "    Y_test = df_test['info.E_ground_truth'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[ARAUS_features].values\n",
    "    X_val =df_val[ARAUS_features].values\n",
    "    X_test = df_test[ARAUS_features].values    \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "    MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "    MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "    ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "    ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "    ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "    MEs_train.append(ME_train)\n",
    "    MEs_val.append(ME_val)\n",
    "    MEs_test.append(ME_test)\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} |')\n",
    "print()\n",
    "\n",
    "# Assuming X_LR is your linear regression model\n",
    "coefficients = X_LR.coef_\n",
    "\n",
    "# Pairing coefficients with feature names\n",
    "feature_importances = list(zip(ARAUS_features, coefficients))\n",
    "\n",
    "# Sorting feature importances by absolute value of coefficient\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Displaying feature importances\n",
    "for feature, importance in feature_importances:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Defining parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating performance of ElasticNet(alpha=0.1, l1_ratio=0.7) model...\n",
      "     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "   1 | 0.1322 | 0.1233 | 0.0310 | 0.3000 | 0.2875 | 0.1417 | -1.3174 | 20160 |  5040 |  48  |  113  |   9   |\n",
      "   2 | 0.1293 | 0.1339 | 0.0360 | 0.2965 | 0.2990 | 0.1486 | -1.5575 | 20160 |  5040 |  48  |  113  |   9   |\n",
      "   3 | 0.1317 | 0.1268 | 0.0352 | 0.2991 | 0.2910 | 0.1469 | -1.5710 | 20160 |  5040 |  48  |  113  |   9   |\n",
      "   4 | 0.1303 | 0.1314 | 0.0329 | 0.2977 | 0.2993 | 0.1436 | -1.3900 | 20160 |  5040 |  48  |  113  |   9   |\n",
      "   5 | 0.1260 | 0.1479 | 0.0343 | 0.2918 | 0.3233 | 0.1510 | -1.4665 | 20160 |  5040 |  48  |  113  |  10   |\n",
      "Mean | 0.1299 | 0.1327 | 0.0339 | 0.2970 | 0.3000 | 0.1464 |\n",
      "\n",
      "ARAUS.LA.max: 0.0086675860767809\n",
      "ARAUS.energy_frequency.00630_0: 0.004874415230518314\n",
      "ARAUS.energy_frequency.00500_0: 0.004644300407696553\n",
      "ARAUS.LC.max: 0.003639196317562482\n",
      "ARAUS.energy_frequency.00080_0: -0.0029378672650310165\n",
      "ARAUS.energy_frequency.20000_0: -0.0016145495244722554\n",
      "ARAUS.LA.p10: 0.0010963147482709523\n",
      "ARAUS.energy_frequency.03150_0: 0.0007973704121210227\n",
      "ARAUS.loudness.p05: 0.0007758759598786416\n",
      "ARAUS.LA.p20: 0.0006223647278262293\n",
      "ARAUS.sharpness.avg: 0.0\n",
      "ARAUS.sharpness.max: -0.0\n",
      "ARAUS.sharpness.p05: 0.0\n",
      "ARAUS.sharpness.p10: 0.0\n",
      "ARAUS.sharpness.p20: 0.0\n",
      "ARAUS.sharpness.p30: 0.0\n",
      "ARAUS.sharpness.p40: 0.0\n",
      "ARAUS.sharpness.p50: 0.0\n",
      "ARAUS.sharpness.p60: 0.0\n",
      "ARAUS.sharpness.p70: 0.0\n",
      "ARAUS.sharpness.p80: -0.0\n",
      "ARAUS.sharpness.p90: -0.0\n",
      "ARAUS.sharpness.p95: -0.0\n",
      "ARAUS.loudness.avg: 0.0\n",
      "ARAUS.loudness.max: 0.0\n",
      "ARAUS.loudness.p10: 0.0\n",
      "ARAUS.loudness.p20: 0.0\n",
      "ARAUS.loudness.p30: 0.0\n",
      "ARAUS.loudness.p40: 0.0\n",
      "ARAUS.loudness.p50: 0.0\n",
      "ARAUS.loudness.p60: 0.0\n",
      "ARAUS.loudness.p70: 0.0\n",
      "ARAUS.loudness.p80: 0.0\n",
      "ARAUS.loudness.p90: 0.0\n",
      "ARAUS.loudness.p95: 0.0\n",
      "ARAUS.fluctuation.avg: 0.0\n",
      "ARAUS.fluctuation.max: 0.0\n",
      "ARAUS.fluctuation.p05: 0.0\n",
      "ARAUS.fluctuation.p10: 0.0\n",
      "ARAUS.fluctuation.p20: 0.0\n",
      "ARAUS.fluctuation.p30: 0.0\n",
      "ARAUS.fluctuation.p40: 0.0\n",
      "ARAUS.fluctuation.p50: 0.0\n",
      "ARAUS.fluctuation.p60: 0.0\n",
      "ARAUS.fluctuation.p70: 0.0\n",
      "ARAUS.fluctuation.p80: 0.0\n",
      "ARAUS.fluctuation.p90: 0.0\n",
      "ARAUS.fluctuation.p95: 0.0\n",
      "ARAUS.LA.avg: 0.0\n",
      "ARAUS.LA.min: -0.0\n",
      "ARAUS.LA.p05: 0.0\n",
      "ARAUS.LA.p30: 0.0\n",
      "ARAUS.LA.p40: 0.0\n",
      "ARAUS.LA.p50: 0.0\n",
      "ARAUS.LA.p60: 0.0\n",
      "ARAUS.LA.p70: 0.0\n",
      "ARAUS.LA.p80: 0.0\n",
      "ARAUS.LA.p90: 0.0\n",
      "ARAUS.LA.p95: 0.0\n",
      "ARAUS.LC.avg: 0.0\n",
      "ARAUS.LC.min: -0.0\n",
      "ARAUS.LC.p05: 0.0\n",
      "ARAUS.LC.p10: 0.0\n",
      "ARAUS.LC.p20: 0.0\n",
      "ARAUS.LC.p30: 0.0\n",
      "ARAUS.LC.p40: 0.0\n",
      "ARAUS.LC.p50: 0.0\n",
      "ARAUS.LC.p60: 0.0\n",
      "ARAUS.LC.p70: 0.0\n",
      "ARAUS.LC.p80: -0.0\n",
      "ARAUS.LC.p90: -0.0\n",
      "ARAUS.LC.p95: -0.0\n",
      "ARAUS.roughness.avg: -0.0\n",
      "ARAUS.roughness.max: -0.0\n",
      "ARAUS.roughness.p05: -0.0\n",
      "ARAUS.roughness.p10: -0.0\n",
      "ARAUS.roughness.p20: -0.0\n",
      "ARAUS.roughness.p30: -0.0\n",
      "ARAUS.roughness.p40: -0.0\n",
      "ARAUS.roughness.p50: -0.0\n",
      "ARAUS.roughness.p60: -0.0\n",
      "ARAUS.roughness.p70: -0.0\n",
      "ARAUS.roughness.p80: -0.0\n",
      "ARAUS.roughness.p90: -0.0\n",
      "ARAUS.roughness.p95: -0.0\n",
      "ARAUS.energy_frequency.00006_3: 0.0\n",
      "ARAUS.energy_frequency.00012_5: -0.0\n",
      "ARAUS.energy_frequency.00016_0: -0.0\n",
      "ARAUS.energy_frequency.00025_0: -0.0\n",
      "ARAUS.energy_frequency.00031_5: 0.0\n",
      "ARAUS.energy_frequency.00040_0: -0.0\n",
      "ARAUS.energy_frequency.00050_0: -0.0\n",
      "ARAUS.energy_frequency.00063_0: -0.0\n",
      "ARAUS.energy_frequency.00100_0: -0.0\n",
      "ARAUS.energy_frequency.00125_0: -0.0\n",
      "ARAUS.energy_frequency.00160_0: -0.0\n",
      "ARAUS.energy_frequency.00200_0: 0.0\n",
      "ARAUS.energy_frequency.00250_0: 0.0\n",
      "ARAUS.energy_frequency.00315_0: 0.0\n",
      "ARAUS.energy_frequency.00400_0: 0.0\n",
      "ARAUS.energy_frequency.00800_0: 0.0\n",
      "ARAUS.energy_frequency.01000_0: 0.0\n",
      "ARAUS.energy_frequency.01250_0: 0.0\n",
      "ARAUS.energy_frequency.01600_0: 0.0\n",
      "ARAUS.energy_frequency.02000_0: 0.0\n",
      "ARAUS.energy_frequency.02500_0: 0.0\n",
      "ARAUS.energy_frequency.04000_0: 0.0\n",
      "ARAUS.energy_frequency.05000_0: 0.0\n",
      "ARAUS.energy_frequency.06300_0: 0.0\n",
      "ARAUS.energy_frequency.08000_0: 0.0\n",
      "ARAUS.energy_frequency.10000_0: -0.0\n",
      "ARAUS.energy_frequency.12500_0: -0.0\n",
      "ARAUS.energy_frequency.16000_0: -0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "# Define your ElasticNet model with specific hyperparameters\n",
    "alpha = 0.1  # Example value, adjust as needed\n",
    "l1_ratio = 0.7  # Example value, adjust as needed\n",
    "model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "print(f'Investigating performance of {model} model...')\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "MEs_train = []\n",
    "MEs_val = []\n",
    "MEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses_ARAUS[(responses_ARAUS['info.fold'] != val_fold) & (responses_ARAUS['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses_ARAUS[responses_ARAUS['info.fold'] == val_fold]\n",
    "    df_test  = responses_ARAUS[responses_ARAUS['info.fold'] == 0].groupby(['info.soundscape','info.masker','info.smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['info.E_ground_truth'].values\n",
    "    Y_val = df_val['info.E_ground_truth'].values\n",
    "    Y_test = df_test['info.E_ground_truth'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[ARAUS_features].values\n",
    "    X_val =df_val[ARAUS_features].values\n",
    "    X_test = df_test[ARAUS_features].values    \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "    MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "    MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "    ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "    ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "    ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "    MEs_train.append(ME_train)\n",
    "    MEs_val.append(ME_val)\n",
    "    MEs_test.append(ME_test)\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} |')\n",
    "print()\n",
    "\n",
    "# Assuming X_LR is your linear regression model\n",
    "coefficients = X_LR.coef_\n",
    "\n",
    "# Pairing coefficients with feature names\n",
    "feature_importances = list(zip(ARAUS_features, coefficients))\n",
    "\n",
    "# Sorting feature importances by absolute value of coefficient\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Displaying feature importances\n",
    "for feature, importance in feature_importances:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
