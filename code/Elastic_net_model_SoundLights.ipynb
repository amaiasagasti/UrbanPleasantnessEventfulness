{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from SoundLights.features_groups import  ARAUS_features\n",
    "\n",
    "normalise = lambda X: (X-np.mean(X,axis=0,keepdims=True))/np.std(X,axis=0,keepdims=True) # Normalise an (n,p) numpy array to mean 0, variance 1.\n",
    "clip = lambda x, x_min = -1, x_max = 1: np.where(np.where(x < x_min,x_min,x) > x_max, x_max, np.where(x < x_min,x_min,x)) # Clip an array to values between x_min and x_max."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24440 entries, 0 to 24439\n",
      "Columns: 138 entries, info.fold to ARAUS.energy_frequency.20000_0\n",
      "dtypes: float64(118), int64(18), object(2)\n",
      "memory usage: 25.7+ MB\n"
     ]
    }
   ],
   "source": [
    "responses= pd.read_csv(os.path.join('..','data','SoundLights_ARAUS.csv'), dtype = {'info.participant':str}) #, dtype = {'participant':str}\n",
    "responses=responses.drop(\"info.file\", axis=1)\n",
    "responses=responses.drop(\"info.participant\", axis=1)\n",
    "\n",
    "# Drop columns that contain all zero values\n",
    "# Store column names before dropping\n",
    "columns_before = responses.columns.tolist()\n",
    "# Drop zero-columns\n",
    "responses = responses.loc[:, (responses != 0).any(axis=0)]\n",
    "# Store column names after dropping\n",
    "columns_after = responses.columns.tolist()\n",
    "# Determine which columns were dropped\n",
    "columns_dropped = [col for col in columns_before if col not in columns_after]\n",
    "# Drop those columns from ARAUS_features\n",
    "ARAUS_features = [col for col in ARAUS_features if col not in columns_dropped]\n",
    "\n",
    "\n",
    "responses.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) PLEASANTNESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) With default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating performance of ElasticNet() model...\n",
      "     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "   1 | 0.1448 | 0.1416 | 0.0890 | 0.3142 | 0.3104 | 0.2451 |  0.2143 | 19160 |  5040 |  48  |  113  |   2   |\n",
      "   2 | 0.1458 | 0.1375 | 0.0920 | 0.3155 | 0.3043 | 0.2497 |  0.2317 | 19160 |  5040 |  48  |  113  |   2   |\n",
      "   3 | 0.1421 | 0.1569 | 0.0928 | 0.3110 | 0.3262 | 0.2509 |  0.1883 | 20160 |  4040 |  48  |  113  |   2   |\n",
      "   4 | 0.1431 | 0.1501 | 0.0923 | 0.3115 | 0.3234 | 0.2501 |  0.2044 | 19160 |  5040 |  48  |  113  |   2   |\n",
      "   5 | 0.1455 | 0.1404 | 0.0893 | 0.3150 | 0.3087 | 0.2456 |  0.1957 | 19160 |  5040 |  48  |  113  |   2   |\n",
      "Mean | 0.1443 | 0.1453 | 0.0911 | 0.3134 | 0.3146 | 0.2483 |\n",
      "\n",
      "ARAUS.loudness.max: -0.005310076226013088\n",
      "ARAUS.energy_frequency.10000_0: -0.0009497878980805982\n"
     ]
    }
   ],
   "source": [
    "model = sklearn.linear_model.ElasticNet()\n",
    "print(f'Investigating performance of {model} model...')\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "MEs_train = []\n",
    "MEs_val = []\n",
    "MEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses[(responses['info.fold'] != val_fold) & (responses['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses[responses['info.fold'] == val_fold]\n",
    "    df_test  = responses[responses['info.fold'] == 0].groupby(['info.soundscape','info.masker','info.smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['info.P_ground_truth'].values\n",
    "    Y_val = df_val['info.P_ground_truth'].values\n",
    "    Y_test = df_test['info.P_ground_truth'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[ARAUS_features].values\n",
    "    X_val =df_val[ARAUS_features].values\n",
    "    X_test = df_test[ARAUS_features].values    \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "    MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "    MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "    ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "    ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "    ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "    MEs_train.append(ME_train)\n",
    "    MEs_val.append(ME_val)\n",
    "    MEs_test.append(ME_test)\n",
    "\n",
    "    # Display important coefficients\n",
    "    \"\"\" coefficients = X_LR.coef_\n",
    "    feature_importances = list(zip(ARAUS_features, coefficients))\n",
    "    feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    for feature, importance in feature_importances:\n",
    "        if float(importance)!=0:\n",
    "            print(f\"{feature}: {importance}\") \"\"\"\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} |')\n",
    "print()\n",
    "\n",
    "\n",
    "coefficients = X_LR.coef_\n",
    "feature_importances = list(zip(ARAUS_features, coefficients))\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "for feature, importance in feature_importances:\n",
    "    if float(importance)!=0:\n",
    "        print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Defining parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "   1 | 0.1346 | 0.1333 | 0.0727 | 0.3002 | 0.2976 | 0.2285 |  0.5439 | 19160 |  5040 |  48  |  113  |  12   |\n",
      "   2 | 0.1356 | 0.1317 | 0.0756 | 0.3014 | 0.2935 | 0.2313 |  0.1596 | 19160 |  5040 |  48  |  113  |  10   |\n",
      "   3 | 0.1336 | 0.1430 | 0.0747 | 0.2992 | 0.3076 | 0.2307 |  0.7282 | 20160 |  4040 |  48  |  113  |  10   |\n",
      "   4 | 0.1321 | 0.1424 | 0.0784 | 0.2963 | 0.3129 | 0.2384 |  0.4333 | 19160 |  5040 |  48  |  113  |  11   |\n",
      "   5 | 0.1352 | 0.1341 | 0.0696 | 0.3006 | 0.3006 | 0.2212 |  0.4728 | 19160 |  5040 |  48  |  113  |  10   |\n",
      "Mean | 0.1342 | 0.1369 | 0.0742 | 0.2995 | 0.3024 | 0.2300 |\n",
      "\n",
      "ARAUS.energy_frequency.00006_3: -0.011408799496230112\n",
      "ARAUS.LC.max: -0.00404082687715505\n",
      "ARAUS.energy_frequency.02000_0: -0.0036817094818814497\n",
      "ARAUS.energy_frequency.00063_0: -0.002507553289379047\n",
      "ARAUS.energy_frequency.04000_0: 0.002156577744634647\n",
      "ARAUS.energy_frequency.10000_0: -0.0018687766545752696\n",
      "ARAUS.energy_frequency.00200_0: -0.0017261075989720338\n",
      "ARAUS.energy_frequency.08000_0: -0.0014712983767501374\n",
      "ARAUS.energy_frequency.00031_5: -0.0013398817195810152\n",
      "ARAUS.loudness.max: -0.0011110263265633074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "# Define your ElasticNet model with specific hyperparameters\n",
    "alpha = 0.1  # Example value, adjust as needed\n",
    "l1_ratio = 0.7  # Example value, adjust as needed\n",
    "model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, selection=\"random\")\n",
    "#print(f'Investigating performance of {model} model...')\n",
    "\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "MEs_train = []\n",
    "MEs_val = []\n",
    "MEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses[(responses['info.fold'] != val_fold) & (responses['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses[responses['info.fold'] == val_fold]\n",
    "    df_test  = responses[responses['info.fold'] == 0].groupby(['info.soundscape','info.masker','info.smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['info.P_ground_truth'].values\n",
    "    Y_val = df_val['info.P_ground_truth'].values\n",
    "    Y_test = df_test['info.P_ground_truth'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[ARAUS_features].values\n",
    "    X_val =df_val[ARAUS_features].values\n",
    "    X_test = df_test[ARAUS_features].values    \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model.fit(X_train, Y_train)\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "    MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "    MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "    ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "    ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "    ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "    MEs_train.append(ME_train)\n",
    "    MEs_val.append(ME_val)\n",
    "    MEs_test.append(ME_test)\n",
    "\n",
    "    # Display important coefficients\n",
    "    \"\"\" coefficients = X_LR.coef_\n",
    "    feature_importances = list(zip(ARAUS_features, coefficients))\n",
    "    feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    for feature, importance in feature_importances:\n",
    "        if float(importance)!=0:\n",
    "            print(f\"{feature}: {importance}\") \"\"\"\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} |')\n",
    "print()\n",
    "\n",
    "\n",
    "coefficients = X_LR.coef_\n",
    "feature_importances = list(zip(ARAUS_features, coefficients))\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "for feature, importance in feature_importances:\n",
    "    if float(importance)!=0:\n",
    "        print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) EVENTFULNESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) With default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating performance of ElasticNet() model...\n",
      "     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "   1 | 0.1412 | 0.1287 | 0.0388 | 0.3132 | 0.2961 | 0.1677 | -0.2973 | 19160 |  5040 |  48  |  113  |   1   |\n",
      "   2 | 0.1395 | 0.1365 | 0.0405 | 0.3111 | 0.3066 | 0.1716 | -0.3033 | 19160 |  5040 |  48  |  113  |   2   |\n",
      "   3 | 0.1390 | 0.1343 | 0.0394 | 0.3102 | 0.3043 | 0.1688 | -0.3629 | 20160 |  4040 |  48  |  113  |   2   |\n",
      "   4 | 0.1391 | 0.1400 | 0.0414 | 0.3107 | 0.3109 | 0.1736 | -0.2811 | 19160 |  5040 |  48  |  113  |   1   |\n",
      "   5 | 0.1352 | 0.1563 | 0.0437 | 0.3052 | 0.3338 | 0.1793 | -0.2872 | 19160 |  5040 |  48  |  113  |   2   |\n",
      "Mean | 0.1388 | 0.1391 | 0.0408 | 0.3101 | 0.3104 | 0.1722 |\n",
      "\n",
      "ARAUS.loudness.max: 0.009498902654049448\n",
      "ARAUS.energy_frequency.00630_0: 8.7571961329682e-05\n",
      "ARAUS.sharpness.avg: -0.0\n",
      "ARAUS.sharpness.max: -0.0\n",
      "ARAUS.sharpness.p05: -0.0\n",
      "ARAUS.sharpness.p10: -0.0\n",
      "ARAUS.sharpness.p20: -0.0\n",
      "ARAUS.sharpness.p30: -0.0\n",
      "ARAUS.sharpness.p40: -0.0\n",
      "ARAUS.sharpness.p50: -0.0\n",
      "ARAUS.sharpness.p60: -0.0\n",
      "ARAUS.sharpness.p70: -0.0\n",
      "ARAUS.sharpness.p80: -0.0\n",
      "ARAUS.sharpness.p90: -0.0\n",
      "ARAUS.sharpness.p95: -0.0\n",
      "ARAUS.loudness.avg: 0.0\n",
      "ARAUS.loudness.p05: 0.0\n",
      "ARAUS.loudness.p10: 0.0\n",
      "ARAUS.loudness.p20: 0.0\n",
      "ARAUS.loudness.p30: 0.0\n",
      "ARAUS.loudness.p40: 0.0\n",
      "ARAUS.loudness.p50: 0.0\n",
      "ARAUS.loudness.p60: 0.0\n",
      "ARAUS.loudness.p70: 0.0\n",
      "ARAUS.loudness.p80: 0.0\n",
      "ARAUS.loudness.p90: 0.0\n",
      "ARAUS.loudness.p95: 0.0\n",
      "ARAUS.fluctuation.avg: 0.0\n",
      "ARAUS.fluctuation.max: 0.0\n",
      "ARAUS.fluctuation.p05: 0.0\n",
      "ARAUS.fluctuation.p10: 0.0\n",
      "ARAUS.fluctuation.p20: 0.0\n",
      "ARAUS.fluctuation.p30: 0.0\n",
      "ARAUS.fluctuation.p40: 0.0\n",
      "ARAUS.fluctuation.p50: 0.0\n",
      "ARAUS.fluctuation.p60: 0.0\n",
      "ARAUS.fluctuation.p70: 0.0\n",
      "ARAUS.fluctuation.p80: 0.0\n",
      "ARAUS.fluctuation.p90: 0.0\n",
      "ARAUS.fluctuation.p95: 0.0\n",
      "ARAUS.LA.avg: 0.0\n",
      "ARAUS.LA.min: 0.0\n",
      "ARAUS.LA.max: 0.0\n",
      "ARAUS.LA.p05: 0.0\n",
      "ARAUS.LA.p10: 0.0\n",
      "ARAUS.LA.p20: 0.0\n",
      "ARAUS.LA.p30: 0.0\n",
      "ARAUS.LA.p40: 0.0\n",
      "ARAUS.LA.p50: 0.0\n",
      "ARAUS.LA.p60: 0.0\n",
      "ARAUS.LA.p70: 0.0\n",
      "ARAUS.LA.p80: 0.0\n",
      "ARAUS.LA.p90: 0.0\n",
      "ARAUS.LA.p95: 0.0\n",
      "ARAUS.LC.avg: 0.0\n",
      "ARAUS.LC.min: 0.0\n",
      "ARAUS.LC.max: 0.0\n",
      "ARAUS.LC.p05: 0.0\n",
      "ARAUS.LC.p10: 0.0\n",
      "ARAUS.LC.p20: 0.0\n",
      "ARAUS.LC.p30: 0.0\n",
      "ARAUS.LC.p40: 0.0\n",
      "ARAUS.LC.p50: 0.0\n",
      "ARAUS.LC.p60: 0.0\n",
      "ARAUS.LC.p70: 0.0\n",
      "ARAUS.LC.p80: 0.0\n",
      "ARAUS.LC.p90: 0.0\n",
      "ARAUS.LC.p95: 0.0\n",
      "ARAUS.roughness.avg: 0.0\n",
      "ARAUS.roughness.max: 0.0\n",
      "ARAUS.roughness.p05: 0.0\n",
      "ARAUS.roughness.p10: 0.0\n",
      "ARAUS.roughness.p20: 0.0\n",
      "ARAUS.roughness.p30: 0.0\n",
      "ARAUS.roughness.p40: 0.0\n",
      "ARAUS.roughness.p50: 0.0\n",
      "ARAUS.roughness.p60: 0.0\n",
      "ARAUS.roughness.p70: 0.0\n",
      "ARAUS.roughness.p80: 0.0\n",
      "ARAUS.roughness.p90: 0.0\n",
      "ARAUS.roughness.p95: 0.0\n",
      "ARAUS.energy_frequency.00006_3: 0.0\n",
      "ARAUS.energy_frequency.00012_5: 0.0\n",
      "ARAUS.energy_frequency.00016_0: 0.0\n",
      "ARAUS.energy_frequency.00025_0: 0.0\n",
      "ARAUS.energy_frequency.00031_5: 0.0\n",
      "ARAUS.energy_frequency.00040_0: 0.0\n",
      "ARAUS.energy_frequency.00050_0: 0.0\n",
      "ARAUS.energy_frequency.00063_0: 0.0\n",
      "ARAUS.energy_frequency.00080_0: 0.0\n",
      "ARAUS.energy_frequency.00100_0: 0.0\n",
      "ARAUS.energy_frequency.00125_0: 0.0\n",
      "ARAUS.energy_frequency.00160_0: 0.0\n",
      "ARAUS.energy_frequency.00200_0: 0.0\n",
      "ARAUS.energy_frequency.00250_0: 0.0\n",
      "ARAUS.energy_frequency.00315_0: 0.0\n",
      "ARAUS.energy_frequency.00400_0: 0.0\n",
      "ARAUS.energy_frequency.00500_0: 0.0\n",
      "ARAUS.energy_frequency.00800_0: 0.0\n",
      "ARAUS.energy_frequency.01000_0: 0.0\n",
      "ARAUS.energy_frequency.01250_0: 0.0\n",
      "ARAUS.energy_frequency.01600_0: 0.0\n",
      "ARAUS.energy_frequency.02000_0: 0.0\n",
      "ARAUS.energy_frequency.02500_0: 0.0\n",
      "ARAUS.energy_frequency.03150_0: 0.0\n",
      "ARAUS.energy_frequency.04000_0: 0.0\n",
      "ARAUS.energy_frequency.05000_0: 0.0\n",
      "ARAUS.energy_frequency.06300_0: 0.0\n",
      "ARAUS.energy_frequency.08000_0: 0.0\n",
      "ARAUS.energy_frequency.10000_0: 0.0\n",
      "ARAUS.energy_frequency.12500_0: 0.0\n",
      "ARAUS.energy_frequency.16000_0: 0.0\n",
      "ARAUS.energy_frequency.20000_0: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "# Define your ElasticNet model with specific hyperparameters\n",
    "\n",
    "model = ElasticNet()\n",
    "print(f'Investigating performance of {model} model...')\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "MEs_train = []\n",
    "MEs_val = []\n",
    "MEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses[(responses['info.fold'] != val_fold) & (responses['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses[responses['info.fold'] == val_fold]\n",
    "    df_test  = responses[responses['info.fold'] == 0].groupby(['info.soundscape','info.masker','info.smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['info.E_ground_truth'].values\n",
    "    Y_val = df_val['info.E_ground_truth'].values\n",
    "    Y_test = df_test['info.E_ground_truth'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[ARAUS_features].values\n",
    "    X_val =df_val[ARAUS_features].values\n",
    "    X_test = df_test[ARAUS_features].values    \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "    MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "    MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "    ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "    ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "    ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "    MEs_train.append(ME_train)\n",
    "    MEs_val.append(ME_val)\n",
    "    MEs_test.append(ME_test)\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} |')\n",
    "print()\n",
    "\n",
    "# Assuming X_LR is your linear regression model\n",
    "coefficients = X_LR.coef_\n",
    "\n",
    "# Pairing coefficients with feature names\n",
    "feature_importances = list(zip(ARAUS_features, coefficients))\n",
    "\n",
    "# Sorting feature importances by absolute value of coefficient\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Displaying feature importances\n",
    "for feature, importance in feature_importances:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Defining parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating performance of ElasticNet(alpha=0.1, l1_ratio=0.7) model...\n",
      "     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "   1 | 0.1340 | 0.1232 | 0.0311 | 0.3024 | 0.2873 | 0.1411 | -1.3419 | 19160 |  5040 |  48  |  113  |   9   |\n",
      "   2 | 0.1309 | 0.1343 | 0.0370 | 0.2985 | 0.2991 | 0.1505 | -1.6071 | 19160 |  5040 |  48  |  113  |   7   |\n",
      "   3 | 0.1317 | 0.1335 | 0.0352 | 0.2991 | 0.2999 | 0.1469 | -1.5710 | 20160 |  4040 |  48  |  113  |   9   |\n",
      "   4 | 0.1319 | 0.1313 | 0.0333 | 0.2999 | 0.2991 | 0.1439 | -1.4248 | 19160 |  5040 |  48  |  113  |   9   |\n",
      "   5 | 0.1274 | 0.1479 | 0.0346 | 0.2937 | 0.3232 | 0.1512 | -1.4954 | 19160 |  5040 |  48  |  113  |  10   |\n",
      "Mean | 0.1312 | 0.1340 | 0.0342 | 0.2987 | 0.3017 | 0.1467 |\n",
      "\n",
      "ARAUS.LA.max: 0.009180610868356717\n",
      "ARAUS.energy_frequency.00500_0: 0.004954341327478382\n",
      "ARAUS.energy_frequency.00630_0: 0.004614568279095922\n",
      "ARAUS.LC.max: 0.003475745565756907\n",
      "ARAUS.energy_frequency.00080_0: -0.003322271991857064\n",
      "ARAUS.energy_frequency.20000_0: -0.001554147489507944\n",
      "ARAUS.LA.p20: 0.0013927447766884182\n",
      "ARAUS.energy_frequency.03150_0: 0.0008288431374934944\n",
      "ARAUS.LA.p10: 0.000670544692807845\n",
      "ARAUS.loudness.p05: 0.0003691073414163637\n",
      "ARAUS.sharpness.avg: 0.0\n",
      "ARAUS.sharpness.max: -0.0\n",
      "ARAUS.sharpness.p05: 0.0\n",
      "ARAUS.sharpness.p10: 0.0\n",
      "ARAUS.sharpness.p20: 0.0\n",
      "ARAUS.sharpness.p30: 0.0\n",
      "ARAUS.sharpness.p40: 0.0\n",
      "ARAUS.sharpness.p50: 0.0\n",
      "ARAUS.sharpness.p60: 0.0\n",
      "ARAUS.sharpness.p70: 0.0\n",
      "ARAUS.sharpness.p80: -0.0\n",
      "ARAUS.sharpness.p90: -0.0\n",
      "ARAUS.sharpness.p95: -0.0\n",
      "ARAUS.loudness.avg: 0.0\n",
      "ARAUS.loudness.max: 0.0\n",
      "ARAUS.loudness.p10: 0.0\n",
      "ARAUS.loudness.p20: 0.0\n",
      "ARAUS.loudness.p30: 0.0\n",
      "ARAUS.loudness.p40: 0.0\n",
      "ARAUS.loudness.p50: 0.0\n",
      "ARAUS.loudness.p60: 0.0\n",
      "ARAUS.loudness.p70: 0.0\n",
      "ARAUS.loudness.p80: 0.0\n",
      "ARAUS.loudness.p90: 0.0\n",
      "ARAUS.loudness.p95: 0.0\n",
      "ARAUS.fluctuation.avg: 0.0\n",
      "ARAUS.fluctuation.max: 0.0\n",
      "ARAUS.fluctuation.p05: 0.0\n",
      "ARAUS.fluctuation.p10: 0.0\n",
      "ARAUS.fluctuation.p20: 0.0\n",
      "ARAUS.fluctuation.p30: 0.0\n",
      "ARAUS.fluctuation.p40: 0.0\n",
      "ARAUS.fluctuation.p50: 0.0\n",
      "ARAUS.fluctuation.p60: 0.0\n",
      "ARAUS.fluctuation.p70: 0.0\n",
      "ARAUS.fluctuation.p80: 0.0\n",
      "ARAUS.fluctuation.p90: 0.0\n",
      "ARAUS.fluctuation.p95: 0.0\n",
      "ARAUS.LA.avg: 0.0\n",
      "ARAUS.LA.min: -0.0\n",
      "ARAUS.LA.p05: 0.0\n",
      "ARAUS.LA.p30: 0.0\n",
      "ARAUS.LA.p40: 0.0\n",
      "ARAUS.LA.p50: 0.0\n",
      "ARAUS.LA.p60: 0.0\n",
      "ARAUS.LA.p70: 0.0\n",
      "ARAUS.LA.p80: 0.0\n",
      "ARAUS.LA.p90: 0.0\n",
      "ARAUS.LA.p95: 0.0\n",
      "ARAUS.LC.avg: 0.0\n",
      "ARAUS.LC.min: -0.0\n",
      "ARAUS.LC.p05: 0.0\n",
      "ARAUS.LC.p10: 0.0\n",
      "ARAUS.LC.p20: 0.0\n",
      "ARAUS.LC.p30: 0.0\n",
      "ARAUS.LC.p40: 0.0\n",
      "ARAUS.LC.p50: 0.0\n",
      "ARAUS.LC.p60: 0.0\n",
      "ARAUS.LC.p70: 0.0\n",
      "ARAUS.LC.p80: 0.0\n",
      "ARAUS.LC.p90: -0.0\n",
      "ARAUS.LC.p95: -0.0\n",
      "ARAUS.roughness.avg: -0.0\n",
      "ARAUS.roughness.max: -0.0\n",
      "ARAUS.roughness.p05: -0.0\n",
      "ARAUS.roughness.p10: -0.0\n",
      "ARAUS.roughness.p20: -0.0\n",
      "ARAUS.roughness.p30: -0.0\n",
      "ARAUS.roughness.p40: -0.0\n",
      "ARAUS.roughness.p50: -0.0\n",
      "ARAUS.roughness.p60: -0.0\n",
      "ARAUS.roughness.p70: -0.0\n",
      "ARAUS.roughness.p80: -0.0\n",
      "ARAUS.roughness.p90: -0.0\n",
      "ARAUS.roughness.p95: -0.0\n",
      "ARAUS.energy_frequency.00006_3: 0.0\n",
      "ARAUS.energy_frequency.00012_5: -0.0\n",
      "ARAUS.energy_frequency.00016_0: -0.0\n",
      "ARAUS.energy_frequency.00025_0: -0.0\n",
      "ARAUS.energy_frequency.00031_5: 0.0\n",
      "ARAUS.energy_frequency.00040_0: -0.0\n",
      "ARAUS.energy_frequency.00050_0: -0.0\n",
      "ARAUS.energy_frequency.00063_0: -0.0\n",
      "ARAUS.energy_frequency.00100_0: -0.0\n",
      "ARAUS.energy_frequency.00125_0: -0.0\n",
      "ARAUS.energy_frequency.00160_0: -0.0\n",
      "ARAUS.energy_frequency.00200_0: 0.0\n",
      "ARAUS.energy_frequency.00250_0: 0.0\n",
      "ARAUS.energy_frequency.00315_0: 0.0\n",
      "ARAUS.energy_frequency.00400_0: 0.0\n",
      "ARAUS.energy_frequency.00800_0: 0.0\n",
      "ARAUS.energy_frequency.01000_0: 0.0\n",
      "ARAUS.energy_frequency.01250_0: 0.0\n",
      "ARAUS.energy_frequency.01600_0: 0.0\n",
      "ARAUS.energy_frequency.02000_0: 0.0\n",
      "ARAUS.energy_frequency.02500_0: 0.0\n",
      "ARAUS.energy_frequency.04000_0: 0.0\n",
      "ARAUS.energy_frequency.05000_0: 0.0\n",
      "ARAUS.energy_frequency.06300_0: 0.0\n",
      "ARAUS.energy_frequency.08000_0: 0.0\n",
      "ARAUS.energy_frequency.10000_0: -0.0\n",
      "ARAUS.energy_frequency.12500_0: -0.0\n",
      "ARAUS.energy_frequency.16000_0: -0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "# Define your ElasticNet model with specific hyperparameters\n",
    "alpha = 0.1  # Example value, adjust as needed\n",
    "l1_ratio = 0.7  # Example value, adjust as needed\n",
    "model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "print(f'Investigating performance of {model} model...')\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "MEs_train = []\n",
    "MEs_val = []\n",
    "MEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses[(responses['info.fold'] != val_fold) & (responses['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses[responses['info.fold'] == val_fold]\n",
    "    df_test  = responses[responses['info.fold'] == 0].groupby(['info.soundscape','info.masker','info.smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['info.E_ground_truth'].values\n",
    "    Y_val = df_val['info.E_ground_truth'].values\n",
    "    Y_test = df_test['info.E_ground_truth'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[ARAUS_features].values\n",
    "    X_val =df_val[ARAUS_features].values\n",
    "    X_test = df_test[ARAUS_features].values    \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "    MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "    MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "    ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "    ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "    ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "    MEs_train.append(ME_train)\n",
    "    MEs_val.append(ME_val)\n",
    "    MEs_test.append(ME_test)\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} |')\n",
    "print()\n",
    "\n",
    "# Assuming X_LR is your linear regression model\n",
    "coefficients = X_LR.coef_\n",
    "\n",
    "# Pairing coefficients with feature names\n",
    "feature_importances = list(zip(ARAUS_features, coefficients))\n",
    "\n",
    "# Sorting feature importances by absolute value of coefficient\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Displaying feature importances\n",
    "for feature, importance in feature_importances:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
