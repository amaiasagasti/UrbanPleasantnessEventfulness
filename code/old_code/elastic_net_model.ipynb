{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic net model - no maskers in features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, we train an elastic net model for each fold of the cross-validation set and compute the corresponding metrics. The elastic net model minimises the loss function\n",
    "\n",
    "$$L(w_1,\\dots,w_n) = \\sum_{i=1}^{n}\\left(\\left(y_i-w_ix_i\\right)^2 + \\alpha\\left|w_i\\right| + \\beta w_i^2\\right),$$\n",
    "\n",
    "where $y_i$ are the ground truth labels, $x_i$ are the input features (or \"predictor variables\"), $w_i$ are the weights for the individual features (or \"coefficients\"), $n$ is the number of training samples, and $\\alpha,\\beta$ are regularisation parameters.\n",
    "\n",
    "Note that the shapes of the feature arrays in the following block are:\n",
    "- `X_train`: (20160, 132)\n",
    "- `Y_train`: (20160,)\n",
    "- `X_val`: (5040, 132)\n",
    "- `Y_val`: (5040,)\n",
    "- `X_test`: (48, 132)\n",
    "- `Y_test`: (48,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load\n",
    "- Libraries\n",
    "- Data files with responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "clip = lambda x, x_min = -1, x_max = 1: np.where(np.where(x < x_min,x_min,x) > x_max, x_max, np.where(x < x_min,x_min,x)) # Clip an array to values between x_min and x_max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       participant  fold_r                          soundscape  \\\n",
      "0      ARAUS_00001      -1  R0091_segment_binaural_44100_1.wav   \n",
      "1      ARAUS_00001       1  R0079_segment_binaural_44100_1.wav   \n",
      "2      ARAUS_00001       1  R0056_segment_binaural_44100_2.wav   \n",
      "3      ARAUS_00001       1  R0046_segment_binaural_44100_2.wav   \n",
      "4      ARAUS_00001       1  R0092_segment_binaural_44100_1.wav   \n",
      "...            ...     ...                                 ...   \n",
      "27250  ARAUS_10005       0    R1007_segment_binaural_44100.wav   \n",
      "27251  ARAUS_10005       0    R1006_segment_binaural_44100.wav   \n",
      "27252  ARAUS_10005       0    R1008_segment_binaural_44100.wav   \n",
      "27253  ARAUS_10005       0    R1007_segment_binaural_44100.wav   \n",
      "27254  ARAUS_10005      -1  R0091_segment_binaural_44100_1.wav   \n",
      "\n",
      "                       masker  smr  stimulus_index  wav_gain  time_taken  \\\n",
      "0           silence_00001.wav    0               1  0.000000      98.328   \n",
      "1           silence_00001.wav    6               2  4.902479      77.446   \n",
      "2             water_00047.wav   -3               3  4.044932      67.102   \n",
      "3           traffic_00006.wav    6               4  5.255976      56.640   \n",
      "4           traffic_00016.wav   -6               5  9.141567      51.311   \n",
      "...                       ...  ...             ...       ...         ...   \n",
      "27250       traffic_10001.wav    0              47  3.228121      43.005   \n",
      "27251       silence_10001.wav    0              48  8.660320      34.629   \n",
      "27252  construction_10001.wav    0              49  6.153127      31.484   \n",
      "27253       silence_10001.wav    0              50  3.160764      35.533   \n",
      "27254       silence_10001.wav    0              51  0.000000      37.181   \n",
      "\n",
      "       is_attention  pleasant  ...    Leq_L_r    Leq_R_r  masker_bird  \\\n",
      "0                 0         5  ...  85.172757  89.614971            0   \n",
      "1                 0         5  ...  68.205627  68.885104            0   \n",
      "2                 0         4  ...  74.789701  75.876626            0   \n",
      "3                 0         5  ...  68.045045  70.963026            0   \n",
      "4                 0         5  ...  77.314983  81.262421            0   \n",
      "...             ...       ...  ...        ...        ...          ...   \n",
      "27250             0         3  ...  65.248280  67.034565            0   \n",
      "27251             0         2  ...  69.411266  71.075758            0   \n",
      "27252             0         1  ...  78.966513  78.857925            0   \n",
      "27253             0         5  ...  64.532490  66.833307            0   \n",
      "27254             0         2  ...  85.172757  89.614971            0   \n",
      "\n",
      "       masker_construction  masker_silence  masker_traffic  masker_water  \\\n",
      "0                        0               1               0             0   \n",
      "1                        0               1               0             0   \n",
      "2                        0               0               0             1   \n",
      "3                        0               0               1             0   \n",
      "4                        0               0               1             0   \n",
      "...                    ...             ...             ...           ...   \n",
      "27250                    0               0               1             0   \n",
      "27251                    0               1               0             0   \n",
      "27252                    1               0               0             0   \n",
      "27253                    0               1               0             0   \n",
      "27254                    0               1               0             0   \n",
      "\n",
      "       masker_wind  P_ground_truth  E_ground_truth  \n",
      "0                0    6.035534e-01        0.207107  \n",
      "1                0    4.571068e-01       -0.500000  \n",
      "2                0    3.535534e-01       -0.250000  \n",
      "3                0    4.571068e-01       -0.189340  \n",
      "4                0    5.303301e-01       -0.116117  \n",
      "...            ...             ...             ...  \n",
      "27250            0   -2.299347e-17        0.207107  \n",
      "27251            0   -3.964466e-01        0.560660  \n",
      "27252            0   -9.267767e-01        0.383883  \n",
      "27253            0    6.338835e-01       -0.573223  \n",
      "27254            0   -1.338835e-01        0.926777  \n",
      "\n",
      "[27255 rows x 169 columns]\n"
     ]
    }
   ],
   "source": [
    "responses = pd.read_csv(os.path.join('..','data','responses_SoundLights.csv'), dtype = {'participant':str})\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the predictor variables that we will be using in `relevant_columns_enet`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns_enet = ['Savg_r','Smax_r','S05_r','S10_r','S20_r','S30_r','S40_r','S50_r','S60_r','S70_r','S80_r','S90_r','S95_r',\n",
    "                         'Navg_r','Nmax_r','N05_r','N10_r','N20_r','N30_r','N40_r','N50_r','N60_r','N70_r','N80_r','N90_r','N95_r',\n",
    "                         'Favg_r','Fmax_r','F05_r','F10_r','F20_r','F30_r','F40_r','F50_r','F60_r','F70_r','F80_r','F90_r','F95_r',\n",
    "                         'LAavg_r','LAmin_r','LAmax_r','LA05_r','LA10_r','LA20_r','LA30_r','LA40_r','LA50_r','LA60_r','LA70_r','LA80_r','LA90_r','LA95_r',\n",
    "                         'LCavg_r','LCmin_r','LCmax_r','LC05_r','LC10_r','LC20_r','LC30_r','LC40_r','LC50_r','LC60_r','LC70_r','LC80_r','LC90_r','LC95_r',\n",
    "                         'Ravg_r','Rmax_r','R05_r','R10_r','R20_r','R30_r','R40_r','R50_r','R60_r','R70_r','R80_r','R90_r','R95_r',\n",
    "                         'M00005_0_r','M00006_3_r','M00008_0_r','M00010_0_r','M00012_5_r','M00016_0_r','M00020_0_r','M00025_0_r','M00031_5_r','M00040_0_r',\n",
    "                         'M00050_0_r','M00063_0_r','M00080_0_r','M00100_0_r','M00125_0_r','M00160_0_r','M00200_0_r','M00250_0_r','M00315_0_r','M00400_0_r',\n",
    "                         'M00500_0_r','M00630_0_r','M00800_0_r','M01000_0_r','M01250_0_r','M01600_0_r','M02000_0_r','M02500_0_r','M03150_0_r','M04000_0_r',\n",
    "                         'M05000_0_r','M06300_0_r','M08000_0_r','M10000_0_r','M12500_0_r','M16000_0_r','M20000_0_r']\n",
    "#'Nrmc_r','Tgavg_r','Tavg_r','Tmax_r','T05_r','T10_r','T20_r','T30_r','T40_r','T50_r','T60_r','T70_r','T80_r','T90_r','T95_r',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating performance of ElasticNet() model...\n",
      "     |    Mean squared error    |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "   1 | 0.1360 | 0.1321 | 0.0912 |  0.3074 | 20160 |  5040 |  48  |  117  |   3   |\n",
      "   2 | 0.1368 | 0.1284 | 0.0954 |  0.3105 | 20160 |  5040 |  48  |  117  |   2   |\n",
      "   3 | 0.1351 | 0.1384 | 0.0941 |  0.2898 | 20160 |  5040 |  48  |  117  |   2   |\n",
      "   4 | 0.1329 | 0.1439 | 0.0941 |  0.3070 | 20160 |  5040 |  48  |  117  |   2   |\n",
      "   5 | 0.1349 | 0.1355 | 0.0900 |  0.3029 | 20160 |  5040 |  48  |  117  |   3   |\n",
      "Mean | 0.1351 | 0.1357 | 0.0930 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = sklearn.linear_model.ElasticNet\n",
    "print(f'Investigating performance of {model()} model...')\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses[(responses['fold_r'] != val_fold) & (responses['fold_r'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses[responses['fold_r'] == val_fold]\n",
    "    df_test  = responses[responses['fold_r'] == 0].groupby(['soundscape','masker','smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "    \n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['P_ground_truth'].values\n",
    "    Y_val = df_val['P_ground_truth'].values\n",
    "    Y_test = df_test['P_ground_truth'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[relevant_columns_enet].values \n",
    "    X_val = df_val[relevant_columns_enet].values\n",
    "    X_test = df_test[relevant_columns_enet].values        \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model().fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((X_LR.predict(X_train) - Y_train)**2)\n",
    "    MSE_val = np.mean((X_LR.predict(X_val) - Y_val)**2)\n",
    "    MSE_test = np.mean((X_LR.predict(X_test) - Y_test)**2)\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} |')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we generate the elastic net models and evaluate their performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLEASANTNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nmax_r: -0.007584002720763451\n",
      "M10000_0_r: -0.0017722299435817064\n",
      "M12500_0_r: -0.0007933806330985146\n",
      "Savg_r: 0.0\n",
      "Smax_r: 0.0\n",
      "S05_r: 0.0\n",
      "S10_r: 0.0\n",
      "S20_r: 0.0\n",
      "S30_r: -0.0\n",
      "S40_r: -0.0\n",
      "S50_r: -0.0\n",
      "S60_r: -0.0\n",
      "S70_r: -0.0\n",
      "S80_r: 0.0\n",
      "S90_r: 0.0\n",
      "S95_r: 0.0\n",
      "Navg_r: -0.0\n",
      "Nrmc_r: -0.0\n",
      "N05_r: -0.0\n",
      "N10_r: -0.0\n",
      "N20_r: -0.0\n",
      "N30_r: -0.0\n",
      "N40_r: -0.0\n",
      "N50_r: -0.0\n",
      "N60_r: -0.0\n",
      "N70_r: -0.0\n",
      "N80_r: -0.0\n",
      "N90_r: -0.0\n",
      "N95_r: -0.0\n",
      "Favg_r: 0.0\n",
      "Fmax_r: -0.0\n",
      "F05_r: -0.0\n",
      "F10_r: 0.0\n",
      "F20_r: 0.0\n",
      "F30_r: 0.0\n",
      "F40_r: 0.0\n",
      "F50_r: 0.0\n",
      "F60_r: 0.0\n",
      "F70_r: -0.0\n",
      "F80_r: -0.0\n",
      "F90_r: -0.0\n",
      "F95_r: -0.0\n",
      "LAavg_r: -0.0\n",
      "LAmin_r: -0.0\n",
      "LAmax_r: -0.0\n",
      "LA05_r: -0.0\n",
      "LA10_r: -0.0\n",
      "LA20_r: -0.0\n",
      "LA30_r: -0.0\n",
      "LA40_r: -0.0\n",
      "LA50_r: -0.0\n",
      "LA60_r: -0.0\n",
      "LA70_r: -0.0\n",
      "LA80_r: -0.0\n",
      "LA90_r: -0.0\n",
      "LA95_r: -0.0\n",
      "LCavg_r: -0.0\n",
      "LCmin_r: -0.0\n",
      "LCmax_r: -0.0\n",
      "LC05_r: -0.0\n",
      "LC10_r: -0.0\n",
      "LC20_r: -0.0\n",
      "LC30_r: -0.0\n",
      "LC40_r: -0.0\n",
      "LC50_r: -0.0\n",
      "LC60_r: -0.0\n",
      "LC70_r: -0.0\n",
      "LC80_r: -0.0\n",
      "LC90_r: -0.0\n",
      "LC95_r: -0.0\n",
      "Ravg_r: -0.0\n",
      "Rmax_r: -0.0\n",
      "R05_r: -0.0\n",
      "R10_r: -0.0\n",
      "R20_r: -0.0\n",
      "R30_r: -0.0\n",
      "R40_r: -0.0\n",
      "R50_r: -0.0\n",
      "R60_r: -0.0\n",
      "R70_r: -0.0\n",
      "R80_r: -0.0\n",
      "R90_r: -0.0\n",
      "R95_r: -0.0\n",
      "Tgavg_r: -0.0\n",
      "Tavg_r: -0.0\n",
      "Tmax_r: -0.0\n",
      "T05_r: -0.0\n",
      "T10_r: -0.0\n",
      "T20_r: -0.0\n",
      "T30_r: -0.0\n",
      "T40_r: 0.0\n",
      "T50_r: 0.0\n",
      "T60_r: 0.0\n",
      "T70_r: 0.0\n",
      "T80_r: 0.0\n",
      "T90_r: 0.0\n",
      "T95_r: 0.0\n",
      "M00005_0_r: -0.0\n",
      "M00006_3_r: -0.0\n",
      "M00008_0_r: -0.0\n",
      "M00010_0_r: -0.0\n",
      "M00012_5_r: -0.0\n",
      "M00016_0_r: -0.0\n",
      "M00020_0_r: -0.0\n",
      "M00025_0_r: -0.0\n",
      "M00031_5_r: -0.0\n",
      "M00040_0_r: -0.0\n",
      "M00050_0_r: -0.0\n",
      "M00063_0_r: -0.0\n",
      "M00080_0_r: -0.0\n",
      "M00100_0_r: -0.0\n",
      "M00125_0_r: -0.0\n",
      "M00160_0_r: -0.0\n",
      "M00200_0_r: -0.0\n",
      "M00250_0_r: -0.0\n",
      "M00315_0_r: -0.0\n",
      "M00400_0_r: -0.0\n",
      "M00500_0_r: -0.0\n",
      "M00630_0_r: -0.0\n",
      "M00800_0_r: -0.0\n",
      "M01000_0_r: -0.0\n",
      "M01250_0_r: -0.0\n",
      "M01600_0_r: -0.0\n",
      "M02000_0_r: -0.0\n",
      "M02500_0_r: -0.0\n",
      "M03150_0_r: -0.0\n",
      "M04000_0_r: -0.0\n",
      "M05000_0_r: -0.0\n",
      "M06300_0_r: -0.0\n",
      "M08000_0_r: -0.0\n",
      "M16000_0_r: -0.0\n",
      "M20000_0_r: -0.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_LR is your linear regression model\n",
    "coefficients = X_LR.coef_\n",
    "\n",
    "# Pairing coefficients with feature names\n",
    "feature_importances = list(zip(relevant_columns_enet, coefficients))\n",
    "\n",
    "# Sorting feature importances by absolute value of coefficient\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Displaying feature importances\n",
    "for feature, importance in feature_importances:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can see that only Nmax_r, M12500_0_r and M10000_0_r features play a role in the decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVENTFULNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.linear_model.ElasticNet\n",
    "print(f'Investigating performance of {model()} model...')\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses[(responses['fold_r'] != val_fold) & (responses['fold_r'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses[responses['fold_r'] == val_fold]\n",
    "    df_test  = responses[responses['fold_r'] == 0].groupby(['soundscape','masker','smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['E_ground_truth'].values\n",
    "    Y_val = df_val['E_ground_truth'].values\n",
    "    Y_test = df_test['E_ground_truth'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[relevant_columns_enet].values \n",
    "    X_val = df_val[relevant_columns_enet].values\n",
    "    X_test = df_test[relevant_columns_enet].values        \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model().fit(X_train, Y_train)\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((X_LR.predict(X_train) - Y_train)**2)\n",
    "    MSE_val = np.mean((X_LR.predict(X_val) - Y_val)**2)\n",
    "    MSE_test = np.mean((X_LR.predict(X_test) - Y_test)**2)\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d}')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_LR is your linear regression model\n",
    "coefficients = X_LR.coef_\n",
    "\n",
    "# Pairing coefficients with feature names\n",
    "feature_importances = list(zip(relevant_columns_enet, coefficients))\n",
    "\n",
    "# Sorting feature importances by absolute value of coefficient\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Displaying feature importances\n",
    "for feature, importance in feature_importances:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that only Nmax_r, M00630_0_r, M00005_0_r and M00006_3_r features play a role in the decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat process including maskers as input features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which sound source is present in a soundscape can provide very usefull and direct information about the pleasantness and eventfulness of a sound scene. Therefore, we are introducing the masker column as an additional input feature to test any improvements in the predictions of the elastic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns_enet = ['Savg_r','Smax_r','S05_r','S10_r','S20_r','S30_r','S40_r','S50_r','S60_r','S70_r','S80_r','S90_r','S95_r',\n",
    "                         'Navg_r','Nrmc_r','Nmax_r','N05_r','N10_r','N20_r','N30_r','N40_r','N50_r','N60_r','N70_r','N80_r','N90_r','N95_r',\n",
    "                         'Favg_r','Fmax_r','F05_r','F10_r','F20_r','F30_r','F40_r','F50_r','F60_r','F70_r','F80_r','F90_r','F95_r',\n",
    "                         'LAavg_r','LAmin_r','LAmax_r','LA05_r','LA10_r','LA20_r','LA30_r','LA40_r','LA50_r','LA60_r','LA70_r','LA80_r','LA90_r','LA95_r',\n",
    "                         'LCavg_r','LCmin_r','LCmax_r','LC05_r','LC10_r','LC20_r','LC30_r','LC40_r','LC50_r','LC60_r','LC70_r','LC80_r','LC90_r','LC95_r',\n",
    "                         'Ravg_r','Rmax_r','R05_r','R10_r','R20_r','R30_r','R40_r','R50_r','R60_r','R70_r','R80_r','R90_r','R95_r',\n",
    "                         'Tgavg_r','Tavg_r','Tmax_r','T05_r','T10_r','T20_r','T30_r','T40_r','T50_r','T60_r','T70_r','T80_r','T90_r','T95_r',\n",
    "                         'M00005_0_r','M00006_3_r','M00008_0_r','M00010_0_r','M00012_5_r','M00016_0_r','M00020_0_r','M00025_0_r','M00031_5_r','M00040_0_r',\n",
    "                         'M00050_0_r','M00063_0_r','M00080_0_r','M00100_0_r','M00125_0_r','M00160_0_r','M00200_0_r','M00250_0_r','M00315_0_r','M00400_0_r',\n",
    "                         'M00500_0_r','M00630_0_r','M00800_0_r','M01000_0_r','M01250_0_r','M01600_0_r','M02000_0_r','M02500_0_r','M03150_0_r','M04000_0_r',\n",
    "                         'M05000_0_r','M06300_0_r','M08000_0_r','M10000_0_r','M12500_0_r','M16000_0_r','M20000_0_r', 'masker_bird' , 'masker_construction',  \n",
    "                         'masker_silence',  'masker_traffic','masker_water',  'masker_wind']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pleasantness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating performance of ElasticNet() model...\n",
      "     |    Mean squared error    |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "   1 | 0.1360 | 0.1321 | 0.0912 |  0.3074 | 20160 |  5040 |  48  |  138  |   3  \n",
      "   2 | 0.1368 | 0.1284 | 0.0954 |  0.3105 | 20160 |  5040 |  48  |  138  |   2  \n",
      "   3 | 0.1351 | 0.1384 | 0.0941 |  0.2898 | 20160 |  5040 |  48  |  138  |   2  \n",
      "   4 | 0.1329 | 0.1439 | 0.0941 |  0.3070 | 20160 |  5040 |  48  |  138  |   2  \n",
      "   5 | 0.1349 | 0.1355 | 0.0900 |  0.3029 | 20160 |  5040 |  48  |  138  |   3  \n",
      "Mean | 0.1351 | 0.1357 | 0.0930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = sklearn.linear_model.ElasticNet\n",
    "print(f'Investigating performance of {model()} model...')\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses[(responses['fold_r'] != val_fold) & (responses['fold_r'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses[responses['fold_r'] == val_fold]\n",
    "    df_test  = responses[responses['fold_r'] == 0].groupby(['soundscape','masker','smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['P_ground_truth'].values\n",
    "    Y_val = df_val['P_ground_truth'].values\n",
    "    Y_test = df_test['P_ground_truth'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[relevant_columns_enet].values \n",
    "    X_val = df_val[relevant_columns_enet].values\n",
    "    X_test = df_test[relevant_columns_enet].values        \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model().fit(X_train, Y_train)\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((X_LR.predict(X_train) - Y_train)**2)\n",
    "    MSE_val = np.mean((X_LR.predict(X_val) - Y_val)**2)\n",
    "    MSE_test = np.mean((X_LR.predict(X_test) - Y_test)**2)\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d}')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nmax_r: -0.008460668968782802\n",
      "M12500_0_r: -0.0013485302212456784\n",
      "M10000_0_r: -0.0004837700048420824\n",
      "Savg_r: 0.0\n",
      "Smax_r: 0.0\n",
      "S05_r: 0.0\n",
      "S10_r: 0.0\n",
      "S20_r: -0.0\n",
      "S30_r: -0.0\n",
      "S40_r: -0.0\n",
      "S50_r: -0.0\n",
      "S60_r: -0.0\n",
      "S70_r: -0.0\n",
      "S80_r: 0.0\n",
      "S90_r: 0.0\n",
      "S95_r: 0.0\n",
      "Navg_r: -0.0\n",
      "Nrmc_r: -0.0\n",
      "N05_r: -0.0\n",
      "N10_r: -0.0\n",
      "N20_r: -0.0\n",
      "N30_r: -0.0\n",
      "N40_r: -0.0\n",
      "N50_r: -0.0\n",
      "N60_r: -0.0\n",
      "N70_r: -0.0\n",
      "N80_r: -0.0\n",
      "N90_r: -0.0\n",
      "N95_r: -0.0\n",
      "Favg_r: 0.0\n",
      "Fmax_r: -0.0\n",
      "F05_r: 0.0\n",
      "F10_r: 0.0\n",
      "F20_r: 0.0\n",
      "F30_r: 0.0\n",
      "F40_r: 0.0\n",
      "F50_r: 0.0\n",
      "F60_r: 0.0\n",
      "F70_r: 0.0\n",
      "F80_r: 0.0\n",
      "F90_r: 0.0\n",
      "F95_r: 0.0\n",
      "LAavg_r: -0.0\n",
      "LAmin_r: -0.0\n",
      "LAmax_r: -0.0\n",
      "LA05_r: -0.0\n",
      "LA10_r: -0.0\n",
      "LA20_r: -0.0\n",
      "LA30_r: -0.0\n",
      "LA40_r: -0.0\n",
      "LA50_r: -0.0\n",
      "LA60_r: -0.0\n",
      "LA70_r: -0.0\n",
      "LA80_r: -0.0\n",
      "LA90_r: -0.0\n",
      "LA95_r: -0.0\n",
      "LCavg_r: -0.0\n",
      "LCmin_r: -0.0\n",
      "LCmax_r: -0.0\n",
      "LC05_r: -0.0\n",
      "LC10_r: -0.0\n",
      "LC20_r: -0.0\n",
      "LC30_r: -0.0\n",
      "LC40_r: -0.0\n",
      "LC50_r: -0.0\n",
      "LC60_r: -0.0\n",
      "LC70_r: -0.0\n",
      "LC80_r: -0.0\n",
      "LC90_r: -0.0\n",
      "LC95_r: -0.0\n",
      "Ravg_r: -0.0\n",
      "Rmax_r: -0.0\n",
      "R05_r: -0.0\n",
      "R10_r: -0.0\n",
      "R20_r: -0.0\n",
      "R30_r: -0.0\n",
      "R40_r: -0.0\n",
      "R50_r: -0.0\n",
      "R60_r: -0.0\n",
      "R70_r: -0.0\n",
      "R80_r: -0.0\n",
      "R90_r: -0.0\n",
      "R95_r: -0.0\n",
      "Tgavg_r: -0.0\n",
      "Tavg_r: 0.0\n",
      "Tmax_r: -0.0\n",
      "T05_r: -0.0\n",
      "T10_r: -0.0\n",
      "T20_r: -0.0\n",
      "T30_r: 0.0\n",
      "T40_r: 0.0\n",
      "T50_r: 0.0\n",
      "T60_r: 0.0\n",
      "T70_r: 0.0\n",
      "T80_r: 0.0\n",
      "T90_r: 0.0\n",
      "T95_r: 0.0\n",
      "M00005_0_r: -0.0\n",
      "M00006_3_r: -0.0\n",
      "M00008_0_r: -0.0\n",
      "M00010_0_r: -0.0\n",
      "M00012_5_r: -0.0\n",
      "M00016_0_r: -0.0\n",
      "M00020_0_r: -0.0\n",
      "M00025_0_r: -0.0\n",
      "M00031_5_r: -0.0\n",
      "M00040_0_r: -0.0\n",
      "M00050_0_r: -0.0\n",
      "M00063_0_r: -0.0\n",
      "M00080_0_r: -0.0\n",
      "M00100_0_r: -0.0\n",
      "M00125_0_r: -0.0\n",
      "M00160_0_r: -0.0\n",
      "M00200_0_r: -0.0\n",
      "M00250_0_r: -0.0\n",
      "M00315_0_r: -0.0\n",
      "M00400_0_r: -0.0\n",
      "M00500_0_r: -0.0\n",
      "M00630_0_r: -0.0\n",
      "M00800_0_r: -0.0\n",
      "M01000_0_r: -0.0\n",
      "M01250_0_r: -0.0\n",
      "M01600_0_r: -0.0\n",
      "M02000_0_r: -0.0\n",
      "M02500_0_r: -0.0\n",
      "M03150_0_r: -0.0\n",
      "M04000_0_r: -0.0\n",
      "M05000_0_r: -0.0\n",
      "M06300_0_r: -0.0\n",
      "M08000_0_r: -0.0\n",
      "M16000_0_r: -0.0\n",
      "M20000_0_r: -0.0\n",
      "masker_bird: 0.0\n",
      "masker_construction: -0.0\n",
      "masker_silence: 0.0\n",
      "masker_traffic: -0.0\n",
      "masker_water: 0.0\n",
      "masker_wind: -0.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_LR is your linear regression model\n",
    "coefficients = X_LR.coef_\n",
    "\n",
    "# Pairing coefficients with feature names\n",
    "feature_importances = list(zip(relevant_columns_enet, coefficients))\n",
    "\n",
    "# Sorting feature importances by absolute value of coefficient\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Displaying feature importances\n",
    "for feature, importance in feature_importances:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eventfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating performance of ElasticNet() model...\n",
      "     |    Mean squared error    |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "   1 | 0.1376 | 0.1297 | 0.0425 | -0.2748 | 20160 |  5040 |  48  |  138  |   4  \n",
      "   2 | 0.1373 | 0.1365 | 0.0463 | -0.2423 | 20160 |  5040 |  48  |  138  |   4  \n",
      "   3 | 0.1390 | 0.1247 | 0.0434 | -0.3780 | 20160 |  5040 |  48  |  138  |   6  \n",
      "   4 | 0.1352 | 0.1401 | 0.0439 | -0.3372 | 20160 |  5040 |  48  |  138  |   4  \n",
      "   5 | 0.1322 | 0.1546 | 0.0450 | -0.3418 | 20160 |  5040 |  48  |  138  |   4  \n",
      "Mean | 0.1363 | 0.1371 | 0.0442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = sklearn.linear_model.ElasticNet\n",
    "print(f'Investigating performance of {model()} model...')\n",
    "MSEs_train = []\n",
    "MSEs_val = []\n",
    "MSEs_test = []\n",
    "\n",
    "print('     |    Mean squared error    |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "    # Extract dataframes\n",
    "    df_train = responses[(responses['fold_r'] != val_fold) & (responses['fold_r'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "    df_val   = responses[responses['fold_r'] == val_fold]\n",
    "    df_test  = responses[responses['fold_r'] == 0].groupby(['soundscape','masker','smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "    # Get ground-truth labels\n",
    "    Y_train = df_train['E_ground_truth'].values\n",
    "    Y_val = df_val['E_ground_truth'].values\n",
    "    Y_test = df_test['E_ground_truth'].values\n",
    "\n",
    "    # Get features\n",
    "    X_train = df_train[relevant_columns_enet].values \n",
    "    X_val = df_val[relevant_columns_enet].values\n",
    "    X_test = df_test[relevant_columns_enet].values        \n",
    "\n",
    "    # Fit model\n",
    "    X_LR = model().fit(X_train, Y_train)\n",
    "\n",
    "    # Get MSEs\n",
    "    MSE_train = np.mean((X_LR.predict(X_train) - Y_train)**2)\n",
    "    MSE_val = np.mean((X_LR.predict(X_val) - Y_val)**2)\n",
    "    MSE_test = np.mean((X_LR.predict(X_test) - Y_test)**2)\n",
    "\n",
    "    # Add metrics\n",
    "    MSEs_train.append(MSE_train)\n",
    "    MSEs_val.append(MSE_val)\n",
    "    MSEs_test.append(MSE_test)\n",
    "\n",
    "    print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d}')\n",
    "\n",
    "print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nmax_r: 0.009261245154877234\n",
      "M00630_0_r: 0.0018587244415044907\n",
      "M00005_0_r: -0.0007956206191416479\n",
      "M00006_3_r: -0.00020145418858936328\n",
      "Savg_r: 0.0\n",
      "Smax_r: 0.0\n",
      "S05_r: 0.0\n",
      "S10_r: 0.0\n",
      "S20_r: 0.0\n",
      "S30_r: 0.0\n",
      "S40_r: 0.0\n",
      "S50_r: 0.0\n",
      "S60_r: 0.0\n",
      "S70_r: 0.0\n",
      "S80_r: 0.0\n",
      "S90_r: 0.0\n",
      "S95_r: 0.0\n",
      "Navg_r: 0.0\n",
      "Nrmc_r: 0.0\n",
      "N05_r: 0.0\n",
      "N10_r: 0.0\n",
      "N20_r: 0.0\n",
      "N30_r: 0.0\n",
      "N40_r: 0.0\n",
      "N50_r: 0.0\n",
      "N60_r: 0.0\n",
      "N70_r: 0.0\n",
      "N80_r: 0.0\n",
      "N90_r: 0.0\n",
      "N95_r: 0.0\n",
      "Favg_r: 0.0\n",
      "Fmax_r: 0.0\n",
      "F05_r: 0.0\n",
      "F10_r: 0.0\n",
      "F20_r: 0.0\n",
      "F30_r: 0.0\n",
      "F40_r: 0.0\n",
      "F50_r: 0.0\n",
      "F60_r: 0.0\n",
      "F70_r: 0.0\n",
      "F80_r: 0.0\n",
      "F90_r: 0.0\n",
      "F95_r: 0.0\n",
      "LAavg_r: 0.0\n",
      "LAmin_r: 0.0\n",
      "LAmax_r: 0.0\n",
      "LA05_r: 0.0\n",
      "LA10_r: 0.0\n",
      "LA20_r: 0.0\n",
      "LA30_r: 0.0\n",
      "LA40_r: 0.0\n",
      "LA50_r: 0.0\n",
      "LA60_r: 0.0\n",
      "LA70_r: 0.0\n",
      "LA80_r: 0.0\n",
      "LA90_r: 0.0\n",
      "LA95_r: 0.0\n",
      "LCavg_r: 0.0\n",
      "LCmin_r: 0.0\n",
      "LCmax_r: 0.0\n",
      "LC05_r: 0.0\n",
      "LC10_r: 0.0\n",
      "LC20_r: 0.0\n",
      "LC30_r: 0.0\n",
      "LC40_r: 0.0\n",
      "LC50_r: 0.0\n",
      "LC60_r: 0.0\n",
      "LC70_r: 0.0\n",
      "LC80_r: 0.0\n",
      "LC90_r: 0.0\n",
      "LC95_r: 0.0\n",
      "Ravg_r: 0.0\n",
      "Rmax_r: 0.0\n",
      "R05_r: 0.0\n",
      "R10_r: 0.0\n",
      "R20_r: 0.0\n",
      "R30_r: 0.0\n",
      "R40_r: 0.0\n",
      "R50_r: 0.0\n",
      "R60_r: 0.0\n",
      "R70_r: 0.0\n",
      "R80_r: 0.0\n",
      "R90_r: 0.0\n",
      "R95_r: 0.0\n",
      "Tgavg_r: 0.0\n",
      "Tavg_r: 0.0\n",
      "Tmax_r: 0.0\n",
      "T05_r: 0.0\n",
      "T10_r: 0.0\n",
      "T20_r: 0.0\n",
      "T30_r: 0.0\n",
      "T40_r: 0.0\n",
      "T50_r: 0.0\n",
      "T60_r: 0.0\n",
      "T70_r: 0.0\n",
      "T80_r: 0.0\n",
      "T90_r: 0.0\n",
      "T95_r: 0.0\n",
      "M00008_0_r: -0.0\n",
      "M00010_0_r: -0.0\n",
      "M00012_5_r: -0.0\n",
      "M00016_0_r: -0.0\n",
      "M00020_0_r: -0.0\n",
      "M00025_0_r: 0.0\n",
      "M00031_5_r: 0.0\n",
      "M00040_0_r: 0.0\n",
      "M00050_0_r: 0.0\n",
      "M00063_0_r: -0.0\n",
      "M00080_0_r: -0.0\n",
      "M00100_0_r: 0.0\n",
      "M00125_0_r: 0.0\n",
      "M00160_0_r: 0.0\n",
      "M00200_0_r: 0.0\n",
      "M00250_0_r: 0.0\n",
      "M00315_0_r: 0.0\n",
      "M00400_0_r: 0.0\n",
      "M00500_0_r: 0.0\n",
      "M00800_0_r: 0.0\n",
      "M01000_0_r: 0.0\n",
      "M01250_0_r: 0.0\n",
      "M01600_0_r: 0.0\n",
      "M02000_0_r: 0.0\n",
      "M02500_0_r: 0.0\n",
      "M03150_0_r: 0.0\n",
      "M04000_0_r: 0.0\n",
      "M05000_0_r: 0.0\n",
      "M06300_0_r: 0.0\n",
      "M08000_0_r: 0.0\n",
      "M10000_0_r: 0.0\n",
      "M12500_0_r: 0.0\n",
      "M16000_0_r: 0.0\n",
      "M20000_0_r: 0.0\n",
      "masker_bird: 0.0\n",
      "masker_construction: 0.0\n",
      "masker_silence: -0.0\n",
      "masker_traffic: 0.0\n",
      "masker_water: -0.0\n",
      "masker_wind: -0.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_LR is your linear regression model\n",
    "coefficients = X_LR.coef_\n",
    "\n",
    "# Pairing coefficients with feature names\n",
    "feature_importances = list(zip(relevant_columns_enet, coefficients))\n",
    "\n",
    "# Sorting feature importances by absolute value of coefficient\n",
    "feature_importances.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Displaying feature importances\n",
    "for feature, importance in feature_importances:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the maskers as features didn't provide any improvements to the elastic net linear regression model. In fact, we can see which features are employed or perform a more important role are only :\n",
    "\n",
    "For pleasantness\n",
    "- Nmax_r: -0.008460668968782803\n",
    "- M12500_0_r: -0.00134853022124568\n",
    "- M10000_0_r: -0.0004837700048420805\n",
    "\n",
    "For eventfulness\n",
    "- Nmax_r: 0.009261245154877232\n",
    "- M00630_0_r: 0.001858724441504498\n",
    "- M00005_0_r: -0.0007956206191416494\n",
    "- M00006_3_r: -0.00020145418858936152\n",
    "\n",
    "Meaning that only features related to loudness (Nmax_r) and to frequency energy distribution (M...) play a role in the model. The coefficients indicate the contribution of each feature to the model's predictions. Here's how to interpret the results:\n",
    "- Positive Coefficient: A positive coefficient (e.g., Savg_r: 0.123) means that as the value of the feature increases, the predicted target variable is expected to increase by the coefficient value.\n",
    "- Negative Coefficient: A negative coefficient (e.g., Nmax_r: -0.008) means that as the value of the feature increases, the predicted target variable is expected to decrease by the absolute value of the coefficient.\n",
    "- Coefficient Magnitude: The magnitude (absolute value) of the coefficient indicates the strength of the effect. Larger magnitudes imply a stronger impact on the predictions.\n",
    "\n",
    "Then, it makes sense that as loudness increases, pleasantness decreases but eventfulness increases. It also makes sense that pleasantness is more influenced by high frequency bands content (they can be more annoying) and eventfulness with low frequency content (?why)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "araus-mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
