{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from SoundLights.features_groups import  ARAUS_features, Freesound_features, mix_features, chosen_features\n",
    "\n",
    "normalise = lambda X: (X-np.mean(X,axis=0,keepdims=True))/np.std(X,axis=0,keepdims=True) # Normalise an (n,p) numpy array to mean 0, variance 1.\n",
    "clip = lambda x, x_min = -1, x_max = 1: np.where(np.where(x < x_min,x_min,x) > x_max, x_max, np.where(x < x_min,x_min,x)) # Clip an array to values between x_min and x_max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARAUS.sharpness.avg', 'ARAUS.sharpness.max', 'ARAUS.sharpness.p05', 'ARAUS.sharpness.p10', 'ARAUS.sharpness.p20', 'ARAUS.sharpness.p30', 'ARAUS.sharpness.p40', 'ARAUS.sharpness.p50', 'ARAUS.sharpness.p60', 'ARAUS.sharpness.p70', 'ARAUS.sharpness.p80', 'ARAUS.sharpness.p90', 'ARAUS.sharpness.p95', 'ARAUS.loudness.avg', 'ARAUS.loudness.max', 'ARAUS.loudness.p05', 'ARAUS.loudness.p10', 'ARAUS.loudness.p20', 'ARAUS.loudness.p30', 'ARAUS.loudness.p40', 'ARAUS.loudness.p50', 'ARAUS.loudness.p60', 'ARAUS.loudness.p70', 'ARAUS.loudness.p80', 'ARAUS.loudness.p90', 'ARAUS.loudness.p95', 'ARAUS.fluctuation.avg', 'ARAUS.fluctuation.max', 'ARAUS.fluctuation.p05', 'ARAUS.fluctuation.p10', 'ARAUS.fluctuation.p20', 'ARAUS.fluctuation.p30', 'ARAUS.fluctuation.p40', 'ARAUS.fluctuation.p50', 'ARAUS.fluctuation.p60', 'ARAUS.fluctuation.p70', 'ARAUS.fluctuation.p80', 'ARAUS.fluctuation.p90', 'ARAUS.fluctuation.p95', 'ARAUS.LA.avg', 'ARAUS.LA.min', 'ARAUS.LA.max', 'ARAUS.LA.p05', 'ARAUS.LA.p10', 'ARAUS.LA.p20', 'ARAUS.LA.p30', 'ARAUS.LA.p40', 'ARAUS.LA.p50', 'ARAUS.LA.p60', 'ARAUS.LA.p70', 'ARAUS.LA.p80', 'ARAUS.LA.p90', 'ARAUS.LA.p95', 'ARAUS.LC.avg', 'ARAUS.LC.min', 'ARAUS.LC.max', 'ARAUS.LC.p05', 'ARAUS.LC.p10', 'ARAUS.LC.p20', 'ARAUS.LC.p30', 'ARAUS.LC.p40', 'ARAUS.LC.p50', 'ARAUS.LC.p60', 'ARAUS.LC.p70', 'ARAUS.LC.p80', 'ARAUS.LC.p90', 'ARAUS.LC.p95', 'ARAUS.roughness.avg', 'ARAUS.roughness.max', 'ARAUS.roughness.p05', 'ARAUS.roughness.p10', 'ARAUS.roughness.p20', 'ARAUS.roughness.p30', 'ARAUS.roughness.p40', 'ARAUS.roughness.p50', 'ARAUS.roughness.p60', 'ARAUS.roughness.p70', 'ARAUS.roughness.p80', 'ARAUS.roughness.p90', 'ARAUS.roughness.p95', 'ARAUS.energy_frequency.00006_3', 'ARAUS.energy_frequency.00012_5', 'ARAUS.energy_frequency.00016_0', 'ARAUS.energy_frequency.00025_0', 'ARAUS.energy_frequency.00031_5', 'ARAUS.energy_frequency.00040_0', 'ARAUS.energy_frequency.00050_0', 'ARAUS.energy_frequency.00063_0', 'ARAUS.energy_frequency.00080_0', 'ARAUS.energy_frequency.00100_0', 'ARAUS.energy_frequency.00125_0', 'ARAUS.energy_frequency.00160_0', 'ARAUS.energy_frequency.00200_0', 'ARAUS.energy_frequency.00250_0', 'ARAUS.energy_frequency.00315_0', 'ARAUS.energy_frequency.00400_0', 'ARAUS.energy_frequency.00500_0', 'ARAUS.energy_frequency.00630_0', 'ARAUS.energy_frequency.00800_0', 'ARAUS.energy_frequency.01000_0', 'ARAUS.energy_frequency.01250_0', 'ARAUS.energy_frequency.01600_0', 'ARAUS.energy_frequency.02000_0', 'ARAUS.energy_frequency.02500_0', 'ARAUS.energy_frequency.03150_0', 'ARAUS.energy_frequency.04000_0', 'ARAUS.energy_frequency.05000_0', 'ARAUS.energy_frequency.06300_0', 'ARAUS.energy_frequency.08000_0', 'ARAUS.energy_frequency.10000_0', 'ARAUS.energy_frequency.12500_0', 'ARAUS.energy_frequency.16000_0', 'ARAUS.energy_frequency.20000_0']\n"
     ]
    }
   ],
   "source": [
    "responses_ARAUS= pd.read_csv(os.path.join('..','data','SoundLights_ARAUS.csv'), dtype = {'info.participant':str}) #, dtype = {'participant':str}\n",
    "responses_ARAUS=responses_ARAUS.drop(\"info.file\", axis=1)\n",
    "responses_ARAUS=responses_ARAUS.drop(\"info.participant\", axis=1)\n",
    "\n",
    "# Drop columns that contain all zero values\n",
    "# Store column names before dropping\n",
    "columns_before = responses_ARAUS.columns.tolist()\n",
    "# Drop zero-columns\n",
    "responses_ARAUS = responses_ARAUS.loc[:, (responses_ARAUS != 0).any(axis=0)]\n",
    "# Store column names after dropping\n",
    "columns_after = responses_ARAUS.columns.tolist()\n",
    "# Determine which columns were dropped\n",
    "columns_dropped = [col for col in columns_before if col not in columns_after]\n",
    "# Drop those columns from ARAUS_features\n",
    "ARAUS_features = [col for col in ARAUS_features if col not in columns_dropped]\n",
    "print(ARAUS_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_Freesound= pd.read_csv(os.path.join('..','data','SoundLights_Freesound.csv')) #, dtype = {'participant':str}\n",
    "responses_Freesound=responses_Freesound.drop(\"info.file\", axis=1)\n",
    "responses_Freesound=responses_Freesound.drop(\"info.participant\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_Mix= pd.read_csv(os.path.join('..','data','SoundLights_mix.csv')) #, dtype = {'participant':str}\n",
    "responses_Mix=responses_Mix.drop(\"info.file\", axis=1)\n",
    "responses_Mix=responses_Mix.drop(\"info.participant\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_complete= pd.read_csv(os.path.join('..','data','SoundLights_complete.csv')) #, dtype = {'participant':str}\n",
    "responses_complete=responses_complete.drop(\"info.file\", axis=1)\n",
    "responses_complete=responses_complete.drop(\"info.participant\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "Parameters  0.1 0.5\n",
      "Mean | 0.1243 | 0.1288 | 0.0794 | 0.2854 | 0.2902 | 0.2377 |\n",
      "Parameters  0.2 0.5\n",
      "Mean | 0.1255 | 0.1289 | 0.0768 | 0.2868 | 0.2906 | 0.2269 |\n",
      "Parameters  0.3 0.5\n",
      "Mean | 0.1257 | 0.1289 | 0.0774 | 0.2872 | 0.2906 | 0.2270 |\n",
      "Parameters  0.4 0.5\n",
      "Mean | 0.1258 | 0.1289 | 0.0779 | 0.2874 | 0.2907 | 0.2277 |\n",
      "Parameters  0.5 0.5\n",
      "Mean | 0.1259 | 0.1289 | 0.0784 | 0.2875 | 0.2908 | 0.2283 |\n",
      "Parameters  0.6 0.5\n",
      "Mean | 0.1260 | 0.1289 | 0.0786 | 0.2877 | 0.2908 | 0.2286 |\n",
      "Parameters  0.7 0.5\n",
      "Mean | 0.1261 | 0.1289 | 0.0788 | 0.2878 | 0.2909 | 0.2287 |\n",
      "Parameters  0.8 0.5\n",
      "Mean | 0.1262 | 0.1289 | 0.0787 | 0.2880 | 0.2909 | 0.2286 |\n",
      "Parameters  0.9 0.5\n",
      "Mean | 0.1263 | 0.1289 | 0.0787 | 0.2881 | 0.2909 | 0.2284 |\n",
      "Parameters  1 0.5\n",
      "Mean | 0.1264 | 0.1289 | 0.0786 | 0.2882 | 0.2910 | 0.2283 |\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "# Suppress ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "# Define your ElasticNet model with specific hyperparameters\n",
    "alpha = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1] \n",
    "l1_ratio = 0.5\n",
    "print('     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "\n",
    "for value in alpha:\n",
    "\n",
    "    model = ElasticNet(alpha=value, l1_ratio=l1_ratio, selection=\"random\")\n",
    "    #print(f'Investigating performance of {model} model...')\n",
    "\n",
    "    MSEs_train = []\n",
    "    MSEs_val = []\n",
    "    MSEs_test = []\n",
    "    MEs_train = []\n",
    "    MEs_val = []\n",
    "    MEs_test = []\n",
    "\n",
    "    \n",
    "    for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "        # Extract dataframes\n",
    "        df_train = responses_complete[(responses_complete['info.fold'] != val_fold) & (responses_complete['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "        df_val   = responses_complete[responses_complete['info.fold'] == val_fold]\n",
    "        df_test  = responses_complete[responses_complete['info.fold'] == 0].groupby(['info.soundscape','info.masker','info.smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "        # Get ground-truth labels\n",
    "        Y_train = df_train['info.P_ground_truth'].values\n",
    "        Y_val = df_val['info.P_ground_truth'].values\n",
    "        Y_test = df_test['info.P_ground_truth'].values\n",
    "\n",
    "        # Get features\n",
    "        X_train = df_train[chosen_features].values\n",
    "        X_val =df_val[chosen_features].values\n",
    "        X_test = df_test[chosen_features].values    \n",
    "\n",
    "        # Fit model\n",
    "        X_LR = model.fit(X_train, Y_train)\n",
    "\n",
    "        # Get MSEs\n",
    "        MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "        MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "        MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "        ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "        ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "        ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "\n",
    "        # Add metrics\n",
    "        MSEs_train.append(MSE_train)\n",
    "        MSEs_val.append(MSE_val)\n",
    "        MSEs_test.append(MSE_test)\n",
    "        MEs_train.append(ME_train)\n",
    "        MEs_val.append(ME_val)\n",
    "        MEs_test.append(ME_test)\n",
    "\n",
    "        #print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "    print(\"Parameters \",value, l1_ratio )\n",
    "    print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust l1_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ \n",
      "Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-\n",
      "     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures \n",
      "-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------\n",
      "Parameters  0.2 0.1\n",
      "Mean | 0.1233 | 0.1286 | 0.0848 | 0.2840 | 0.2897 | 0.2516 |\n",
      "Parameters  0.2 0.2\n",
      "Mean | 0.1241 | 0.1287 | 0.0806 | 0.2851 | 0.2900 | 0.2420 |\n",
      "Parameters  0.2 0.3\n",
      "Mean | 0.1246 | 0.1288 | 0.0782 | 0.2858 | 0.2903 | 0.2338 |\n",
      "Parameters  0.2 0.4\n",
      "Mean | 0.1251 | 0.1288 | 0.0770 | 0.2864 | 0.2904 | 0.2291 |\n",
      "Parameters  0.2 0.5\n",
      "Mean | 0.1255 | 0.1289 | 0.0768 | 0.2868 | 0.2906 | 0.2269 |\n",
      "Parameters  0.2 0.6\n",
      "Mean | 0.1256 | 0.1289 | 0.0770 | 0.2871 | 0.2906 | 0.2266 |\n",
      "Parameters  0.2 0.7\n",
      "Mean | 0.1257 | 0.1289 | 0.0773 | 0.2872 | 0.2906 | 0.2269 |\n",
      "Parameters  0.2 0.8\n",
      "Mean | 0.1258 | 0.1289 | 0.0774 | 0.2872 | 0.2906 | 0.2271 |\n",
      "Parameters  0.2 0.9\n",
      "Mean | 0.1258 | 0.1289 | 0.0776 | 0.2873 | 0.2907 | 0.2273 |\n",
      "Parameters  0.2 1\n",
      "Mean | 0.1258 | 0.1289 | 0.0779 | 0.2874 | 0.2907 | 0.2277 |\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "# Suppress ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "# Define your ElasticNet model with specific hyperparameters\n",
    "alpha = 0.2 \n",
    "l1_ratio = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1] #[0.5,0.5]#\n",
    "print('     |    Mean squared error    |        Mean  error       |         |       # samples      | #     | # NZ ')\n",
    "print('Fold |--------+--------+--------|--------+--------+--------| Inter-  |-------+-------+------| feat- | feat-')\n",
    "print('     | Train  |   Val  |  Test  | Train  |   Val  |  Test  |  cept   | Train |  Val  | Test | ures  | ures ')\n",
    "print('-----+--------+--------+--------+--------+--------+--------+---------+-------+-------+------+-------+------')\n",
    "\n",
    "for value in l1_ratio:\n",
    "\n",
    "    model = ElasticNet(alpha=alpha, l1_ratio=value, selection=\"random\")\n",
    "    #print(f'Investigating performance of {model} model...')\n",
    "\n",
    "    MSEs_train = []\n",
    "    MSEs_val = []\n",
    "    MSEs_test = []\n",
    "    MEs_train = []\n",
    "    MEs_val = []\n",
    "    MEs_test = []\n",
    "\n",
    "    \n",
    "    for val_fold in [1,2,3,4,5]:\n",
    "\n",
    "        # Extract dataframes\n",
    "        df_train = responses_complete[(responses_complete['info.fold'] != val_fold) & (responses_complete['info.fold'] > 0)] # For the training set, use all samples that are not in the test set (fold 0) and current validation fold.\n",
    "        df_val   = responses_complete[responses_complete['info.fold'] == val_fold]\n",
    "        df_test  = responses_complete[responses_complete['info.fold'] == 0].groupby(['info.soundscape','info.masker','info.smr']).mean() # For the test set, the same 48 stimuli were shown to all participants so we take the mean of their ratings as the ground truth\n",
    "\n",
    "        # Get ground-truth labels\n",
    "        Y_train = df_train['info.P_ground_truth'].values\n",
    "        Y_val = df_val['info.P_ground_truth'].values\n",
    "        Y_test = df_test['info.P_ground_truth'].values\n",
    "\n",
    "        # Get features\n",
    "        X_train = df_train[chosen_features].values\n",
    "        X_val =df_val[chosen_features].values\n",
    "        X_test = df_test[chosen_features].values    \n",
    "\n",
    "        # Fit model\n",
    "        X_LR = model.fit(X_train, Y_train)\n",
    "\n",
    "        # Get MSEs\n",
    "        MSE_train = np.mean((clip(X_LR.predict(X_train)) - Y_train)**2)\n",
    "        MSE_val = np.mean((clip(X_LR.predict(X_val)) - Y_val)**2)\n",
    "        MSE_test = np.mean((clip(X_LR.predict(X_test)) - Y_test)**2)\n",
    "        ME_train = np.mean(np.abs(clip(X_LR.predict(X_train)) - Y_train))\n",
    "        ME_val = np.mean(np.abs(clip(X_LR.predict(X_val)) - Y_val))\n",
    "        ME_test = np.mean(np.abs(clip(X_LR.predict(X_test)) - Y_test))\n",
    "\n",
    "        # Add metrics\n",
    "        MSEs_train.append(MSE_train)\n",
    "        MSEs_val.append(MSE_val)\n",
    "        MSEs_test.append(MSE_test)\n",
    "        MEs_train.append(ME_train)\n",
    "        MEs_val.append(ME_val)\n",
    "        MEs_test.append(ME_test)\n",
    "\n",
    "        #print(f'{val_fold:4d} | {MSE_train:.4f} | {MSE_val:.4f} | {MSE_test:.4f} | {ME_train:.4f} | {ME_val:.4f} | {ME_test:.4f} | {X_LR.intercept_:7.4f} | {X_train.shape[0]:5d} | {X_val.shape[0]:5d} | {X_test.shape[0]:^4d} | {X_train.shape[1]:^5d} | {np.sum(np.abs(X_LR.coef_) > 0):^5d} |')\n",
    "    print(\"Parameters \",alpha, value )\n",
    "    print(f'Mean | {np.mean(MSEs_train):.4f} | {np.mean(MSEs_val):.4f} | {np.mean(MSEs_test):.4f} | {np.mean(MEs_train):.4f} | {np.mean(MEs_val):.4f} | {np.mean(MEs_test):.4f} |')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
