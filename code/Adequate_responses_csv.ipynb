{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script adequates the augmented audios and the data csv from ARAUS dataset so that it is prepared to generate the new ARAUS-extended dataset. It consists of 2 parts:\n",
    "1) Apply gain to the augmented audios and re-save them\n",
    "2) Complete responses.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from maad.util import mean_dB\n",
    "from maad.spl import pressure2leq\n",
    "from Mosqito.loadFiles import load\n",
    "from SoundLights.wav_files import save_wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapt augmented audios gains\n",
    "ARAUS augmented audios should be found in folder /data/augmented_soundscapes, distributed in 25 folders according to the fold they belong to. \n",
    "Each of these audios, was played (in the listening tests) at a certain Leq. This Leq value is provided in responses.csv by ARAUS authors. \n",
    "\n",
    "In order to generate certain features (the ones we call \"ARAUS features\" as they aim to replicate the original ARAUS features), it is needed to know the gain that was applyied to the wav files (audios) in order to get the specified Leq. This linear gain (that converts wav into Peak-Pascals), one for each audio, is calculated in this section, and it must be stored. This is needed because this set of features are acoustical or psychoacoustical, and are linked to the physical signal, not the digital one.\n",
    "\n",
    "However, for the second set of features (the ones we call \"Freesound features\", as they are calculated with FreesoundExtractor() from Essentia library), the audios need to be coherent between each other in terms of energy, meaning that audios that were played with less volume, should have less amplitude than those who were played with higher energy. The factor that gives us this proportionate relation is the gain mentioned in the paragraph above. Therefore, we are re-generating the whole set of augmented audios applying the corresponding gain to each soundscape. In order to avoid clipping (signal values out of range [+1,-1]), we are later normalising by (1/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder containing original augmented soundscapes\n",
    "audioFolderPath=\"../data/soundscapes_augmented/\"\n",
    "# Path to original responeses.csv\n",
    "csvPath=\"../data/csv_files/responses.csv\"\n",
    "ARAUScsv = pd.read_csv(csvPath)\n",
    "\n",
    "count_clip=0\n",
    "count_total=0\n",
    "clipping=[]\n",
    "\n",
    "for dirpath, dirnames, files in os.walk(audioFolderPath):\n",
    "    dirpath_split=dirpath.split(\"soundscapes_augmented\")\n",
    "    # Iterate over all files in the current directory\n",
    "    files.sort()\n",
    "    for file in files:\n",
    "        if file.endswith(\".mp3\") or file.endswith(\".wav\"):\n",
    "            # Find the row in responses.csv corresponding to current audio\n",
    "            audio_path = dirpath + \"/\"+file\n",
    "            file_split = file.split(\"_\")\n",
    "            file_fold = int(file_split[1])\n",
    "            file_participant = \"ARAUS_\" + file_split[3]\n",
    "            file_stimulus = int(file_split[5].split(\".\")[0])\n",
    "            audio_info_aug = ARAUScsv[ARAUScsv[\"fold_r\"] == file_fold]\n",
    "            audio_info_aug = audio_info_aug[\n",
    "                audio_info_aug[\"stimulus_index\"] == file_stimulus\n",
    "            ]\n",
    "            audio_info_aug = audio_info_aug[\n",
    "                audio_info_aug[\"participant\"] == file_participant\n",
    "            ]\n",
    "            # Get the original Leq of this audio \n",
    "            true_Leq=audio_info_aug[\"Leq_R_r\"].values[0]\n",
    "            # Load the stereo audio file\n",
    "            audio_r,fs=load(audio_path, wav_calib=1.0, ch=1)\n",
    "            audio_l,fs=load(audio_path, wav_calib=1.0, ch=0)\n",
    "            # Calculate gain from true Leq and \"raw\" Leq\n",
    "            rawR_Leq=mean_dB(pressure2leq(audio_r, fs, 0.125))\n",
    "            difference=true_Leq-rawR_Leq\n",
    "            gain=10**(difference/20)\n",
    "            # Normalisation gain to avoid a lot of clipping\n",
    "            norm_gain=6.44\n",
    "            # Apply gain to audio\n",
    "            safe_gain=gain/norm_gain\n",
    "            adapted_audio_r=audio_r*safe_gain\n",
    "            adapted_audio_l=audio_l*safe_gain\n",
    "            adapted_signal=np.column_stack((adapted_audio_l, adapted_audio_r))\n",
    "            max_gain=np.max(adapted_audio_r)\n",
    "            min_gain=np.min(adapted_audio_r)\n",
    "            # Clipping?\n",
    "            if(max_gain>1 or min_gain<-1):\n",
    "                count_clip=count_clip+1\n",
    "                clipping.append([file, gain, max_gain,min_gain])\n",
    "            # Save audio\n",
    "            savingPath=dirpath_split[0]+\"ARAUS-extended\"+dirpath_split[1]+\"/\"\n",
    "            if not os.path.exists(savingPath):\n",
    "                os.makedirs(savingPath)\n",
    "            savingPathComplete=savingPath+file\n",
    "            save_wav(adapted_signal, fs, savingPathComplete)\n",
    "            \n",
    "            count_total=count_total+1\n",
    "            print(\"Done audio \", count_total,\"/25440\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completing responses.csv\n",
    "responses.csv provided by ARAUS authors contains the data associated with the augmented soundscapes (participant answers, features of the audio, fold to which the audio belongs, base soundscape and masker used for the augmentation...).\n",
    "However, we are included some new columns into the dataframe, so that it is complete and handy for our operations.\n",
    "1) We are adding the sound source of the maskers (bird, traffic, construction...), as new features --> 6 more columns\n",
    "2) We are addind Pleasantness and Eventfulness values calculated from the participant answers punctuations --> 2 more columns\n",
    "3) We are adding the wav gain that has to be applied to each digital signal to convert it to pressure signal in Pascals --> 1 more column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.read_csv(os.path.join('..','data/csv_files','responses.csv'), dtype = {'participant':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Maskers as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding is a technique used to convert categorical variables into a numerical format that can be used for machine learning algorithms. It is particularly useful when dealing with categorical data that has no inherent order or hierarchy among its categories.\n",
    "\n",
    "Here's how one-hot encoding works:\n",
    "\n",
    "1) Identify Unique Categories:\n",
    "First, you identify all the unique categories present in the categorical variable.\n",
    "\n",
    "1) Create Binary Columns:\n",
    "For each unique category, you create a new binary column. Each binary column corresponds to one unique category.\n",
    "\n",
    "1) Assign Values:\n",
    "In each binary column, you assign a value of 1 if the observation belongs to the category represented by that column, and 0 otherwise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract only the maskers column to generate the one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskers=responses[\"masker\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now from the maskers, extract the type of masker from name (type_number.wav) and then calculate the number of different maskers there is, and assign an order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             silence\n",
      "1             silence\n",
      "2               water\n",
      "3             traffic\n",
      "4             traffic\n",
      "             ...     \n",
      "27250         traffic\n",
      "27251         silence\n",
      "27252    construction\n",
      "27253         silence\n",
      "27254         silence\n",
      "Name: masker, Length: 27255, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Generate maskers column with just masker type\n",
    "maskers_type=maskers.str.split(\"_\").str[0]\n",
    "print(maskers_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['silence', 'water', 'traffic', 'construction', 'wind', 'bird']\n"
     ]
    }
   ],
   "source": [
    "# Now count different maskers\n",
    "maskers_variety=maskers_type.unique().tolist()\n",
    "print(maskers_variety)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, generate the one-hot encoded dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       masker_bird  masker_construction  ...  masker_water  masker_wind\n",
      "0                0                    0  ...             0            0\n",
      "1                0                    0  ...             0            0\n",
      "2                0                    0  ...             1            0\n",
      "3                0                    0  ...             0            0\n",
      "4                0                    0  ...             0            0\n",
      "...            ...                  ...  ...           ...          ...\n",
      "27250            0                    0  ...             0            0\n",
      "27251            0                    0  ...             0            0\n",
      "27252            0                    1  ...             0            0\n",
      "27253            0                    0  ...             0            0\n",
      "27254            0                    0  ...             0            0\n",
      "\n",
      "[27255 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoded=pd.get_dummies(maskers_type, columns=maskers_variety, prefix=\"masker\", dtype=int)\n",
    "print(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, concatenate the one-hot-encoded dataframe with the original, and store it as a new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27255, 166)        participant  fold_r  ... masker_water masker_wind\n",
      "0      ARAUS_00001      -1  ...            0           0\n",
      "1      ARAUS_00001       1  ...            0           0\n",
      "2      ARAUS_00001       1  ...            1           0\n",
      "3      ARAUS_00001       1  ...            0           0\n",
      "4      ARAUS_00001       1  ...            0           0\n",
      "...            ...     ...  ...          ...         ...\n",
      "27250  ARAUS_10005       0  ...            0           0\n",
      "27251  ARAUS_10005       0  ...            0           0\n",
      "27252  ARAUS_10005       0  ...            0           0\n",
      "27253  ARAUS_10005       0  ...            0           0\n",
      "27254  ARAUS_10005      -1  ...            0           0\n",
      "\n",
      "[27255 rows x 166 columns]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate\n",
    "responses_with_maskers=pd.concat([responses, one_hot_encoded], axis=1)\n",
    "print(responses_with_maskers.shape, responses_with_maskers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Calculate P and E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground truth labels refer to the actual, true, or correct values of the target variable (or labels) in a supervised machine learning task. In other words, these are the known outcomes or responses associated with the input data points. The purpose of ground truth labels is to provide a basis for training and evaluating machine learning models.\n",
    "\n",
    "<img src=\"../data/images/PandE_axis.png\" alt=\"Image Description\" width=\"500\">\n",
    "\n",
    "<img src=\"../data/images/PandE_formulas.png\" alt=\"Image Description\" width=\"800\">\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Weights for ISO pleasantness:\n",
    "- Pleasant: 1\n",
    "- Eventful: 0\n",
    "- Chaotic: -sqrt(2)/2\n",
    "- Vibrant: sqrt(2)/2\n",
    "- Uneventful: 0\n",
    "- Calm: sqrt(2)/2\n",
    "- Annoying: -1\n",
    "- Monotonous: -sqrt(2)/2\n",
    "\n",
    "Weights for ISO eventfulness:\n",
    "- Pleasant: 0\n",
    "- Eventful: 1\n",
    "- Chaotic: sqrt(2)/2\n",
    "- Vibrant: sqrt(2)/2\n",
    "- Uneventful: -1\n",
    "- Calm: -sqrt(2)/2\n",
    "- Annoying: 0\n",
    "- Monotonous: -sqrt(2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['pleasant', 'eventful', 'chaotic', 'vibrant', 'uneventful', 'calm', 'annoying', 'monotonous'] # Define attributes to extract from dataframes\n",
    "ISOPl_weights = [1,0,-np.sqrt(2)/2,np.sqrt(2)/2, 0, np.sqrt(2)/2,-1,-np.sqrt(2)/2] # Define weights for each attribute in attributes in computation of ISO Pleasantness\n",
    "ISOEv_weights = [0,1,np.sqrt(2)/2,np.sqrt(2)/2, -1, -np.sqrt(2)/2,0,-np.sqrt(2)/2] # Define weights for each attribute in attributes in computation of ISO Eventfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   participant  fold_r  ... P_ground_truth E_ground_truth\n",
      "0  ARAUS_00001      -1  ...       0.603553       0.207107\n",
      "1  ARAUS_00001       1  ...       0.457107      -0.500000\n",
      "2  ARAUS_00001       1  ...       0.353553      -0.250000\n",
      "3  ARAUS_00001       1  ...       0.457107      -0.189340\n",
      "4  ARAUS_00001       1  ...       0.530330      -0.116117\n",
      "\n",
      "[5 rows x 168 columns]\n",
      "       participant  fold_r  ... P_ground_truth E_ground_truth\n",
      "0      ARAUS_00001      -1  ...   6.035534e-01       0.207107\n",
      "1      ARAUS_00001       1  ...   4.571068e-01      -0.500000\n",
      "2      ARAUS_00001       1  ...   3.535534e-01      -0.250000\n",
      "3      ARAUS_00001       1  ...   4.571068e-01      -0.189340\n",
      "4      ARAUS_00001       1  ...   5.303301e-01      -0.116117\n",
      "...            ...     ...  ...            ...            ...\n",
      "27250  ARAUS_10005       0  ...  -2.299347e-17       0.207107\n",
      "27251  ARAUS_10005       0  ...  -3.964466e-01       0.560660\n",
      "27252  ARAUS_10005       0  ...  -9.267767e-01       0.383883\n",
      "27253  ARAUS_10005       0  ...   6.338835e-01      -0.573223\n",
      "27254  ARAUS_10005      -1  ...  -1.338835e-01       0.926777\n",
      "\n",
      "[27255 rows x 168 columns]\n"
     ]
    }
   ],
   "source": [
    "responses_with_maskers_PE = responses_with_maskers.copy() \n",
    "responses_with_maskers_PE['P_ground_truth'] = ((responses[attributes] * ISOPl_weights).sum(axis=1)/(4+np.sqrt(32))).values # These are normalised ISO Pleasantness values (in [-1,1])\n",
    "responses_with_maskers_PE['E_ground_truth'] = ((responses[attributes] * ISOEv_weights).sum(axis=1)/(4+np.sqrt(32))).values # These are normalised ISO Pleasantness values (in [-1,1])\n",
    "print(responses_with_maskers_PE.head())\n",
    "print(responses_with_maskers_PE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Wav gains for each augmented soundscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ARAUS dataset responses.csv constitute the dataset of +25k augmented soundscapes labeled with psychoacoustic and acoustic parametres. Among these, we can find Leq_r, which constitutes the Leq of channel R for each audio.\n",
    "The wav calibration we need to apply to the audio to obtain such Leq was calculated and already applyied in \"Adapt augmented audios gain\" section: we applyied gain/norm_gain. Therefore, in order to transform the new soundscape augmented ARAUS-extended audio wavs into the peak-Pascals signal, the norm_gain needs to be applyied still. This gain is stored in the new csv, in a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "norm_gain=6.44\n",
    "n_audios=responses.shape[0]\n",
    "gain_values=np.ones(n_audios)*norm_gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['participant', 'fold_r', 'soundscape', 'masker', 'smr',\n",
      "       'stimulus_index', 'wav_gain', 'time_taken', 'is_attention', 'pleasant',\n",
      "       ...\n",
      "       'Leq_L_r', 'Leq_R_r', 'masker_bird', 'masker_construction',\n",
      "       'masker_silence', 'masker_traffic', 'masker_water', 'masker_wind',\n",
      "       'P_ground_truth', 'E_ground_truth'],\n",
      "      dtype='object', length=169)\n"
     ]
    }
   ],
   "source": [
    "# Create a new column with the generated values\n",
    "responses_with_maskers_PE_gain=responses_with_maskers_PE.copy(deep=True)\n",
    "responses_with_maskers_PE_gain.insert(loc=6, column='wav_gain', value=gain_values)\n",
    "print(responses_with_maskers_PE_gain.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save new generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new dataset\n",
    "responses_with_maskers_PE_gain.to_csv(\"../data/responses_SoundLights.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "araus-mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
